<h1>A Raytracer</h1>
What follows is a raytracer written in Java for the course 
"Rendering Algorithms" of the University of Bern in the first half of 2015.

<p>
In computer graphics, ray tracing is a technique for generating an image 
by tracing the path of light through pixels in an image plane and simulating
the effects of its encounters with virtual objects. 
The technique is capable of producing a very high degree of visual realism [...]

<h2>This is a literate program</h2>
This is written in a "literate programming" style and completely contained in this single file.
We write an indented &lt;multi word identifier&gt;=
or  &lt;multi word identifier&gt;+=
to start or expand a section of code that can be inserted elsewhere by referring to <multi word identifier> as in
    <multi word identifier>
Furthermore, [folder/filename.ext]= marks the start of a section that will be written to a file once all abbreviations are fully expanded.

<h2>Known Issues/TODO</h2>
This is a work in progress project, and as such it has a lot of problems, including but not limited to:
<ul>
<li>The colors it computes for Blinn shading do not match the example images.
<li>There are no interesting example scenes.
<li>Refraction does not work
<li>Distance fields are not well tested or understood.
And their maximumRadius property is not properly updated.
It might also be more efficient to have a bounding box instead.
<li>There seem to be some issues with reflection
<li>Raytracing lots of primitives is very slow
<li>The creator does not understand why the camera's projection matrices work, but they do
<li>There is something wrong with the teapot normals or they are too bright for some other reason
<li>The BSP traversal should use a custom stack instead of relying on the runtime callstack for efficiency 
and to support any amount of levels. Well for the latter, the construction would also need a custom stack.
<li>It would be nice to extract texture coordinates from the .obj files and store them in the meshes.
<li>This literate program has some things that are not so nice. For example, it still uses packages, 
which are useless in this context. Also it repeats itself quite often in class names and some other things, 
e.g. the names of images generated by code, in particular the amount of samples.

<p>It would also be nice if we could have inline math formulas via MathJax.
</ul>

<h2>Running</h2>
This program can be "tangled" (i.e. the Java files it encodes created) and then compiled using the prepared
script tt, i.e. by calling
    tt.bat
under windows or
    ./tt.sh
under an Unix os with a recent version of Java properly installed.

<p>
You can always delete the rt and outputs subfolders created here - running tt will recreate them with all
their content.

<h2>Basic Raytracing</h2>
The basic raytracing algorithm is this:
    rayTrace() {
        construct scene representation
        
        for each pixel
            ray = computePrimary()
            hit = first intersection with scene
            color = shade( hit )
            set pixel color
    }
    
The subsequent sections will motivate and define algorithms and data structures
that implement this.

<h3>Ray</h3>    
A ray is represented by an origin and a direction (need not be a unit vector) in three dimensional space.
    [rt/Ray.java]= 
    package rt;
    <common imports>
    public class Ray {
        public final Vector3f origin, direction;
        
        public Ray(Vector3f origin, Vector3f direction)
        {
            assert origin != null : "origin may not be null";
            assert direction != null : "direction mustt be non null";
            assert !direction.equals(new Vector3f());
            <copy origin and direction>
        }
        <ray methods>
        
        public String toString() {
            return "Ray["+origin+","+direction+"]";
        }
    }
We always need to make defensive copies of mutable arguments supplied to constructors if we want to
enforce encapsulation. The javax.vecmath vector objects are all mutable.
    <copy origin and direction>=
    this.origin = new Vector3f(origin); 
    this.direction = new Vector3f(direction);
For convenience, we provide the method t to construct the point o + t*d on the ray:
    <ray methods>=
    public Vector3f t(float t) {
        return M.t(origin, direction, t);
    }
    
    <unit tests>+=
    @Test
    public void testRay() {
        Vector3f x = new Vector3f(1,2,3);
        Ray r = new Ray(x,x);
        x.set(0,0,0);
        assertEquals(new Vector3f(1,2,3), r.origin);
        assertEquals(new Vector3f(2,4,6), r.t(1));
        assertEquals(new Vector3f(3,6,9), r.t(2));
    }
<h3>Scene Representation</h3>
    construct scene representation
Defines 'scene' properties (list of objects, 'camera' position, final image resolution etc.)
that need to be made accessible to the renderer. 
    [rt/Scene.java]= 
    package rt;
    <common imports>
    public abstract class Scene {
        <scene image capturing device>
    
        protected IntegratorFactory integratorFactory;
        public IntegratorFactory getIntegratorFactory() {return integratorFactory;}

        protected SamplerFactory samplerFactory;
        public SamplerFactory getSamplerFactory() {return samplerFactory;}
        protected Intersectable root;
        public Intersectable getIntersectable() {return root;}
        <additional scene data>
        
        public void prepare() {
            <scene preparation tasks>
        }
    }
    
    <additional scene data>=
    
    <scene image capturing device>=
        public String getOutputFilename() {return "output/"+this.getClass().getName();}
        protected int width;
        protected int height;
        protected Film film;
        public Film getFilm() {return film;}
        /** Number of samples per pixel */
        protected int SPP;
        public int getSPP() {return SPP;}
        protected Tonemapper tonemapper;
        public Tonemapper getTonemapper() {return tonemapper;}
        
        protected Camera camera;
        public Camera getCamera() {return camera;}

        
We will define all of these things along the way.

<h3>Multithreaded rendering</h3>    
We use a multi-threaded approach to casting the rays for the image pixels, that is, to
implement the loop
    for each pixel
We partition the image into blocks, called RenderTasks, that are then submitted to
    <number of threads>=
    Runtime.getRuntime().availableProcessors()-1
worker threads. 
We call the final image a Film and the component responsible for intersection testing and
computing the color value (shading, illumination) at a point is called an Integrator,
so the code goes something like:
    for all pixels in block {
        Ray r = camera.makeWorldSpaceRay(pixel);
        Spectrum s = integrator.integrate(r);
        film.addSample(pixel, s);
    }
The camera is the component responsible for creating rays that originate at some
point and are directed towards the pixels mapped to an image plane in three dimensional space.
Think camera obscura, but with the image plane in front of the camera.
We allow the film to accumulate multiple samples gathered by shooting multiple rays
through points (randomly) sampled on the area covered by a pixel
(so called subpixel locations) on the image plane. 
The process of generating the random samples is left to the integrator.
    for all pixels in block {
        float samples[][] = integrator.makePixelSamples(sampler,spp);
        for all samples {
            Ray r = camera.makeWorldSpaceRay(pixel, sample);
            Spectrum s = integrator.integrate(r);
            film.addSample(pixel + sample_offset, s);
        }
    }
„spp“ is the amount of samples per pixel.
The final code is then
    <blockwise raytracing>=
    for (int j = bottom; j < top; j++) for (int i = left; i < right; i++) {
        float samples[][] = integrator.makePixelSamples(sampler, scene.getSPP());
        for (float[] sample : samples) {
            Ray r = scene.getCamera().makeWorldSpaceRay(i, j, sample);
            Spectrum s = integrator.integrate(r);    
            scene.getFilm().addSample(i + sample[0], j + sample[1], s);
        }
    }
Note that the sampler may choose to return less than spp samples.
We make sure that class names do not clash in our raytracer, so we can always import all of it.
    <common imports>=
    import javax.vecmath.*;
    import rt.*;
    import rt.materials.*;
    import rt.Material.*;
    import rt.lightsources.*;
    import rt.samplers.*;
    import rt.tonemappers.*;
    import rt.intersectables.*;
    import rt.integrators.*;
    import rt.films.*;
    import rt.cameras.*;
    import rt.basicscenes.*;
    import rt.testscenes.*;
    import java.util.*;
    import java.nio.file.Files;
    import java.util.Collections;
    import java.io.*;
    import rt.intersectables.CSGSolid.*;
    import rt.intersectables.CSGNode.*;
    import rt.intersectables.DFNode.*;
    import rt.BSPNode.*;
    import java.awt.image.*;
    import java.awt.Color;
    import java.util.concurrent.*;
    import javax.imageio.*;

The main executable Java file serves to set up and render some scenes.
We will render the following (instances of) scenes:
    <rendered scenes>=
        <test scenes>
        <beautiful scenes>
    <beautiful scenes>=
    
that are defined along the way.
    [rt/Main.java]= 
    package rt;
    <common imports>
    public class Main {
        public static Scene[] scenes = {
            <rendered scenes>
        };
        
        <render task>
        
        public static void main(String[] args) 
        {    
            for (Scene s : scenes) 
                try { 
                    render(s);
                } catch (Exception e) {
                    System.err.println(e);
                    e.printStackTrace(System.err);
                }
        }
        
        public static void render(Scene scene) throws Exception
        {    
            <render scene>
        }
    }    
    
<h4>RenderTask</h4>
    <render task>=
    static class RenderTask implements Runnable
    {
        public int left, right, bottom, top;
        public Integrator integrator;
        public Scene scene;
        public Sampler sampler;
        
        public RenderTask(Scene scene, int left, int right, int bottom, int top) 
        {            
            assert scene != null : "scene may not be null";
            this.scene = scene;
            assert left < right && bottom < top : "wicked boundaries "+left+" "+right+" "+bottom+" "+top;
            this.left = left; this.right = right; this.bottom = bottom; this.top = top;

            <create sampler and integrator>
        }

        public void run() {
            <blockwise raytracing>
        }
    }
    
The render task has its own sampler and integrator. This way threads don't 
compete for access to a shared sampler/integrator, and thread contention
can be reduced. 
    <create sampler and integrator>=
        integrator = scene.getIntegratorFactory().make(scene);
        sampler = scene.getSamplerFactory().make();
        
<h4>Render scene</h4>    
To render a scene, we do the following
    <render scene>=
    scene.prepare();
    <determine amount of blocks and create thread pool>

    <start timer>
    <create and dispatch render tasks>
    <wait for threads to end reporting progress>
    <stop timer>

    <tone map output image and write to file>
            
Each task renders a square image block of size
    <image block size>=
    4
The amount of tasks then computes as
    <determine amount of blocks and create thread pool>=
    int taskSize = <image block size>;    
    int nThreads = <number of threads>;
    int width = scene.getFilm().getWidth(); int height = scene.getFilm().getHeight();
    int nTasks = (int)(Math.ceil(width/(double)taskSize) * Math.ceil(height/(double)taskSize));
    ThreadPoolExecutor executor = new ThreadPoolExecutor(nThreads, nThreads, 60, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(nTasks) );

    <create and dispatch render tasks>=
    ArrayList<Future<?>> futures = new ArrayList<>(nTasks);
    for (int j=0; j < Math.ceil(height/(double)taskSize); j++) {
        for (int i=0; i < Math.ceil(width/(double)taskSize); i++) {
            RenderTask task = new RenderTask(scene, 
                i*taskSize, Math.min((i+1)*taskSize, width), 
                j*taskSize, Math.min((j+1)*taskSize, height));
            futures.add(executor.submit(task));
        }
    }
            
            
    <wait for threads to end reporting progress>=
    System.out.printf("Rendering scene %s (%d spp) with %s threads to file %s: \n", scene.getClass().getName(), scene.getSPP(), nThreads, scene.getClass().toString());
    System.out.println("0%                                                50%                                           100%");
    System.out.println("|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|");
    executor.shutdown();
    
    int printed = 0;
    for (Future<?> f: futures) {
        <wait for f to finish>
        int toPrint = (int) (<get percentage completed>);
        for (; printed < toPrint; printed++) System.out.print("*");
    }
    System.out.println();
    
    <wait for f to finish>=
    f.get();

    <get percentage completed>=
    executor.getCompletedTaskCount()/(float)executor.getTaskCount()*100
    
    <tone map output image and write to file>=
    BufferedImage image = scene.getTonemapper().process(scene.getFilm());
    ImageIO.write(image, "png", new File(scene.getOutputFilename()+".png"));
    
We record the time the rendering takes:
    <start timer>=
    Timer timer = new Timer();
    
    <stop timer>=
    long time_ms = timer.timeElapsed();
    long time_s = time_ms / 1000;
    long time_min =  time_s / 60;
    System.out.printf("Image computed in %d ms = %d min, %d sec.\n", time_ms, time_min, time_s - time_min*60);

<h2>Tests</h2>
We will define simple JUnit 3-tests for certain components as we go.
    [rt/AllTests.java]=
    package rt;
    <common imports>
    import org.junit.runner.*;
    import org.junit.runners.*;
    import org.junit.runners.Suite.*;

    @RunWith(Suite.class)
    @SuiteClasses({rt.UnitTests.class})
    public class AllTests {}
where
    [rt/UnitTests.java]=
    package rt;
    import static org.junit.Assert.*;
    import org.junit.*;
    <common imports>
    public class UnitTests {
        public static void out(Object o) {
            System.out.println(o);
        }
        public static void asserNotEquals(Object a, Object b) {
            assertFalse(a.equals(b));
        }
        public static final float APPROX = 0.0001f;
        // We use this approximation, because it is empirically the best we can hope for (?)
        // no need to go down to 0.001f?
        
        public static Ray validRay() {
            return new Ray(new Vector3f(), validNormal());
        }
        public static Intersectable validIntersectable() {
            return new CSGUnitSphere();
        }
        public static Vector3f validNormal() {
            return new Vector3f(1,0,0);
        }
        public static HitRecord validHitRecord() {
            return new HitRecord(
                validRay(), 1.f, validIntersectable(), validNormal());
        }
        public static Matrix4f validMatrix() {
            Matrix4f m = new Matrix4f();
            m.setIdentity(); return m;
            }
        
        public static void assertEqualsX(float exp, float got) {
            if (M.absf(exp - got) > APPROX) {
                out("assertEqualsX failed, expected "+exp+", got "+got);
            }
            assertEquals(exp, got, APPROX);
        }
        public static void assertEqualsX(Vector3f exp, Vector3f got) {
           assertEqualsX(exp.x, got.x);
           assertEqualsX(exp.y, got.y);
           assertEqualsX(exp.z, got.z);
        }
        public static void assertNotEqualsX(float notexp, float got) {
            assertTrue(M.absf(notexp - got) > APPROX);
        }
        public static void assertNotEqualsX(Vector3f notexp, Vector3f got) {
            if (!(M.absf(notexp.x - got.x) > APPROX
            || M.absf(notexp.y - got.y) > APPROX
            || M.absf(notexp.z - got.z) > APPROX)) {
                out("assertNotEqualsX failed, expected not "+notexp+", got "+got);
            }
            
            assertTrue(
            M.absf(notexp.x - got.x) > APPROX
            || M.absf(notexp.y - got.y) > APPROX
            || M.absf(notexp.z - got.z) > APPROX
            );
        }
        
        @Test 
        public void testEqX() {
            assertEqualsX(0, 0.00005f);
            assertNotEqualsX(0, 0.0002f);
            
            assertEqualsX(new Vector3f(), new Vector3f(0.00005f, 0.00005f, 0.00005f));
            assertEqualsX(new Vector3f(), new Vector3f(0.0001f, 0.00005f, 0.00005f));
            assertNotEqualsX(new Vector3f(), new Vector3f(0.0002f, 0.00005f, 0.00005f));
        }
        @Test 
        public void testNotEq() {
            assertNotEquals(true, false);
        }
        
        <unit tests>
    }
They can be run with
    java -ea -cp *;. org.junit.runner.JUnitCore rt.AllTests
    
<h2>Coordinates</h2>
The ray-tracer operates in three-dimensional space in a right handed coordinate system where
positive y is the up direction
<img src=right-handed.png></img>
    <up vector>=
    new Vector3f(0.f, 1.f, 0.f)
Units are scaled arbitrarily.

<h2>Camera</h2>
A camera is any object that can return rays given pixel coordinates.
It implements the pseudocode
    ray = computePrimary()
of the basic raytracing algorithm.
Given a pixel in image space, the method should make a ray in world space according 
to the camera specifications. The method receives a sample that 
the camera can use to generate the ray with subpixel offset. Typically the first two
sample dimensions are used to sample a sub-location in the current 
pixel (i.e. determine a sub-pixel location). The samples are assumed to be in the range [0,1].
    [rt/Camera.java]= 
    package rt;
    <common imports>
    public interface Camera {
        public Ray makeWorldSpaceRay(int i, int j, float sample[]);
    }
    
<h3>Specific Cameras</h3>
<h4>FixedCamera</h4>
A simple camera with fixed position 
    <fixed camera position>=
    eye = new Vector3f(0.f, 0.f, 3.0f);
(in world coordinates) and no rotation. Thus the camera to world transform is just
    <fixed camera to world>=
    Matrix4f c = new Matrix4f();
    c.setIdentity();
    c.m03 = eye.x;
    c.m13 = eye.y;
    c.m23 = eye.z;

„The view frustum of the camera points to -z direction (in both camera and world space) and
goes through the points [-1,-1,-1], [1,-1,-1], [-1,1,-1], [1,1,-1] in camera coordinates.
The projection matrix is constructed by inverting the matrix that goes from camera coordinates to the 
canonic view volume, which is the cube [-1..1]x[-1..1]x[-1..1] centered at origin.“
<p>
I do not understand how this whole story with the projection matrix, 
homogeneous coordinates, canonic view volume and perspective divide/homogeneous divide works.
<img src=perproj.png></img>
    <fixed projection matrix>=
    Matrix4f p = new Matrix4f();
    p.setIdentity();
    float near = 1.f,  far = 10.f;
    
    p.m22 = -(far+near)/(far-near); p.m23 = -(2*far*near)/(far-near);
    p.m32 = -1.f;                   p.m33 = 0.f;
    
    p.invert();
The viewport matrix transforms points in the range [0..width]x[0..height] linearly to the range [-1..1]x[-1..1], where width and height give the size of the final image. We start off with the matrix that transforms [-1..1]x[-1..1] to [0..width]x[0..height] and then invert.
    <fixed viewport matrix>=
    Matrix4f v = new Matrix4f();
    v.setIdentity();        
    v.m00 = width/2.f;  v.m03 = width/2.f;
    v.m11 = height/2.f; v.m13 = height/2.f;
    v.m22 = 1.f;        v.m23 = 0.f;
    v.invert();

Finally we combine all of them to get the matrix c*p*v that transforms a viewport pixel coordinate
to a world space point.
    <make viewport to world matrix>=
    p.mul(v); c.mul(p); viewportToWorld = c;

The viewport pixels are defined with z -1 coordinate. In homogeneous 3d coordinates, 
the 4th component being 1 defines it as a point.
    <make point on image plane in viewport coordinates>=
    Vector4f d = new Vector4f(i+sample[0], j+sample[1], -1.f, 1.f);
The assumption is that pixel [i,j] is the square [i,i+1] x [j,j+1] in viewport coordinates
            
    [rt/cameras/FixedCamera.java]= 
    package rt.cameras;
    <common imports>
    public class FixedCamera implements Camera {
        Vector3f eye;
        Matrix4f viewportToWorld;
        
        FixedCamera() {}
        public FixedCamera(int width, int height)
        {
            <fixed camera position>
            <fixed camera to world>
            
            <fixed projection matrix>
            <fixed viewport matrix>

            <make viewport to world matrix>
        }
        
        public Ray makeWorldSpaceRay(int i, int j, float[] sample) {
            <make point on image plane in viewport coordinates>
            
            viewportToWorld.transform(d);
            
            return new Ray(eye, M.sub(new Vector3f(d.x, d.y, d.z), eye));
        }

    }
    
    <unit tests>+=
    @Test
    public void testFC() {
        FixedCamera c = new FixedCamera(100,100);
        /* 0,0 is the lower left corner*/
        Ray r = c.makeWorldSpaceRay(0,0,new float[]{0,0});
        assertTrue(r.origin.equals(new Vector3f(0.f, 0.f, 3.0f)));
        
        out("testFC "+r.direction);
        assertEqualsX(new Vector3f(-1.f, -1.f, -1.0f), r.direction);
    }
<h4>PinholeCamera</h4>
A camera with a given position, look-at and up direction and view frustum 
determined by aspect and fov. 
fov is the vertical field of view angle (opening of the view trapezoid) in degrees.
<img src=cam.png></img>
    <pinhole camera to world matrix>=
    Vector3f w = M.sub(eye, to); w.normalize();
    Vector3f u = M.cross(up, w); u.normalize();
    Vector3f v_ = M.cross(w,  u);
            
    // Camera to world transform matrix - take:
    //     x to u
    //     y to v
    //    z coordinates to w,
    // and translate by eye.
    Matrix4f c = new Matrix4f(); c.setIdentity();

    c.m00 = u.x; c.m01 = v_.x; c.m02 = w.x; c.m03 = eye.x;
    c.m10 = u.y; c.m11 = v_.y; c.m12 = w.y; c.m13 = eye.y;
    c.m20 = u.z; c.m21 = v_.z; c.m22 = w.z; c.m23 = eye.z;
        
Perspective projection matrix    
<img src=perproj.png></img>
    <pinhole projection matrix>=
    Matrix4f p = new Matrix4f();
    float tfo2 = (float)Math.tan(Math.toRadians(fov) / 2);
    float near = 1.f, far = 10.f;

    p.m00 = 1/(aspect * tfo2);
    p.m11 = 1/tfo2;
    p.m22 = (near+far)/(near-far);   p.m23 = (2*far*near)/(near-far);
    p.m32 = -1.f;    
    p.invert();

    [rt/cameras/PinholeCamera.java]= 
    package rt.cameras;

    <common imports>

    public class PinholeCamera extends FixedCamera {
        public PinholeCamera(
                Vector3f eye,
                Vector3f to,
                Vector3f up,
                float fov,
                float aspect,
                int width, int height)
        {
            this.eye = eye;
            
            <pinhole camera to world matrix>
            <pinhole projection matrix>
            
            <fixed viewport matrix>
            
            <make viewport to world matrix>
        }
    }
    
    <unit tests>+=
    @Test
    public void testPC() {
        PinholeCamera c = new PinholeCamera(
            new Vector3f(0,0,1),
            new Vector3f(), 
            <up vector>,
            (float)Math.toDegrees(Math.atan(1)*2),
            1,
            100,100);
        /* 0,0 is the lower left corner*/
        Ray r = c.makeWorldSpaceRay(0,0,new float[]{0,0});
        assertTrue(r.origin.equals(new Vector3f(0,0,1)));
        
        
        out("testPC "+r.direction);
        
        assertEqualsX(new Vector3f(-1.f, -1.f, -1.0f), r.direction);
    }
<h2>Ray-Object Intersection</h2>
This section is concerned with the statement 
    hit = first intersection with scene
of the basic raytracing algorithm.

<p>
Our scenes are represented as a set of surfaces in three dimensional space.
We call individual surfaces primitives or objects of the scene.
We need to be able to efficiently intersect rays with all surfaces in
the scene. 
<h3>HitRecord</h3>
A HitRecord stores information about a ray-surface intersection.
It is the type of the 'hit' variable above.
<p>
The information recorded about the hit surface 
is typically used for shading and certain advanced object intersection algorithms.
We will extend this datastructure as needed.
    [rt/HitRecord.java]= 
    package rt;
    <common imports>
    public class HitRecord  {
        <hit record datastructure>
    }
    
At minimum it includes 
<ul>
<li>a reference to the object (or surface, intersectable) that 
was hit
    <hit record datastructure>+=
        public final Intersectable intersectable;    
<li>the ray parameter at the intersection point
    <hit record datastructure>+=
        public final float t;    
such that the hit position is
    <hit record datastructure>+=
        public Vector3f position() {
            return ray.t(t);
        }
<li>and a reference to the ray
    <hit record datastructure>+=
        public final Ray ray;    
</ul>
These are in principle enough to construct a hit record.

<h4>Surface Normals</h4> 
All of the shading techniques we use as well as some of the algorithms for ray-surface
intersection (e.g. the CSG algorithm described below) make use of the surface normal
at the intersection point. This is a normalized (that is unit-) vector
perpendicular to the suface or the tangent plane to the surface at the 
intersection point.
We thus only support differentiable surfaces (or '2d manifolds' embedded in 3d space).
    <hit record datastructure>+=
        public Vector3f normal;
For surfaces obtained as implicit functions (c.f. CSG and distance field primitives), 
the normal is the normalized gradient at the intersection point.
<p>
A hit record is thus constructed as
    <hit record datastructure>+=
    public HitRecord(Ray r, float tt, Intersectable i, Vector3f n) {
        assert r != null : "ray must be non null";
        assert i != null : "intersectable must be non null";
        assert n != null : "normal must be non null";
        ray = r; t = tt; intersectable = i; 
        assert M.isApproxUnitvector(n) : "normal "+n+" must be unit vector, len "+n.length();
        normal = n;
    }
    
    <math utilities>+=
    public static boolean isApprox(float exp, float got) {
        return M.absf(exp-got) <= UnitTests.APPROX;
    }
    public static boolean isApproxUnitvector(Vector3f n) {
        return M.isApprox(1.f, n.length());
    }
    
    
    <unit tests>+=
    @Test 
    public void testNotUv() {
        assertFalse(M.isApproxUnitvector(new Vector3f(0.61025363f, -0.35719824f, -0.4082482f)));
        assertTrue(M.isApproxUnitvector(validNormal()));
    }
    @Test 
    public void testHitRecord2() {
        try {
        HitRecord r = new HitRecord(
            validRay(),
            1.f,
            new CSGUnitSphere(),
            new Vector3f(Float.NaN,Float.NaN,Float.NaN)
        );
        } catch (AssertionError e) {return;}
        assert false;
    }
    // non-unit normals:
    @Test 
    public void testHitRecord3() {
        try {
        HitRecord r = new HitRecord(
            validRay(),
            1.f,
            new CSGUnitSphere(),
            new Vector3f()
        );
        } catch (AssertionError e) {return;}
        assert false;
    }
    @Test 
    public void testHitRecord4() {
        try {
        HitRecord r = new HitRecord(
            validRay(),
            1.f,
            new CSGUnitSphere(),
            new Vector3f(0.61025363f, -0.35719824f, -0.4082482f) // len < 1 // 0.81649655
        );
        } catch (AssertionError e) {return;}
        assert false;
    }
    @Test 
    public void testHitRecord5() {
        try {
        HitRecord r = new HitRecord(
            validRay(),
            1.f,
            new CSGUnitSphere(),
            new Vector3f(-0.9366242f, -1.3377322f, 1.1546463f) // len > 1
        );
        } catch (AssertionError e) {return;}
        assert false;
    }
    
    @Test 
    public void testHitRecord6() {
        try {
        HitRecord r = new HitRecord(
            validRay(),
            1.f,
            new CSGUnitSphere(),
            new Vector3f(0.33787248f, -1.2864125f, 0.09360921f) // len = 1.3333333
        );
        } catch (AssertionError e) {return;}
        assert false;
    }
    
<h3>Intersectables</h3>
An Intersectable is an object with a surface that supports ray-surface intersection.
HitRecord intersect(Ray r) determines whether r hits this surface and if so 
constructs a corresponding hit record, otherwise returns null.
    [rt/Intersectable.java]= 
    package rt;
    <common imports>
    public abstract class Intersectable implements Iterable<Intersectable> {
        public abstract HitRecord intersect(Ray r);
        <additional intersectable methods and data>
    }
  
<h4>Intersectable Tree Structure</h4>  
Intersectables may in turn consist of multple intersectables.
We want to be able to traverse this DAG (directed acyclic graph) structure.
    <additional intersectable methods and data>+=
        public Iterator<Intersectable> iterator() {return Collections.emptyIterator();}
            
        public int size() {
            int n = 0;
            for (Intersectable b : this) n++;
            return n;
        }
        
<h4>Aggregate</h4>
A pure group of Intersectable objects is called an aggregate.
To determine the closest hit, we try to intersect with all the objects in the 
group and keep track of only the closest intersection.
We leave it up to implementations of this abstract class how to store the iterable list of 
objects.
    <intersect all objects in group determine closest hit>=
    HitRecord closestHitRecord = null;
    float t = Float.MAX_VALUE;

    for (Intersectable o : this) {
        HitRecord tmp = o.intersect(r);
        if (tmp != null && tmp.t < t) {
            t = tmp.t;
            closestHitRecord = tmp;
        }
    }
    return closestHitRecord;

    [rt/intersectables/Aggregate.java]= 
    package rt.intersectables;
    <common imports>
    public abstract class Aggregate extends Intersectable {

        public HitRecord intersect(Ray r) {
            <intersect all objects in group determine closest hit>
        }
        
        <additional aggregate methods>
    }
    
The most straightforward way to implement this is of course by storing the objects in a list.
    [rt/intersectables/IntersectableList.java]= 
    package rt.intersectables;
    <common imports>
    public class IntersectableList extends Aggregate {
        public LinkedList<Intersectable> list;
        public IntersectableList() {list = new LinkedList<Intersectable>();}
        public IntersectableList(Collection<Intersectable> i) {this(); add(i);}
        public IntersectableList(Intersectable... i) {this(); add(i);}
        public IntersectableList(IntersectableList i) {this(); add(i);}
        public IntersectableList add(Collection<Intersectable> i) {list.addAll(i); return this;}
        public IntersectableList add(Intersectable... i) {list.addAll(Arrays.asList(i)); return this;} 
        public IntersectableList add(IntersectableList i) {add(i.list); return this;} 
        public Iterator<Intersectable> iterator() {return list.iterator();}
        
        public boolean contains(Intersectable i) {return list.contains(i);}
    }
    
<h3>CSG</h3>
<img src=csg.png></img>
CSG objects are volumetric collections of points.
That is, they do not only have a surface but also a contained volume of points.
These point sets can be combined using set-theoretic operations, 
resulting in an tree with basic objects at the
leafs and operations at the internal nodes.

<p>
If a CSG object is intersected
by a ray, we determine all intersection intervals and their boundaries, that is, 
the intervals along the ray where the ray is either inside or outside the object. 
Each interval has two 
boundaries, a start and an end, where the ray enters and leaves the solid. 
    <get interval boundaries>=
    public abstract ArrayList<IntervalBoundary> getIntervalBoundaries(Ray r);

The returned boundaries of intersection intervals have to be sorted by increasing t.
    <natural order of interval boundaries>=
    public int compareTo(IntervalBoundary b) {
        return (this.t() <= b.t()) ? -1 : 1; 
    }

An interval boundary is characterized as follows
    <interval boundary class>=
    public static class IntervalBoundary implements Comparable<IntervalBoundary>
    {        
        <t value of csg intersection>
        public final BoundaryType type;        
        public final HitRecord hitRecord;    
        public BelongsTo belongsTo;
        
        public float t() {return hitRecord == null ? t : hitRecord.t;}
        public IntervalBoundary(float t,     BoundaryType type) {this.hitRecord = null; this.t = t; this.type = type;}
        public IntervalBoundary(HitRecord r, BoundaryType type) {this.hitRecord = r; this.type = type; t = Float.NaN;}
        
        <natural order of interval boundaries>
    }
    
    <unit tests>+=
    @Test
    public void testIntervalBoundary() {
        IntervalBoundary i = new IntervalBoundary(1.f, BoundaryType.START);
        assertEquals(BoundaryType.START , i.type);
        assertEqualsX(1.f, i.t());
        
        HitRecord h;
        i = new IntervalBoundary(
            h = new HitRecord(
                validRay(),
                2.f,
                validIntersectable(),
                validNormal()
            ), BoundaryType.END);
        assertEquals(BoundaryType.END, i.type);
        assertEqualsX(2.f, i.t());
        assertEquals(h, i.hitRecord);
    }
    
where
    <interval boundary class>+=
    public static enum BoundaryType {START, END};
START marks a boundary where we enter the solid volume, END one where we leave it.
The member of type
    <interval boundary class>+=
    public static enum BelongsTo {LEFT, RIGHT};
is used during merging of intervals in the Roth algorithm for internal CSG-graph nodes,
which have a left (‚A‘) and right (‚B‘) child.
It marks to which child an interval boundary belonged to in the merged list of boundaries.
<p>
The t value of intersection, i.e. distance the ray traveled before hitting can be
Float.POSITIVE_INFINITY and Float.NEGATIVE_INFINITY.
These values indicate that the volume is never left. 
In this case, the hitRecord attribute of this IntervalBoundary must be null.
t should also always be equal to hitRecord.t if hitRecord is set.
    <t value of csg intersection>=
    private final float t;    

CSGSolid is the base class of all CSG objects. 
    [rt/intersectables/CSGSolid.java]= 
    package rt.intersectables;
    <common imports>

    public abstract class CSGSolid extends Intersectable {
        <interval boundary class>
        <csg intersect with ray>
        <get interval boundaries>    
    }

<h4>Intersection</h4>
The actual intersection point with a csg object is the first interval boundary with positive t.
    <csg intersect with ray>=
    public HitRecord intersect(Ray r) {
        ArrayList<IntervalBoundary> intervalBoundaries = getIntervalBoundaries(r);
        
        <return first hit>
                
        return null;
    }
where
    <return first hit>=
    for (IntervalBoundary ib : intervalBoundaries)
        if (ib.hitRecord != null && ib.hitRecord.t > 0.f)    
            return ib.hitRecord;            
<h4>Combinators, Intermediate Nodes</h4>
<h5>CSGInstance</h5>
A CSGInstance node modulates the incoming ray and outgoing intervals to simulate a
linear transformation of the CSG object.
It does pretty much the same as Instance does for any Intersectables in general.

    [rt/intersectables/CSGInstance.java]= 
    package rt.intersectables;

    <common imports>
    public class CSGInstance extends CSGSolid {
        public CSGSolid o;
        <instance transformations>
        <instance iterator>
        public CSGInstance(CSGSolid o, Matrix4f t) {
            <establish instance parameters>
        }
        
        public ArrayList<IntervalBoundary> getIntervalBoundaries(Ray r_) {
            Ray r = Instance.transformRay(r_, ti);
            
            // Intersect
            ArrayList<IntervalBoundary> bs = o.getIntervalBoundaries(r);
            ArrayList<IntervalBoundary> tbs = new ArrayList<>();
            
            // Transform result
            for (IntervalBoundary b : bs) {
                if (b.hitRecord == null) {tbs.add(b); continue;}
                tbs.add(
                    new IntervalBoundary(
                        Instance.transformHitRecord(b.hitRecord, r_, t, tit),
                        b.type
                    )
                );
            }
            return tbs;
        }
    }
    <unit tests>+=
    @Test
    public void testCsgInstanceKeepsInfiniteBoundaries() {
        CSGSolid p = new CSGXYPlane();
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(0,0,-1), new Vector3f(1,0,0))
        );
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertTrue(Float.NEGATIVE_INFINITY == a.get(0).t());
        
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertTrue(Float.POSITIVE_INFINITY == a.get(1).t());
        
        assertEquals(2, a.size());
        
        // instance
        Matrix4f m = new Matrix4f(); m.setIdentity();
        p = new CSGInstance(p, m);
        
         a = p.getIntervalBoundaries(
            new Ray(new Vector3f(0,0,-1), new Vector3f(1,0,0))
        );
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertTrue(Float.NEGATIVE_INFINITY == a.get(0).t());
        
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertTrue(Float.POSITIVE_INFINITY == a.get(1).t());
        
        assertEquals(2, a.size());
        
    }
    
<img src="output/rt.testscenes.CSGInstanceTest.png"></img>
    [rt/testscenes/CSGInstanceTest.java]= 
    package rt.testscenes;
    <common imports>
    public class CSGInstanceTest extends ObjectTest {
        public CSGInstanceTest()
        {
            super(new Vector3f(0.f, 0.f, 3.f));
            
            Matrix4f m = new Matrix4f(); m.setIdentity(); 
            m.setTranslation(new Vector3f(0.5f,0.2f,0.3f));
            CSGSolid a = new CSGInstance(new CSGSphere(), m);
            
            CSGSolid b = new CSGSphere();
            
            root = CSGNode.subtract(b,a);
        }
    }
    <test scenes>+=
    new CSGInstanceTest(),

<h5>CSGNode</h5>
A CSG node combines two CSG solids using a set operation, such as
intersection, addition, or subtraction.
It uses the Roth algorithm to combine the sets of intervals from the
left (A) and right (B) child. 
    <csg node>=
    protected CSGSolid left, right;

    public enum OperationType {
        INTERSECT, ADD, SUBTRACT
    };
    protected OperationType operation;

    public CSGNode(CSGSolid left, CSGSolid right, OperationType operation) {
        this.left = left;
        this.right = right;
        this.operation = operation;
    }
    
    @Override
    public Iterator<Intersectable> iterator() {return Arrays.<Intersectable>asList(left, right).iterator();}
    
For convenience, we provide the following methods to construct such nodes
    <static csg node constructors>=
    public static CSGSolid intersect(CSGSolid... s) {
        return operate(OperationType.INTERSECT, s);
    }
    public static CSGSolid add(CSGSolid... s) {
        return operate(OperationType.ADD, s);
    }
    public static CSGSolid subtract(CSGSolid... s) {
        return operate(OperationType.SUBTRACT, s);
    }
which are implemented by repeating the binary operation, associating to the left:
    <static csg node constructors>+=
    public static CSGSolid operate(OperationType operation, CSGSolid... s) {
        assert s.length >= 1;
        if (s.length == 1) return s[0];
        CSGNode r = operate(operation, s[0], s[1]);
        for (int i = 2; i < s.length; i++)
            r = operate(operation, r, s[i]);
        return r;
    }
    
    public static CSGNode operate(OperationType operation, CSGSolid left, CSGSolid right) {
        return new CSGNode(left, right, operation);
    }
    
<h5>The Roth Algorithm</h5>
<img src=roth.png></img>
The getIntervalBoundaries(r) method of the CSGNode computes the combined intervals.
The main idea is to first get
the boundaries of the two CSG solids to be combined. Then, the boundaries
are merged according to the set operation specified by the node with the Roth algorithm.
    <csg node get interval boundaries>=
    public ArrayList<IntervalBoundary> getIntervalBoundaries(Ray r) {
        ArrayList<IntervalBoundary> leftIntervals = left.getIntervalBoundaries(r);
        ArrayList<IntervalBoundary> rightIntervals = right.getIntervalBoundaries(r);

        <interleave intervals>
        <roth combine intervals>
        <clean up intervals>

        return reassigned;
    }

During interleaving, we make use of the BelongsTo property of IntervalBoundary.
    <interleave intervals>=
    ArrayList<IntervalBoundary> combined =
                    new ArrayList<IntervalBoundary>(leftIntervals.size() + rightIntervals.size());
    
    // Tag interval boundaries with left or right node and combine into one list
    tagAndCombine(combined, leftIntervals,     BelongsTo.LEFT);
    tagAndCombine(combined, rightIntervals, BelongsTo.RIGHT);

    // sort by t
    Collections.sort(combined);
where
    <csg node get interval boundaries>+=
        private void tagAndCombine(
                Collection<IntervalBoundary> combined,
                Collection<IntervalBoundary> intervals, 
                BelongsTo tag) {
            for (IntervalBoundary b: intervals) {
                b.belongsTo = tag;
                combined.add(b);
            }
        }
        
The Roth algorithm merges the intervals according to the set operation of the node.
To do this, we traverse interval boundaries 'b' from low to high t and 
re-set the boundaries' BoundaryType property (START, END)
according to Boolean set operation used to combine the two child solids.
The traversal state includes whether we are currently within any interval of
the left child and whether we are currently within any interval of the right child.
    <roth combine intervals>=
        boolean inLeft = false, inRight = false;
        
        ArrayList<IntervalBoundary> reassigned = new ArrayList<IntervalBoundary>();
        for (IntervalBoundary b : combined) {
            <determine whether we enter or leave some interval of left or right>
            
            // apply operation
            BoundaryType newType = BoundaryType.START;
            switch (operation) {
                case INTERSECT: 
                    <apply intersect>
                    break;
                    
                case SUBTRACT: 
                    <apply subtract>
                    break;
                    
                case ADD: 
                    <apply add>
                    break;
            }
            
            if (b.hitRecord != null)
                reassigned.add(new IntervalBoundary(b.hitRecord, newType));
            else
                reassigned.add(new IntervalBoundary(b.t(), newType));
        }
        combined = null;
        
    <determine whether we enter or leave some interval of left or right>=
    switch (b.belongsTo) {
        case LEFT:
            inLeft = b.type == BoundaryType.START;
            break;
        case RIGHT:
            inRight = b.type == BoundaryType.START;
            break; 
    }
    
The "apply operation" phase reclassifies intersection- (or interval boundary-) points.
<ul>
<li>
If we are computing the intersection, an interval boundary is an entering boundary if we are in an interval of both left and right.    
    <apply intersect>=
    if (inLeft && inRight)
        newType = BoundaryType.START;
    else
        newType = BoundaryType.END;
<li>        
If we are computing the subtraction, an interval boundary is an entering boundary if we are in an interval of left and not of right.            
    <apply subtract>=
    if (inLeft && !inRight)
        newType = BoundaryType.START;
    else
        newType = BoundaryType.END;

In a subtract operation, the subtracted solid is turned inside out,
or it "switches sign", so we need to flip its normal direction        
    <apply subtract>+=
    if (b.belongsTo == BelongsTo.RIGHT && b.hitRecord != null) {
        b.hitRecord.normal.negate();
    }
<li>
If we are computing the union (add operation), any interval boundary is an entering boundary if we are in an interval of either left or right.
    <apply add>=
    if (inLeft || inRight)
        newType = BoundaryType.START;
    else
        newType = BoundaryType.END;
</ul>
In the clean-up phase we remove unnecessary interval boundaries:
We remove those where we have two boundaries of the same type (START or END) following each other.
    <clean up intervals>=
    Iterator<IntervalBoundary> it = reassigned.iterator();
    BoundaryType prevType = BoundaryType.END;
    while (it.hasNext()) {
        IntervalBoundary b = it.next();
        if (b.type == prevType)
            it.remove();
        prevType = b.type;
    }
    
    [rt/intersectables/CSGNode.java]= 
    package rt.intersectables;
    <common imports>
    public class CSGNode extends CSGSolid {
        <csg node>
        
        <static csg node constructors>
        
        <csg node get interval boundaries>
    }
        
<h4>Basic Objects, Leaf Nodes</h4>
<h5>Abstract Leaf</h5>
CSG leaf nodes are volumes, here defined as the set of all points p with f(p) <= 0 for some 'density' 
function f.
    <csg leaf volume definition>=
    public abstract float f(Vector3f p);
    
    public boolean isWithinVolume(Vector3f p) {return f(p) <= 0;}
    
The surface of a CSG volume is defined as the set of all points q with f(q) = 0.
The normal at a point on the surface is defined as normalize(∇f(q)).
    <csg leaf get normal>=
    public abstract Vector3f getUnnormalizedNormal(Vector3f q);
    
Each CSG volume must provide a method that computes all finite intersection times t_i such
that
    f(o + t_i * d) = 0
for a ray defined by origin o and d.
    <csg leaf compute finite intersection times>=
    public abstract ArrayList<Float> getFiniteIntersectionTimes(Ray r);

<h6>CSGLeaf intersection intervalcomputation</h6>
    <csg leaf get interval boundaries>=
    public ArrayList<IntervalBoundary> getIntervalBoundaries(Ray ray) {
        <convert finite intersection times to boundaries and classify>
        <add start end if needed>
        return boundaries;
    }
    
We construct interval boundaries corresponding by converting the
all finite intersection times 't' to
HitRecords and sorting them.
    <convert finite intersection times to boundaries and classify>=
        ArrayList<Float> intersectionTimes = getFiniteIntersectionTimes(ray);
        <intersection times empty test>
        ArrayList<IntervalBoundary> boundaries = new ArrayList<IntervalBoundary>(intersectionTimes.size());
        for (Float t : intersectionTimes) {
            Vector3f position = ray.t(t);
            Vector3f normal = M.normalize(getUnnormalizedNormal(position));
            boundaries.add(new IntervalBoundary(
                new HitRecord(
                    ray,
                    t, 
                    this,
                    normal
                ),
                <classify intersection>
            ));
        }
        Collections.sort(boundaries);
The list of intersection times t may be null, i.e. empty. In that case, we return an empty list of
boundaries if the origin of the ray is not within the volume, otherwise we go on
with an empty list of finite intersection times.
    <intersection times empty test>=
    assert intersectionTimes == null || intersectionTimes.size() > 0;
    if (intersectionTimes == null) 
        if (!isWithinVolume(ray.origin))
            return new ArrayList<IntervalBoundary>();
        else
            intersectionTimes = new ArrayList<Float>();
            
We classify the intersections as entering or leaving the volume as follows:
    <classify intersection>=
        (<ray leaves volume>) ? BoundaryType.END : BoundaryType.START
<img src=entercsg.jpg></img>
The ray leaves the volume when the surface normal (red in the above picture) 
and ray direction point into the same halfspace, otherwise it enters.
    <ray leaves volume>=
    M.sameHalfspace(normal, ray.direction)
    
Finally, we prepend an "enter" boundary at t = -∞ if there is none at the beginning,
and a "leave" boundary at t = +∞ if there is none at the end of the list.
    <add start end if needed>=
    if (boundaries.isEmpty() || boundaries.get(0).type == BoundaryType.END)
        boundaries.add(0, new IntervalBoundary(Float.NEGATIVE_INFINITY, BoundaryType.START));
        
    if (boundaries.isEmpty() || boundaries.get(boundaries.size()-1).type == BoundaryType.START)
        boundaries.add(new IntervalBoundary(Float.POSITIVE_INFINITY, BoundaryType.END));
    
    [rt/intersectables/CSGLeaf.java]= 
    package rt.intersectables;
    <common imports>
    public abstract class CSGLeaf extends CSGSolid {
        <csg leaf volume definition>
        <csg leaf get normal>
        <csg leaf compute finite intersection times>
        <csg leaf get interval boundaries>
    }
    
<h5>Concrete primitives</h5>
The solutions for the intersection times and the 
gradients for the functions implemented below 
were found with Mathematica using:
    r[t_] := {ox, oy, oz} + t {dx, dy, dz};
    
    f[{x_, y_, z_}] := (* insert definition of f here *);
    
    Solve[f[r[t]] == 0, t] // FullSimplify // InputForm
    {D[f[{x, y, z}], x], D[f[{x, y, z}], y], D[f[{x, y, z}], z]} // 
      FullSimplify // InputForm
      
Where we abbreviated the ray attributes as
    <rename ray variables>=
    float ox, oy, oz, dx, dy, dz;
    ox = r.origin.x;
    oy = r.origin.y;
    oz = r.origin.z;
    dx = r.direction.x;
    dy = r.direction.y;
    dz = r.direction.z;
    
In the case of the two sided infinite cone, this gives something like
    {{t -> -((dx*ox + dy*oy - dz*oz + 
          Sqrt[4*(dx*ox + dy*oy - dz*oz)^2 - 
             4*(dx^2 + dy^2 - dz^2)*(ox^2 + oy^2 - oz^2)]/2)/
         (dx^2 + dy^2 - dz^2))}, 
     {t -> (-(dx*ox) - dy*oy + dz*oz + 
         Sqrt[4*(dx*ox + dy*oy - dz*oz)^2 - 
            4*(dx^2 + dy^2 - dz^2)*(ox^2 + oy^2 - oz^2)]/2)/
        (dx^2 + dy^2 - dz^2)}}
    {2*x, 2*y, -2*z}

The last line of this result tells us to implement the gradient as
    public Vector3f getUnnormalizedNormal(Vector3f q) {
        return new Vector3f(q.x, q.y, -q.z);
    }
(the scaling with 2 does not matter).
The result also tells us that in getFiniteIntersectionTimes
we first need to compute the expression within the
square root (which is the same for both expressions). 
If it is negative, there are no hits.
Otherwise they are as stated.
The method thus boils down to
    public ArrayList<Float> getFiniteIntersectionTimes(Ray r) {
        <rename ray variables>
        float D = 4*(dx*ox + dy*oy - dz*oz)*(dx*ox + dy*oy - dz*oz) - 
     4*(dx*dx + dy*dy - dz*dz)*(ox*ox + oy*oy - oz*oz);
        if (D < 0) return null;
        
        ArrayList<Float> l = new ArrayList<Float>(2);
        
        l.add(
            -((dx*ox + dy*oy - dz*oz + M.sqrtf(D)/2)/(dx*dx + dy*dy - dz*dz))
        );
        
        l.add(
            (-(dx*ox) - dy*oy + dz*oz + M.sqrtf(D)/2)/(dx*dx + dy*dy - dz*dz)
        );
        return l;
    }
            
<h5>XY CSGPlane</h5>    
    <plane definition>=
    p.z

    [rt/intersectables/CSGXYPlane.java]= 
    package rt.intersectables;
    <common imports>
    public class CSGXYPlane extends CSGLeaf {
        public Vector3f getUnnormalizedNormal(Vector3f q) {
            return new Vector3f(0,0,1);
        }
        
        public float f(Vector3f p) {
            return <plane definition>;
        }
        
        public ArrayList<Float> getFiniteIntersectionTimes(Ray r) {
            if (r.direction.z == 0) return null;
            ArrayList<Float> l = new ArrayList<Float>(1);
            l.add(-(r.origin.z/r.direction.z));
            return l;
        }
    }
    
        
<img src="output/rt.testscenes.CSGXYPlaneTest.png"></img>    
    [rt/testscenes/CSGXYPlaneTest.java]= 
    package rt.testscenes;
    <common imports>

    public class CSGXYPlaneTest extends PinholeCameraScene {
        public CSGXYPlaneTest()
        {
            Vector3f eye = new Vector3f(0.f, 0.f, 3.f);
            Vector3f lookAt = new Vector3f(0.f, 0.f, 0.f);
            setCamera(eye, lookAt, <up vector>);
            
            integratorFactory = new DebugIntegratorFactory();
            
            root = new CSGXYPlane();
        }
    }
    <test scenes>+=
    new CSGXYPlaneTest(),
    
    <unit tests>+=
    @Test
    public void testCSGXYPlane() {
        CSGXYPlane p = new CSGXYPlane();
        
        assertEquals(0, p.getIntervalBoundaries(
            new Ray(new Vector3f(0,0,1), new Vector3f(1,0,0))
        ).size());
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(0,0,-1), new Vector3f(1,0,0))
        );
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertTrue(Float.NEGATIVE_INFINITY == a.get(0).t());
        
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertTrue(Float.POSITIVE_INFINITY == a.get(1).t());
        
        assertEquals(2, a.size());
    }

<h5>UnitSphere</h5>
    <sphere definition>=
    p.x*p.x + p.y*p.y + p.z*p.z - 1

    [rt/intersectables/CSGUnitSphere.java]= 
    package rt.intersectables;
    <common imports>
    public class CSGUnitSphere extends CSGLeaf {
        public Vector3f getUnnormalizedNormal(Vector3f q) {
            return q;
        }
        
        public float f(Vector3f p) {
            return <sphere definition>;
        }
        
        public ArrayList<Float> getFiniteIntersectionTimes(Ray r) {
            <rename ray variables>
            float D = 4*M.sqr(dx*ox + dy*oy + dz*oz) - 
       4*(dx*dx + dy*dy + dz*dz)*(-1 + ox*ox + oy*oy + oz*oz);
            if (D < 0) return null;
            D = M.sqrtf(D);
            
            ArrayList<Float> l = new ArrayList<Float>(2);
            
            l.add(
                -((dx*ox + dy*oy + dz*oz + 
      D/2)/(dx*dx + dy*dy + dz*dz))
            );
            
            l.add(
                (-2*dx*ox - 2*dy*oy - 2*dz*oz + 
     D)/
    (2*(dx*dx + dy*dy + dz*dz))
            );
            return l;
        }
    }
<img src="output/rt.testscenes.UnitSphereTest.png"></img>
    [rt/testscenes/UnitSphereTest.java]= 
    package rt.testscenes;
    <common imports>
    public class UnitSphereTest extends ObjectTest {
        public UnitSphereTest() {
            super(new Vector3f(3.f, 0.f, 0.f));
            root = new CSGUnitSphere();
        }
    }
    <test scenes>+=
    new UnitSphereTest(),
    <unit tests>+=
    @Test 
    public void testUnitSphereTest() {
        assertImgEquals(
            "output/rt.testscenes.UnitSphereTest.png", 
            "testimages/rt.testscenes.UnitSphereTest 1SPP.png"
        );
    }
    
    <unit tests>+=
    @Test
    public void testCSGUnitSphere() {
        CSGUnitSphere p = new CSGUnitSphere();
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(0,0,2), new Vector3f(0,0,-1))
        );
        assertEquals(2, a.size());
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertEquals(1.f, a.get(0).t(), 0.001f);
        assertEquals(1.f, a.get(0).hitRecord.t, 0.001f);
        assertEquals(p, a.get(0).hitRecord.intersectable);
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertEquals(3.f, a.get(1).t(), 0.001f);
        assertEquals(3.f, a.get(1).hitRecord.t, 0.001f);
        assertEquals(p, a.get(1).hitRecord.intersectable);
    }
    
<h5>Cone</h5>
A cone for CSG operations. 
The cone represents a solid cone shaped volume, defined by
    <cone definition>=
    p.x*p.x + p.y*p.y - p.z*p.z
    
    [rt/intersectables/CSGTwoSidedInfiniteCone.java]= 
    package rt.intersectables;
    <common imports>
    public class CSGTwoSidedInfiniteCone extends CSGLeaf {
        public Vector3f getUnnormalizedNormal(Vector3f q) {
            return new Vector3f(q.x, q.y, -q.z);
        }
        
        public float f(Vector3f p) {return <cone definition>;}
        
        public ArrayList<Float> getFiniteIntersectionTimes(Ray r) {
            <rename ray variables>
            float D = 4*(dx*ox + dy*oy - dz*oz)*(dx*ox + dy*oy - dz*oz) - 
         4*(dx*dx + dy*dy - dz*dz)*(ox*ox + oy*oy - oz*oz);
            if (D < 0) return null;
            
            ArrayList<Float> l = new ArrayList<Float>(2);
            
            l.add(
                -((dx*ox + dy*oy - dz*oz + M.sqrtf(D)/2)/(dx*dx + dy*dy - dz*dz))
            );
            
            l.add(
                (-(dx*ox) - dy*oy + dz*oz + M.sqrtf(D)/2)/(dx*dx + dy*dy - dz*dz)
            );
            return l;
        }
    }    
<img src="output/rt.testscenes.ConeTest.png"></img>
    [rt/testscenes/ConeTest.java]= 
    package rt.testscenes;
    <common imports>
    public class ConeTest extends ObjectTest {
        public ConeTest() {
            super(new Vector3f(3.f, 0.f, 0.f));
            root = new CSGTwoSidedInfiniteCone();
        }
    }
    <test scenes>+=
    new ConeTest(),
    <unit tests>+=
    @Test 
    public void testConeTest() {
        assertImgEquals(
            ImageReader.read("output/rt.testscenes.ConeTest.png"), 
            ImageReader.read("testimages/rt.testscenes.ConeTest 1SPP.png")
        );
    }
    
<img src="output/rt.testscenes.ConeNormalTest.png"></img>
    [rt/testscenes/ConeNormalTest.java]= 
    package rt.testscenes;
    <common imports>
    public class ConeNormalTest extends ObjectNormalTest {
        public ConeNormalTest() {
            super(new Vector3f(3.f, 0.f, 0.f));
            root = new CSGTwoSidedInfiniteCone();
        }
    }    
    <test scenes>+=
    new ConeNormalTest(),
    <unit tests>+=
    @Test 
    public void testConeNormalTest() {
        assertImgEquals(
            ImageReader.read("output/rt.testscenes.ConeNormalTest.png"), 
            ImageReader.read("testimages/rt.testscenes.ConeNormalTest 1SPP.png")
        );
    }
        
<h5>Cylinder</h5>
    <cylinder definition>=
    p.x*p.x + p.y*p.y - 1
The solutions for the intersection times and the gradient were found with Mathematica:
    r[t_] := {ox, oy, oz} + t {dx, dy, dz};
    f[{x_, y_, z_}] := x^2 + y^2 - 1;
    Solve[f[r[t]] == 0, t] // FullSimplify // InputForm
    {D[f[{x, y, z}], x], D[f[{x, y, z}], y], D[f[{x, y, z}], z]} // 
      FullSimplify // InputForm
giving
    {{t -> -((dx*ox + dy*oy + Sqrt[-(dy^2*(-1 + ox^2)) + 
        dx*(dx + 2*dy*ox*oy - dx*oy^2)])/(dx^2 + dy^2))}, 
     {t -> (-(dx*ox) - dy*oy + Sqrt[-(dy^2*(-1 + ox^2)) + 
       dx*(dx + 2*dy*ox*oy - dx*oy^2)])/(dx^2 + dy^2)}}
    {2*x, 2*y, 0}
       
    [rt/intersectables/CSGInfiniteCylinder.java]= 
    package rt.intersectables;
    <common imports>
    
    public class CSGInfiniteCylinder extends CSGLeaf {
        public Vector3f getUnnormalizedNormal(Vector3f q) {
            return new Vector3f(q.x, q.y, 0);
        }
        
        public float f(Vector3f p) {return <cylinder definition>;}
        
        public ArrayList<Float> getFiniteIntersectionTimes(Ray r) {
            <rename ray variables>
            float D = -(dy*dy*(-1 + ox*ox)) +  dx*(dx + 2*dy*ox*oy - dx*oy*oy);
            if (D < 0) return null;
            
            ArrayList<Float> l = new ArrayList<Float>(2);
            l.add(
                -((dx*ox + dy*oy + M.sqrtf(D))/(dx*dx + dy*dy))
            );
            
            l.add(
                (-(dx*ox) - dy*oy + M.sqrtf(D))/(dx*dx + dy*dy)
            );
            return l;
        }
    }    
                    
<img src="output/rt.testscenes.CylinderTest.png"></img>    
    [rt/testscenes/CylinderTest.java]= 
    package rt.testscenes;
    <common imports>
    public class CylinderTest extends ObjectNormalTest {
        public CylinderTest() {
            super(new Vector3f(3.f, 0.f, 0.f));
            root = new CSGInfiniteCylinder();
        }
    }
    <test scenes>+=
    new CylinderTest(),
    <unit tests>+=
    @Test 
    public void testCylinderTest() {
        assertImgEquals(
            "output/rt.testscenes.CylinderTest.png", 
            "testimages/rt.testscenes.CylinderTest 1SPP.png"
        );
    }

    
    
    <unit tests>+=
    @Test
    public void testCSGInfiniteCylinder() {
        CSGInfiniteCylinder p = new CSGInfiniteCylinder();
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(2,0,0), new Vector3f(-1,0,0))
        );
        assertEquals(2, a.size());
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertEqualsX(1.f, a.get(0).t());
        assertEquals(1.f, a.get(0).hitRecord.t, 0.001f);
        assertEquals(p, a.get(0).hitRecord.intersectable);
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertEquals(3.f, a.get(1).t(), 0.001f);
        assertEquals(3.f, a.get(1).hitRecord.t, 0.001f);
        assertEquals(p, a.get(1).hitRecord.intersectable);
    }
<h4>Compound CSG Objects</h4>
The following objects are pre combined CSG objects.
    
    [rt/intersectables/CSGCompound.java]= 
    package rt.intersectables;
    <common imports>
    public class CSGCompound extends CSGSolid {
        public CSGSolid root;
        
        @Override
        public Iterator<Intersectable> iterator() {return root.iterator();}
        
        public ArrayList<IntervalBoundary> getIntervalBoundaries(Ray r)
        {
            return root.getIntervalBoundaries(r);
        }
    }

<h5>Sphere</h5>
A sphere for CSG operations. 
The sphere represents a solid spherical shaped volume, so it is
Mathematically speaking a ball.

    [rt/intersectables/CSGSphere.java]= 
    package rt.intersectables;
    <common imports>

    public class CSGSphere extends CSGCompound {
        public CSGSphere() {this(new Vector3f());}
        public CSGSphere(Vector3f p) {this(p, 1.f);}
        public CSGSphere(Vector3f center, float radius) {        
            Matrix4f m = new Matrix4f(); m.setIdentity();
            m.m00 = radius;                                 m.m03 = center.x;
                            m.m11 = radius;                 m.m13 = center.y;
                                            m.m22 = radius; m.m23 = center.z;
            
            root = new CSGInstance(new CSGUnitSphere(), m);
        }
    }    
    <unit tests>+=
    @Test
    public void testCSGSphere() {
        CSGSphere p = new CSGSphere();
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(2,0,0), new Vector3f(-1,0,0))
        );
        assertEquals(2, a.size());
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertEqualsX(1.f, a.get(0).t());
        assertEquals(1.f, a.get(0).hitRecord.t, 0.001f);
        assertTrue(p != a.get(0).hitRecord.intersectable);
        assertTrue(a.get(0).hitRecord.intersectable instanceof CSGUnitSphere);
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertEquals(3.f, a.get(1).t(), 0.001f);
        assertEquals(3.f, a.get(1).hitRecord.t, 0.001f);
        assertFalse(p == a.get(1).hitRecord.intersectable);
    }
    
<img src="output/rt.testscenes.SphereTest.png"></img>    
    [rt/testscenes/SphereTest.java]= 
    package rt.testscenes;
    <common imports>
    public class SphereTest extends PinholeCameraScene {

        public SphereTest()
        {
            super(new Vector3f(0.f, 0.f, 3.f));
            
            CSGSphere a = new CSGSphere(new Vector3f(0.5f,0.2f,0.3f), 1);
            CSGSphere b = new CSGSphere(new Vector3f(0.0f,0,0), 1);
            
            root = CSGNode.subtract(b,a);
        }
    }
    <test scenes>+=
    new SphereTest(),
    <unit tests>+=
    @Test 
    public void testSphereTest() {
        assertImgEquals(
            "output/rt.testscenes.SphereTest.png", 
            "testimages/rt.testscenes.SphereTest.png"
        );
    }
            
<h5>CSGPlane</h5>    
A plane for CSG operations. 
The plane represents a solid that fills a whole half-space.
The plane normal is assumed to point into the empty half-space, 
and the plane occupies the half-space opposite to the normal.
The plane is defined by its (normalized) normal and the signed
distance of the plane to the origin, along the opposite normal direction.
Thus, the plane with normal 0,0,1 and d = -2 is the plane z = 2.

    [rt/intersectables/CSGPlane.java]= 
    package rt.intersectables;
    <common imports>
    public class CSGPlane extends CSGCompound {
        public CSGPlane(Vector3f n, float d)
        {
            Vector3f t1 = M.tangentTo(n);
            Vector3f t2 = M.cross(n, t1);
            
            Matrix4f m = new Matrix4f(); m.setIdentity();
            m.m00 = t1.x; m.m01 = t2.x; m.m02 = n.x; m.m03 = -d*n.x;
            m.m10 = t1.y; m.m11 = t2.y; m.m12 = n.y; m.m13 = -d*n.y;
            m.m20 = t1.z; m.m21 = t2.z; m.m22 = n.z; m.m23 = -d*n.z;
            
            root = new CSGInstance(new CSGXYPlane(), m);
        }
    }
    
    <unit tests>+=
    @Test
    public void testCSGPlane() {
        Vector3f n = new Vector3f(0,1,0);
        CSGPlane p_ = new CSGPlane(n, 1);
        float d = 1;
         Vector3f t1 = M.tangentTo(n);
            Vector3f t2 = M.cross(n, t1);
            
            Matrix4f m = new Matrix4f(); m.setIdentity();
            m.m00 = t1.x; m.m01 = t2.x; m.m02 = n.x; m.m03 = -d*n.x;
            m.m10 = t1.y; m.m11 = t2.y; m.m12 = n.y; m.m13 = -d*n.y;
            m.m20 = t1.z; m.m21 = t2.z; m.m22 = n.z; m.m23 = -d*n.z;
            
        
        Intersectable p = new Instance(
            ((CSGInstance)p_.root).o
            , m
            );
        
        HitRecord r = p.intersect(new Ray(new Vector3f(0,1,0), new Vector3f(0,0,1)));
        assertTrue(r == null);

        r = p.intersect(new Ray(new Vector3f(0,1,0), new Vector3f(0,-1,0)));
        assertTrue(r != null);
        assertEquals(2.f, r.t, 0.001f);

        System.out.println("testCSGPlane" + r.normal);
        assertTrue(n.equals(r.normal));

    }    
    @Test
    public void testCSGPlane2() {
        CSGPlane p = new CSGPlane(new Vector3f(0,0,1), 0); // z = 0
        
        assertEquals(0, p.getIntervalBoundaries(
            new Ray(new Vector3f(0,0,1), new Vector3f(1,0,0))
        ).size());
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(0,0,-1), new Vector3f(1,0,0))
        );
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertTrue(Float.NEGATIVE_INFINITY == a.get(0).t());
        
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertTrue(Float.POSITIVE_INFINITY == a.get(1).t());
        
        assertEquals(2, a.size());
        
        // hit, never leave
        a = p.getIntervalBoundaries(
            new Ray(new Vector3f(0,0,M.PI), new Vector3f(0,0,-1))
        );
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertEqualsX(M.PI, a.get(0).t());
        
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertTrue(Float.POSITIVE_INFINITY == a.get(1).t());
        
        assertEquals(2, a.size());
    }   
    @Test
    public void testCSGPlane3() {
        CSGPlane p = new CSGPlane(new Vector3f(0,1,0), 2); // y == -2
        
        assertEquals(0, p.getIntervalBoundaries(
            new Ray(new Vector3f(0,1,0), new Vector3f(1,0,0))
        ).size());
        
        assertEquals(0, p.getIntervalBoundaries(
            new Ray(new Vector3f(0,-1,0), new Vector3f(1,0,0))
        ).size());
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(0,-3,0), new Vector3f(1,0,0))
        );
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertTrue(Float.NEGATIVE_INFINITY == a.get(0).t());
        
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertTrue(Float.POSITIVE_INFINITY == a.get(1).t());
        
        assertEquals(2, a.size());
    }
    
    
The following tests demonstrate how the plane parametrization works.
You should see nothing on this image, because the plane is exactly at the camera position
<img src="output/rt.testscenes.CSGPlaneTest.png"></img>    
    [rt/testscenes/CSGPlaneTest.java]= 
    package rt.testscenes;
    <common imports>
    public class CSGPlaneTest extends ObjectTest {
        public CSGPlaneTest()
        {
            super(new Vector3f(0.f, 0.f, 3.f));
            root = new CSGPlane(new Vector3f(0,0,1), -3);
        }
    }
    <test scenes>+=
    new CSGPlaneTest(),
    
    <unit tests>+=
    @Test 
    public void testCSGPlaneTest() {
        assertImgEquals(
            ImageReader.read("output/rt.testscenes.CSGPlaneTest.png"), 
            ImageReader.read("testimages/rt.testscenes.CSGPlaneTest 1SPP.png")
        );
    }
    
You should see an infinite plane (in debug output) facing you in this test.
<img src="output/rt.testscenes.CSGPlaneTest2.png"></img>    
    [rt/testscenes/CSGPlaneTest2.java]= 
    package rt.testscenes;
    <common imports>
    public class CSGPlaneTest2 extends ObjectTest {
        public CSGPlaneTest2()
        {
            super(new Vector3f(0.f, 0.f, 3.f));
            root = new CSGPlane(new Vector3f(0,0,1), 3);
        }
    }
    <test scenes>+=
    new CSGPlaneTest2(),
    
        <unit tests>+=
    @Test 
    public void testCSGPlaneTest2() {
        assertImgEquals(
            ImageReader.read("output/rt.testscenes.CSGPlaneTest2.png"), 
            ImageReader.read("testimages/rt.testscenes.CSGPlaneTest2 1SPP.png")
        );
    }
    
    
<img src="output/rt.testscenes.CSGPlaneTest3.png"></img>    
    [rt/testscenes/CSGPlaneTest3.java]= 
    package rt.testscenes;
    <common imports>
    public class CSGPlaneTest3 extends ObjectNormalTest {
        public CSGPlaneTest3()
        {
            super(new Vector3f(0.f, 0.f, 1.f));
            root = new CSGPlane(new Vector3f(0,1,0), 1);
        }
    }
    <test scenes>+=
    new CSGPlaneTest3(),
    <unit tests>+=
    @Test 
    public void testCSGPlaneTest3() {
        assertImgEquals(
            ImageReader.read("output/rt.testscenes.CSGPlaneTest3.png"), 
            ImageReader.read("testimages/rt.testscenes.CSGPlaneTest3.png")
        );
    }
<h5>CSGCube</h5>
A cube implemented using planes and CSG. The cube occupies the volume [-1,1] x [-1,1] x [-1,1]. 
    [rt/intersectables/CSGCube.java]= 
    package rt.intersectables;
    <common imports>
    public class CSGCube extends CSGCompound {
        
        public CSGCube()
        {
            CSGPlane p1 = new CSGPlane(new Vector3f(1.f,0.f,0.f),-1.f);
            CSGPlane p2 = new CSGPlane(new Vector3f(-1.f,0.f,0.f),-1.f);
            CSGPlane p3 = new CSGPlane(new Vector3f(0.f,1.f,0.f),-1.f);
            CSGPlane p4 = new CSGPlane(new Vector3f(0.f,-1.f,0.f),-1.f);
            CSGPlane p5 = new CSGPlane(new Vector3f(0.f,0.f,1.f),-1.f);
            CSGPlane p6 = new CSGPlane(new Vector3f(0.f,0.f,-1.f),-1.f);
            root = CSGNode.intersect(p1, p2, p3, p4,p5, p6);
        }
    }
    <unit tests>+=
    @Test
    public void testCSGCube() {
        CSGCube p = new CSGCube();
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(2,0,0), new Vector3f(-1,0,0))
        );
        assertEquals(2, a.size());
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertEqualsX(1.f, a.get(0).t());
        assertEquals(1.f, a.get(0).hitRecord.t, 0.001f);
        assertTrue(p != a.get(0).hitRecord.intersectable);
        assertTrue(a.get(0).hitRecord.intersectable instanceof CSGXYPlane);
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertEquals(3.f, a.get(1).t(), 0.001f);
        assertEquals(3.f, a.get(1).hitRecord.t, 0.001f);
    }
<img src="output/rt.testscenes.CSGCubeTest.png"></img>    
    [rt/testscenes/CSGCubeTest.java]= 
    package rt.testscenes;
    <common imports>
    public class CSGCubeTest extends ObjectTest {

        public CSGCubeTest()
        {
            super(new Vector3f(2,2,2));
            root = new CSGCube();
        }
    }
    <test scenes>+=
    new CSGCubeTest(),
    <unit tests>+=
    @Test 
    public void testCSGCubeTest() {
        assertImgEquals(
            "output/rt.testscenes.CSGCubeTest.png", 
            "testimages/rt.testscenes.CSGCubeTest 1SPP.png"
        );
    }
<h5>CSGCappedZTunnel</h5>
A square tunnel from -1 to 1 with an opening at the side +z. The face -z is closed.
    [rt/intersectables/CSGCappedZTunnel.java]= 
    package rt.intersectables;
    <common imports>
    public class CSGCappedZTunnel extends CSGCompound {
        public CSGCappedZTunnel()
        {
            CSGPlane p1 = new CSGPlane(new Vector3f(1.f, 0.f, 0.f), 1.f);
            CSGPlane p2 = new CSGPlane(new Vector3f(-1.f, 0.f, 0.f), 1.f);
            CSGPlane p3 = new CSGPlane(new Vector3f(0.f, 1.f, 0.f), 1.f);
            CSGPlane p4 = new CSGPlane(new Vector3f(0.f, -1.f, 0.f), 1.f);
            CSGPlane p5 = new CSGPlane(new Vector3f(0.f, 0.f, 1.f), 1.f);
            root = CSGNode.add(p1, p2, p3, p4, p5);
        }
    }
    
<h5>CSGUnitCylinder</h5>
A cylinder along the z axis from -0.5 to 0.5 of radius 1.    
    [rt/intersectables/CSGUnitCylinder.java]= 
    package rt.intersectables;
    <common imports>

    public class CSGUnitCylinder extends CSGCompound {
        public CSGUnitCylinder()
        {
            root = CSGNode.intersect(
                new CSGPlane(new Vector3f(0.f,0.f,1.f),-1.f),
                new CSGPlane(new Vector3f(0.f,0.f,-1.f),-1.f),
                new CSGInfiniteCylinder()
            );
        }
    }
    
    <unit tests>+=
    @Test
    public void testCSGUnitCylinder() {
        CSGUnitCylinder instance = new CSGUnitCylinder();
        HitRecord h = instance.intersect(new Ray(new Vector3f(2.f,0.f,0.f),new Vector3f(-1.f,0.f,0.f)));
        
        assertTrue(h != null);
        assertEquals(instance, h.intersectable);
        assertEqualsX(h.t, 1.f);
        
        h = instance.intersect(new Ray(new Vector3f(0.f,0.f,2.f),new Vector3f(0.f,0.f,-1.f)));
        assertTrue(h != null);
        assertFalse(instance == h.intersectable);
        assertTrue(h.intersectable instanceof CSGInfiniteCylinder);
        assertEqualsX(h.t, 1.f);
        
        
        h = instance.intersect(new Ray(new Vector3f(0.f,2.f,2.f),new Vector3f(0.f,0.f,-1.f)));
        assertTrue(h == null);
    }
    
    <unit tests>+=
    @Test
    public void testCSGUnitCylinder2() {
        CSGUnitCylinder p = new CSGUnitCylinder();
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(2,0,0), new Vector3f(-1,0,0))
        );
        assertEquals(2, a.size());
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertEqualsX(1.f, a.get(0).t());
        assertEquals(1.f, a.get(0).hitRecord.t, 0.001f);
        assertTrue(p != a.get(0).hitRecord.intersectable);
        assertTrue(a.get(0).hitRecord.intersectable instanceof CSGInfiniteCylinder);
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertEquals(3.f, a.get(1).t(), 0.001f);
        assertEquals(3.f, a.get(1).hitRecord.t, 0.001f);
        assertEquals(a.get(1).hitRecord.intersectable, a.get(0).hitRecord.intersectable);
    }
    // test only the sandwhich
    @Test
    public void testCSGUnitCylinderConstr() {
        CSGSolid p = CSGNode.intersect(
                new CSGPlane(new Vector3f(0.f,0.f,1.f),-1.f),
                new CSGPlane(new Vector3f(0.f,0.f,-1.f),-1.f)
                );
        
        List<IntervalBoundary> a = p.getIntervalBoundaries(
            new Ray(new Vector3f(2,0,0), new Vector3f(-1,0,0))
        );
        assertFalse(null == a);
        assertEquals(2, a.size());
        
        assertEquals(BoundaryType.START, a.get(0).type);
        assertTrue(Float.NEGATIVE_INFINITY == a.get(0).t());
        assertEquals(null, a.get(0).hitRecord);
        
        assertEquals(BoundaryType.END, a.get(1).type);
        assertTrue(Float.POSITIVE_INFINITY == a.get(1).t());
        assertEquals(null, a.get(1).hitRecord);
        
        a = p.getIntervalBoundaries(
            new Ray(new Vector3f(2,0,2), new Vector3f(-1,0,0))
        );
        assertEquals(null, a);
    }
In the test scene, we look at it from the side, i.e. from the +x axis, from
    <unit cylinder origin>=
    3.f, 0.f, 0.f
to be precise.
<img src="output/rt.testscenes.UnitCylinderTest.png"></img>    
    [rt/testscenes/UnitCylinderTest.java]= 
    package rt.testscenes;
    <common imports>
    public class UnitCylinderTest extends ObjectTest {

        public UnitCylinderTest()
        {
            super(new Vector3f(<unit cylinder origin>));
            root = new CSGUnitCylinder();
        }
    }
    <test scenes>+=
    new UnitCylinderTest(),
    <unit tests>+=
    @Test 
    public void testUnitCylinderTest() {
        assertImgEquals(
            "output/rt.testscenes.UnitCylinderTest.png", 
            "testimages/rt.testscenes.UnitCylinderTest 1SPP.png"
        );
    }
<h5>CSGDodecahedron</h5>
A dodecahedron implemented using planes and CSG. The dodecahedron has its center at [0,0,0]. 
All planes are at unit distance from the origin.
It makes a dodecahedron by specifying planes that contain faces, and using CSG
intersection. Face normals are computed using the facts that in a dodecahedron
(1) the top and bottom faces are uniform pentagons, (2) dihedral angles
(a dihedral or torsion angle is the angle between two planes) between 
all faces are 
    pi - arctan(2).
    [rt/intersectables/CSGDodecahedron.java]= 
    package rt.intersectables;
    <common imports>
    public class CSGDodecahedron extends CSGCompound {

        public CSGDodecahedron()
        {
            Vector3f normal;
            
            // Make CSG planes
            CSGPlane planes[] = new CSGPlane[12];
            
            // Bottom half
            normal  = new Vector3f(0.f, -1.f, 0.f);
            planes[0] = new CSGPlane(normal, -1.f);    

            for(int i=0; i<5; i++)
            {
                float x, y, z;
                float theta;
            
                // Make face normals, using facts that in a dodecahedron
                // - top and bottom faces are uniform pentagons
                // - dihedral angles between all faces are pi - arctan(2)
                theta = (float)i * 2.f*(float)Math.PI / 5.f;
                x = (float)(Math.sin(theta) * Math.sin(Math.atan(2.f)));
                z = (float)(Math.cos(theta) * Math.sin(Math.atan(2.f)));
                y = -(float)(Math.cos(Math.atan(2.f)));
                
                normal = new Vector3f(x, y, z);
                planes[i+1] = new CSGPlane(normal, -1.f);    
            }
            
            // Top half
            normal = new Vector3f(0.f, 1.f, 0.f);
            planes[6] = new CSGPlane(normal, -1.f);        

            for(int i=0; i<5; i++)
            {
                float x, y, z;
                float theta;
                
                // Make face normals
                theta = ((float)i+0.5f) * 2.f*(float)Math.PI / 5.f;
                x = (float)(Math.sin(theta) * Math.sin(Math.atan(2.f)));
                z = (float)(Math.cos(theta) * Math.sin(Math.atan(2.f)));
                y = (float)(Math.cos(Math.atan(2.f)));
                
                normal = new Vector3f(x, y, z);
                planes[i+7] = new CSGPlane(normal, -1.f);    
            }
                    
            // Build CSG tree
            CSGNode nodes[] = new CSGNode[6];
            for(int i=0; i<6; i++)
                nodes[i] = new CSGNode(planes[2*i], planes[2*i+1], CSGNode.OperationType.INTERSECT);
            
            CSGNode nodes2[] = new CSGNode[3];
            for(int i=0; i<3; i++)
                nodes2[i] = new CSGNode(nodes[2*i], nodes[2*i+1], CSGNode.OperationType.INTERSECT);

            CSGNode node3 = new CSGNode(nodes2[0], nodes2[1], CSGNode.OperationType.INTERSECT);

            // Return root
            root = new CSGNode(node3, nodes2[2], CSGNode.OperationType.INTERSECT);
        }
    }
    <unit tests>+=
    @Test
    public void testCSGDodecahedron() {
        CSGDodecahedron instance = new CSGDodecahedron();
        HitRecord h = instance.intersect(new Ray(new Vector3f(2.f,0.f,0.f),new Vector3f(-1.f,0.f,0.f)));
        
        assertTrue(h != null);
        assertFalse(instance == h.intersectable);
        assertTrue(h.intersectable instanceof CSGXYPlane);
    }
    <unit tests>+=
    @Test 
    public void testCSGDodecahedron() {
        assertImgEquals(
            "output/rt.testscenes.CSGDodecahedron.png", 
            "testimages/rt.testscenes.CSGDodecahedron.png"
        );
    }
 

<h3>Distance Fields</h3>
A (signed) distance field is similar to a CSG solid in that it is defined by a function f
taking three coordinates as arguments and returning a real number that is 0 at the surface (and negative within the volume).
Indeed, every distance field is a CSG solid, however the converse does not hold.
For f(x, y, z) to define a distance field, the value f(x, y, z) must be exactly or less than
the distance to the nearest contact point with the surface of the volume we are defining.
Remember that for a CSG solid, f(x, y, z) is allowed to be anything, as long as it is
(hopefully continuous) and negative within the volume, 0 on its surface and positive outside.
<p>
However for a distance field, this number must give the radius of a sphere that could be constructed
around the point x, y, z so that it at most touches, but does not intersect, the volume that is being defined.

The distance information is used to march through the distance field efficiently.
<img src=raymarch.png></img>
See <a href=http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm>here</a> for some examples of distance functions.
Some slides about the technique can be found
<a href=http://www.iquilezles.org/www/material/nvscene2008/nvscene2008.htm>here</a>.
We require all basic objects to give a maximum radius r of a sphere centered in the origin which fully contains 
them for optimization purposes.
    <maximum radius>=
    public float maximumRadius = 100.f;
Furthermore, every object can have a minimum ray-march-step size, 
which is also used to compute an approximate normal of the distance field
using symmetric differences.
    <minimal step size>=
    public float minimumStepSize = 0.001f;
<h4>Intersection Algorithm - Distance Marching</h4>
We step through the fields in steps of size given by the f function
at the current origin of a unit marching ray that starts at the input ray position.
    <march step size>=
    Math.abs(f(mr.origin))
we take the absolute value since we want to find intersections when we start on the inside of 
surfaces as well.
    
    <df intersect>=
    public HitRecord intersect(Ray r) {
        <construct marching ray mr of normalized length>
        float totalS = 0.f;
        while (canHitContainingSphere(mr)) {
            float s = <march step size>;     totalS += s;
            mr.origin.set(mr.t(s));
            
            <no hit>
            <process hit>
        }
        return null;
    }

    <construct marching ray mr of normalized length>=
    Vector3f d = new Vector3f(r.direction);
    float originalLength = M.normalizeAndGetLength(d);
    Ray mr = new Ray(r.origin, d);

Once the step size falls below or threshold, we assume a hit.
Otherwise, we do another step of size s.
    <no hit>=
        if (s > minimumStepSize) continue;
        
    <process hit>=
        return new HitRecord(
            mr,
            <compute t>, 
            this, 
            normal(mr.origin)
        );
    
The computation
    <compute t>=
    totalS/originalLength
converts totalS back to „t“ units of the original direction vector and
    <math utilities>+=
    public static float normalizeAndGetLength(Vector3f v) {
        float l = v.length();
        v.scale(1/l);
        return l;
    }
is a fused operation to speed things up a little.
The helper method
    <df intersect>+=
    private boolean canHitContainingSphere(Ray r) {
        float t = Math.max(
            M.intersectSphere(new Vector3f(), maximumRadius, r, -1),
            M.intersectSphere(new Vector3f(), maximumRadius, r, 1)
        );
        return t >= 0;
    }
determines whether the given ray can still hit the containing
sphere from the outside or inside with a positive t (that is, whether r is still 'in front of'
or 'inside' the given sphere).

<h4>Distance Field Normal</h4>
The normal is approximated by taking the central differences along each axis.
In that sense, distance fields, and csg’s can be regarded as density fields,
where this is a common approach to determine the normal.
    <df normal>=
    private float fa(Vector3f p, float x, float y, float z) {
        return f(M.add(p, new Vector3f(x* minimumStepSize, y* minimumStepSize, z* minimumStepSize)));
    }
    private float cd(Vector3f p, float x, float y, float z) {
        return fa(p, x, y, z) - fa(p, -x, -y, -z);
    }    
    public Vector3f normal(Vector3f p) {
        float xd = cd(p, 1.f, 0, 0),
              yd = cd(p, 0, 1.f, 0),
              zd = cd(p, 0, 0, 1.f);
        Vector3f n = new Vector3f(xd, yd, zd); n.normalize();
        return n;
    }
<h4>Distance Field</h4>
The only function implementations of the DistanceField base class need to implement is the
f function.
    [rt/intersectables/DistanceField.java]= 
    package rt.intersectables;
    <common imports>
    public abstract class DistanceField extends Intersectable {
        <minimal step size>
        <maximum radius>
        
        public abstract float f(Vector3f p);

        <df normal>
        <df intersect>
    }
    
<h4>Difference between signed and unsigned fields</h4>
The operations below assume a signed distance field, that is, one where the f function 
is negative inside the volume.
Notice that the intersection algorithm per se would also work with an unsigned field 
i.e. one which is positive on both sides of the surface.
However, the normal computation would not work.

<h4>Distance Field Connectives</h4>
Distance fields can be combined with operations similar to csg operations, and more.
<h5>DFNode</h5>
Issue: We still need to compute combined maximum radius.
Also, I do not know why (or whether always) it works with the
provided smin/smax functions, given they might modify the distances to some value that
is too big (too small does not matter).
So probably smax does not (always) work (?).

    [rt/intersectables/DFNode.java]= 
    package rt.intersectables;
    <common imports>
    public class DFNode extends DistanceField {
        public enum DFOperationType {
            INTERSECT, ADD, SUBTRACT,
            SMOOTH_INTERSECT, SMOOTH_ADD, SMOOTH_SUBTRACT,
        };

        DFOperationType o;
        DistanceField a, b;
            
        @Override
        public Iterator<Intersectable> iterator() {return Arrays.<Intersectable>asList(a, b).iterator();}
            
        public float f(Vector3f p) {
            switch(o) {
                case ADD:
                    return Math.min(a.f(p), b.f(p));
                case INTERSECT:
                    return Math.max(a.f(p), b.f(p));
                case SUBTRACT:            
                    return Math.max(a.f(p), -b.f(p));

                case SMOOTH_ADD:
                    return M.smin(a.f(p), b.f(p));
                case SMOOTH_INTERSECT:
                    return M.smax(a.f(p), b.f(p));
                case SMOOTH_SUBTRACT:            
                    return M.smax(a.f(p), -b.f(p));
            }
            return 0.f;
        }

        public DFNode(DistanceField a, DistanceField b, DFOperationType o) {
            this.a = a; this.b = b; this.o = o;
        }
    }
Where
    <math utilities>+=
    // Like GLSL mix, = a if h = 1, blends to b
    public static float mix(float a, float b, float h) {
            return (1-h)*a + h*b;
    }
    static final float smink = 0.1f;
    public static float smin(float a, float b) {
        float h = clamp( 0.5f+0.5f*(b-a)/smink, 0.0f, 1.0f );
        return mix( b, a, h ) - smink*h*(1.0f-h);
    }
    /*Other smooth minimum functions:
    float res = exp( -k*a ) + exp( -k*b ); // k = 32
    return -log( res )/k;
    
    float a = pow( a, k ), b = pow( b, k ); // k = 8
      return pow( (a*b)/(a+b), 1.0f/k );
    */

    public static float smax(float a, float b) {
        return -smin(-a, -b);
    }
    
are <a href=http://www.iquilezles.org/www/articles/smin/smin.htm>smooth minimum/maximum functions</a>.
<h6>Demo</h6>
Here is the difference between standard minimum/csg subtraction:

<img src="output/rt.testscenes.DFTestCSG.png"></img>    
    [rt/testscenes/DFTestCSG.java]= 
    package rt.testscenes;
    <common imports>
    public class DFTestCSG extends ObjectNormalTest {
        public DFTestCSG()
        {
            super(new Vector3f(3.f, 0.f, 0.f));
            
            integratorFactory = new NormalDebugIntegratorFactory();
            CSGSolid a = new CSGSphere(new Vector3f(), 1);
            <make matrix>
            CSGSolid b = new CSGInstance(new CSGSphere(<sphere two>), m); 
            root = new CSGNode(a, b, OperationType.SUBTRACT);
        }
    }
    <test scenes>+=
    new DFTestCSG(),
    <unit tests>+=
    @Test 
    public void testDFTestCSG() {
        assertImgEquals(
            "output/rt.testscenes.DFTestCSG.png", 
            "testimages/rt.testscenes.DFTestCSG.png"
        );
    }
and SMOOTH_SUBTRACT of two spheres:
<img src="output/rt.testscenes.DFTest.png"></img>    
    [rt/testscenes/DFTest.java]= 
    package rt.testscenes;
    <common imports>
    public class DFTest extends ObjectNormalTest {
        public DFTest()
        {
            super(new Vector3f(3.f, 0.f, 0.f));
            
            DistanceField a = new DFSphere(new Vector3f(), 1);
            <make matrix>
            DistanceField b = new DFInstance(new DFSphere(<sphere two>), m); 
            root = new DFNode(a, b, DFOperationType.SMOOTH_SUBTRACT);
        }
    }
    <test scenes>+=
    new DFTest(),
    <unit tests>+=
    @Test 
    public void testDFTest() {
        assertImgEquals(
            "output/rt.testscenes.DFTest.png", 
            "testimages/rt.testscenes.DFTest 1SPP.png"
        );
    }
    
In this scene the second sphere is squashed along the z axis, which points to the left
since we are watching from 3,0,0.
    <make matrix>=
    Matrix4f m = new Matrix4f(); m.setIdentity();
    m.m22 = 0.5f;
    <sphere two>=
    new Vector3f(0.3f,0.2f,0.27f), 0.75f

<h5>DFInstance</h5>
Looking up the distance function in a uniformly linearly transformed distance field is trivial.

Issue: What does this do to the containing sphere’s radius, maximumRadius? 
We might need to extract the scaling component of the transformation, maybe also the shear, and the translation. A rotation (around the origin) has no influence.
Certainly, nothing needs to change when you don’t move the object too much, e.g. when just rotating.
Can I just use Matri4f.getScale?

    [rt/intersectables/DFInstance.java]= 
    package rt.intersectables;
    <common imports>
    public class DFInstance extends DistanceField {
        DistanceField o;
        Matrix4f t;
        
        <instance iterator>
        
        public float f(Vector3f p) {
            p = M.transformVectorAsPoint(t, p);
            return o.f(p);
        }

        public DFInstance(DistanceField o, Matrix4f t) {
            t = new Matrix4f(t); t.invert();
            this.t = t; this.o = o;
        }
    }
Note: When the deformations are not too big, we can even use non-uniform transformations with distance fields.
See  <a href=http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm>here under 'domain deformations'</a>.

<h4>Distance Field Primitives</h4>
See <a href=http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm>here</a> 
for some examples of distance functions.
    [rt/intersectables/DFSphere.java]= 
    package rt.intersectables;
    <common imports>
    public class DFSphere extends DistanceField {
        Vector3f c; float r; 
        public float f(Vector3f p) {
            return M.sub(p, c).length() - r;
        }

        public DFSphere(Vector3f c, float r) {
            this.c = c;
            this.r = r;            
            maximumRadius = c.equals(new Vector3f()) ? r : <determine radius of containing sphere at origin>;
            maximumRadius *= 1.1f; // just for the fun
        }
    }
    
To determine the radius, notice that we must also consider the case where c = 0.
In the other case, we can do:
    <determine radius of containing sphere at origin>=
    M.t(c, M.normalize(c), r).length()

Note: We might be able to optimize things further by allowing the 'containing sphere' to be
centered anywhere.

<h3>Instance</h3>
An instance of an intersectable is defined by an object o of which is represents
an instance, and a transformation matrix t specifying where to place this „copy“.
    <establish instance parameters>=
        this.t = new Matrix4f(t);
        ti = M.invert(t);
        tit = new Matrix4f(ti);
        tit.transpose(); 
        this.o = o;
tit is t inverse transposed. It is the special transformation matrix needed for normals.
<img src=titnormals.png></img>
Because other instancing classes share lots of code with this, 
we define the transformation of ray and result as static functions.
r_ denotes the original ray.
    <transform ray>=
    public static Ray transformRay(Ray r_, Matrix4f ti) {
        Vector3f o = new Vector3f(r_.origin), d = new Vector3f(r_.direction);
        Ray r = new Ray(
            M.transformVectorAsPoint(ti, r_.origin),
            
            r_.direction);
        ti.transform(r.direction);
        
        assert r_.origin.equals(o) : "origin changed";
        assert r_.direction.equals(d) : "direction changed";
        return r;
    }
        
    <transform hit record>=
    public static HitRecord transformHitRecord(HitRecord h, Ray r_, Matrix4f t, Matrix4f tit) {
        Vector3f n = new Vector3f(h.normal);
        tit.transform(n);
        n.normalize(); // must renormalize
        HitRecord h2 = new HitRecord(
            r_,     // Use original ray
            h.t, // time stays
            h.intersectable, // TODO should this instance become the hit object?
            n
        );
        
        return h2; // not h!
    }
    
    <unit tests>+=
    @Test
    public void testThr() {
        HitRecord h = validHitRecord();
        Ray r = validRay();
        HitRecord h2 = Instance.transformHitRecord(h, r, validMatrix(), validMatrix());
        assertFalse(h == h2);
        assertEquals(r, h2.ray);
    }
    @Test
    public void testThr2() {
        HitRecord h = validHitRecord();
        Ray r = validRay();
        
        Matrix4f t = new Matrix4f();
        t.setIdentity(); t.setScale(2);
        t.invert(); t.transpose();
        
        HitRecord h2 = Instance.transformHitRecord(h, r, t, t);
        assertFalse(h == h2);
        assertEquals(r, h2.ray);
        assertEqualsX(h2.normal.length(), 1.f);
    }
    
    
    <instance transformations>=
        private Matrix4f t, ti, tit; 

    <instance iterator>=
        @Override
        public Iterator<Intersectable> iterator() {return Arrays.<Intersectable>asList(o).iterator();}

    [rt/intersectables/Instance.java]= 
    package rt.intersectables;
    <common imports>

    public class Instance extends Intersectable {
        <instance transformations>
        private Intersectable o;
        <instance iterator>
        public Instance(Intersectable o, Matrix4f t) {
            <establish instance parameters>
        }

        public HitRecord intersect(Ray r_) {
            Ray r = transformRay(r_, ti);
            HitRecord h = o.intersect(r);
            if (h == null) return null;
            return transformHitRecord(h, r_, t, tit);
        }

        <transform ray>
        <transform hit record>        
    }
    
    <unit tests>+=
    @Test
    public void testInstance() {
        Vector3f n = new Vector3f(0,1,0);
        CSGXYPlane p_ = new CSGXYPlane();
        
        Matrix4f m = new Matrix4f(); m.setIdentity();
        m.rotX(3*M.PI/2);
        
        System.out.println("m "+m);
        Intersectable p = new Instance(p_, m);
        
        HitRecord r = p.intersect(new Ray(new Vector3f(0,1,0), new Vector3f(0,0,1)));
        assertTrue(r == null);

        Ray mr;
        r = p.intersect(mr = new Ray(new Vector3f(0,1,0), new Vector3f(0,-1,0)));
        assertTrue(r != null);
        assertEquals(1.f, r.t, 0.001f);
        assertEquals(mr, r.ray);
        assertEquals(new Vector3f(0,1,0), r.ray.origin);
        assertEquals(new Vector3f(0,-1,0), r.ray.direction);


        System.out.println("i "+r.normal);
        assertEquals(0.f, r.normal.x, 0.001f);
        assertEquals(1.f, r.normal.y, 0.001f);
        assertEquals(0.f, r.normal.z, 0.001f);

    }
Test for instancing functionality. Note: the spheres look strange (elliptical) and
it looks like they intersect a bit because of perspective projection!
<img src="output/rt.testscenes.InstancingTest.png"></img>    
    [rt/testscenes/InstancingTest.java]= 
    package rt.testscenes;
    <common imports>
    public class InstancingTest extends ObjectTest {
        public InstancingTest()
        {
            super(new Vector3f(0.f, 0.f, 3.f));
            setDimensions(1280, 720);

            CSGSphere sphere = new CSGSphere();
            
            Matrix4f translation = new Matrix4f();
            translation.setIdentity();
            translation.setTranslation(new Vector3f(2.0f, 0.f, 0.f));
            Instance sphere2 = new Instance(sphere, translation);
            
            translation.setTranslation(new Vector3f(-2.0f, 0.f, 0.f));
            Instance sphere3 = new Instance(sphere, translation);
            
            root = new IntersectableList(sphere, sphere2, sphere3);
        }
    }
    <test scenes>+=
    new InstancingTest(),
    <unit tests>+=
    @Test 
    public void testInstancingTest() {
        assertImgEquals(
            "output/rt.testscenes.InstancingTest.png", 
            "testimages/rt.testscenes.InstancingTest.png"
        );
    }

<h3>Mesh</h3>
A triangle mesh is a list of triangles.
The mesh internally stores the triangles using vertex and index arrays
instead of copying these properties to every triangle it is made of. 

    <mesh vertices>=
    public float[] vertices;
Stores x,y,z coordinates for each vertex consecutively.
    <mesh normals>=
    public float[] normals;
Stores x,y,z component for each vertex-normal consecutively.
<p>
Each triangle is defined by three consecutive indices in the indices array.
    <mesh indices>=
    public int[] indices;
The indices i refer to the vertices and normals arrays that store vertex and normal coordinates: 
the i-th vertex occupies locations {3*i+0, 3*i+1, 3*i+2} in the vertices array.
The mesh instantiates a MeshTriangle for each triangle,
    <mesh triangles>=
    private MeshTriangle[] triangles;
and the mesh provides an iterator to iterate through the triangles.
    <triangle iterator>=
    public Iterator<Intersectable> iterator() {
        return new MeshIterator(triangles);
    }
        
    private class MeshIterator implements Iterator<Intersectable> {
        private int i = 0;
        private MeshTriangle[] triangles;
            
        public MeshIterator(MeshTriangle[] triangles) {
            this.triangles = triangles;
        }
            
        public boolean hasNext() {
            return i < triangles.length;
        }
            
        public MeshTriangle next() {
            int j = i; i++;
            return triangles[j];
        }

        public void remove() {}
    }
    [rt/intersectables/Mesh.java]= 
    package rt.intersectables;
    <common imports>
    public class Mesh extends Aggregate {
        <mesh vertices>
        <mesh normals>
        <mesh indices>
        <mesh triangles>
        
        <additional mesh data>
        
        <triangle iterator>
        
        public Mesh(float[] vertices, float[] normals, int[] indices)
        {
            this.vertices = vertices;
            this.normals = normals;
            this.indices = indices;
            

            triangles = new MeshTriangle[indices.length/3];        
            for(int i=0; i<indices.length/3; i++)
                triangles[i] = new MeshTriangle(this, i);
                
            
            <default mesh constructor>
        }    
        
        <additional mesh constructors>
    }
    <additional mesh constructors>=
    <additional mesh data>=
    
Test scene for rendering triangle meshes.    
<img src="output/rt.testscenes.TeapotTest.png"></img>    
    [rt/testscenes/TeapotTest.java]= 
    package rt.testscenes;
    <common imports>
    public class TeapotTest extends ObjectTest {
        public TeapotTest()
        {    
            super(new Vector3f(0.f,0.f,2.f));
            root = <load teapot>;
        }
    }
    <load teapot>=
    ObjReader.read("obj/teapot.obj", 0.95f)
    <test scenes>+=
    new TeapotTest(),
    <unit tests>+=
    @Test 
    public void testTeapotTest() {
        assertImgEquals(
            "output/rt.testscenes.TeapotTest.png", 
            "testimages/rt.testscenes.TeapotTest 1SPP.png"
        );
    }
    
<img src="output/rt.testscenes.TeapotTest2.png"></img>    
    [rt/testscenes/TeapotTest2.java]= 
    package rt.testscenes;
    <common imports>
    public class TeapotTest2 extends ObjectTest {
        public TeapotTest2()
        {    
            super(new Vector3f(0.f,0.f,2.f));
            Matrix4f m = new Matrix4f(); m.setIdentity();
            m.setTranslation(new Vector3f(0,0.5f,0));
            root = new Instance(<load teapot>, m);
        }
    }
    <test scenes>+=
    new TeapotTest2(),
    <unit tests>+=
    @Test 
    public void testTeapotTest2() {
        assertImgEquals(
            "output/rt.testscenes.TeapotTest2.png", 
            "testimages/rt.testscenes.TeapotTest2 1SPP.png"
        );
    }
  
<img src="output/rt.testscenes.InstancingTeapots2.png"></img>    
    [rt/testscenes/InstancingTeapots2.java]= 
    package rt.testscenes;

    <common imports>

    public class InstancingTeapots2 extends ObjectTest {

        public IntersectableList objects;

        public InstancingTeapots2()
        {    
            setSPP(1);
            setDimensions(256);
            
            // Make camera and film
            Vector3f eye = new Vector3f(0.f,0.f,2.f);
            Vector3f lookAt = new Vector3f(0.f,0.f,0.f);
            Vector3f up = new Vector3f(0.f,1.f,0.f);
            setCamera(eye, lookAt, up);
            
            // List of objects
            objects = new IntersectableList();    
            
            // Add objects
            Mesh mesh;
            mesh = ObjReader.read("obj/teapot.obj", 1.f);
            Matrix4f t = new Matrix4f();
            t.setIdentity();
            
            // Instance one
            t.setScale(0.5f);
            t.setTranslation(new Vector3f(0.f, -0.35f, 0.f));
            Instance instance = new Instance(mesh, t);
            objects.add(instance);    
            
            // Instance two
            t.setScale(0.5f);
            t.setTranslation(new Vector3f(0.f, 0.25f, 0.f));
            Matrix4f rot = new Matrix4f();
            rot.setIdentity();
            rot.rotX((float)Math.toRadians(30.f));
            t.mul(rot);
            instance = new Instance(mesh, t);
            objects.add(instance);
                    
            root = objects;
        }
    }
    <test scenes>+=
    new InstancingTeapots2(),
    
<img src="output/rt.testscenes.InstancingTeapots3.png"></img>    
    [rt/testscenes/InstancingTeapots3.java]= 
    package rt.testscenes;

    <common imports>

    public class InstancingTeapots3 extends ObjectNormalTest {

        public IntersectableList objects;

        public InstancingTeapots3()
        {    
            setSPP(1);
            setDimensions(256);
            
            // Make camera and film
            Vector3f eye = new Vector3f(0.f,0.f,2.f);
            Vector3f lookAt = new Vector3f(0.f,0.f,0.f);
            Vector3f up = new Vector3f(0.f,1.f,0.f);
            setCamera(eye, lookAt, up);
            
            // List of objects
            objects = new IntersectableList();    
            
            // Add objects
            Mesh mesh;
            mesh = ObjReader.read("obj/teapot.obj", 1.f);
            Matrix4f t = new Matrix4f();
            t.setIdentity();
            
            // Instance one
            t.setScale(0.5f);
            t.setTranslation(new Vector3f(0.f, -0.35f, 0.f));
            Instance instance = new Instance(mesh, t);
            objects.add(instance);    
            
            // Instance two
            t.setScale(0.5f);
            t.setTranslation(new Vector3f(0.f, 0.25f, 0.f));
            Matrix4f rot = new Matrix4f();
            rot.setIdentity();
            rot.rotX((float)Math.toRadians(30.f));
            t.mul(rot);
            instance = new Instance(mesh, t);
            objects.add(instance);
                    
            root = objects;
        }
    }
    <test scenes>+=
    new InstancingTeapots3(),
  
    
<h4>MeshTriangle</h4>    
MeshTriangle defines a triangle by referring back to a Mesh
and its vertex and index arrays to look up the vertex data.     
<p>
Convention is that vertex order is counter
clockwise when the triangle is seen from outside (outside is by convention
the direction the normal points into).
The normal here thus refers is the cross product of the vector
AB with AC for the three triangle vertices A, B, C.
    [rt/intersectables/MeshTriangle.java]= 
    package rt.intersectables;
    <common imports>

    public class MeshTriangle extends Intersectable {

        private Mesh mesh;
        private int index;
       
        public MeshTriangle(Mesh mesh, int index)
        {
            this.mesh = mesh;
            this.index = index;    
            
            <additional mesh triangle construction tasks>
        }
        
        public HitRecord intersect(Ray ray)
        {
            <ray triangle intersection>
        }
        
        <additional mesh triangle methods>
    }
<h5>Ray-Triangle Intersection</h5>    
The ray-triangle intersection algorithm has the following steps
    <ray triangle intersection>=
        <extract triangle points>
        <compute two triangle sides and normal>
        <ray plane intersection for triangle>
        <compute triangle st>
        <is triangle st within triangle>
        <interpolate normals>
        <return triangle hitpoint>
        
    <extract triangle points>=
    <extract indices>
    <extract vertices>

    <extract indices>=
    int v0 = mesh.indices[index*3], v1 = mesh.indices[index*3+1], v2 = mesh.indices[index*3+2];
    
    <extract vertices>=
    float x0 = mesh.vertices[v0*3],   x1 = mesh.vertices[v1*3],   x2 = mesh.vertices[v2*3];
    float y0 = mesh.vertices[v0*3+1], y1 = mesh.vertices[v1*3+1], y2 = mesh.vertices[v2*3+1];
    float z0 = mesh.vertices[v0*3+2], z1 = mesh.vertices[v1*3+2], z2 = mesh.vertices[v2*3+2];
    
    Vector3f tv0 = new Vector3f(x0,y0,z0), 
          tv1 = new Vector3f(x1,y1,z1), 
          tv2 = new Vector3f(x2,y2,z2);
    
    <compute two triangle sides and normal>=
    Vector3f u, v, n;             
    u = M.sub(tv1, tv0);
    v = M.sub(tv2, tv0);
    n = M.cross(u, v);  
    n.normalize();    
        
For the following phases, we operate in a shifted coordinate system where tv0, the first triangle point, becomes the origin.
    <ray plane intersection for triangle>=
    Vector3f w0 = M.sub(ray.origin, tv0);

    float tmp = n.dot(ray.direction);
    if (tmp == 0) return null;
    float tt = -n.dot(w0) / tmp;

    Vector3f I = ray.t(tt);
The obtained intersection point is in world space again, so it must be shifted to obtain the intersection point w that is on the triangle plane through the origin.

    <compute triangle st>=
    Vector3f w = M.sub(I, tv0); 

We want to find the factors s, t such that s*u + t*v = w.
It turns out that the following computation yields the desired factors 
(see bottom of <a href=http://geomalgorithms.com/a06-_intersect-2.html>this page</a>, 
I did not check or convince myself of the math).
    <compute triangle st>+=
    float uu, vv, uv, wu, wv, D;
    uu = u.dot(u);
    uv = u.dot(v);
    vv = v.dot(v);
    wu = w.dot(u);
    wv = w.dot(v);
    D = uv * uv - uu * vv;

    if (D == 0) return null;
    
    float s, t;
    s = (uv * wv - vv * wu) / D;
    t = (uv * wu - uu * wv) / D;
A point is within the triangle if s, t and s+t are in the interval [0..1].
    <is triangle st within triangle>=
    if (s < 0.0 || s > 1.0) return null;
    if (t < 0.0 || (s + t) > 1.0) return null;

If so, we can extract the mesh vertice's normals and interpolate them, which 
gives us smoother shading than just using the triangle plane's normal n directly.
    <interpolate normals>=
        <extract normals>
        n0.scale(1-s-t); 
        n1.scale(s);
        n2.scale(t);
        n = n0; n.add(n1); n.add(n2); 
        n.normalize();
       
        if (!M.isApprox(n.length(), 1)) return null;
where       
    <extract normals>=
        float nx0 = mesh.normals[v0*3],   nx1 = mesh.normals[v1*3],   nx2 = mesh.normals[v2*3];
        float ny0 = mesh.normals[v0*3+1], ny1 = mesh.normals[v1*3+1], ny2 = mesh.normals[v2*3+1];
        float nz0 = mesh.normals[v0*3+2], nz1 = mesh.normals[v1*3+2], nz2 = mesh.normals[v2*3+2];
        
        Vector3f n0 = new Vector3f(nx0,ny0,nz0), 
                 n1 = new Vector3f(nx1,ny1,nz1), 
                 n2 = new Vector3f(nx2,ny2,nz2);
          
Then we can output the hit-record.
    <return triangle hitpoint>=
        HitRecord h = new HitRecord(
                ray,
                tt, // not t!
                this, 
                n
                ); 
        <triangle hit record post processing>
        return h;
        
    <triangle hit record post processing>=
    
<h5>Tests</h5>
<img src="output/rt.testscenes.TriangleTest.png"></img>    
<img src=tritest.JPG></img>
    [rt/testscenes/TriangleTest.java]= 
    package rt.testscenes;
    <common imports>
    public class TriangleTest extends ObjectTest {

        public TriangleTest()
        {
            super(new Vector3f(0.f, 0.f, 3.f));

            float[] vertices = {
                0.f, 0.f, 0.f, 
                1.f, 0.f, 0.f, 
                0.f, 1.f, 0.f};
            float[] normals = {
                0.f, 0.f, 1.f,
                0.f, 0.f, 1.f,
                0.f, 0.f, 1.f};
            int[] indices = {0, 1, 2};
            
            root = new Mesh(vertices, normals, indices);
        }
    }
    <test scenes>+=
    new TriangleTest(),
    <unit tests>+=
    @Test 
    public void testTriangleTest() {
        assertImgEquals(
            "output/rt.testscenes.TriangleTest.png", 
            "testimages/rt.testscenes.TriangleTest 1SPP.png"
        );
    }
<img src="output/rt.testscenes.TriangleTest2.png"></img>    
    [rt/testscenes/TriangleTest2.java]= 
    package rt.testscenes;
    <common imports>
    public class TriangleTest2 extends ObjectTest {

        public TriangleTest2()
        {
            super(new Vector3f(0.f, 0.f, 9.f));
            
            float[] vertices = {
                0.f, 0.f, 0.f, 
                1.f, 0.f, 0.f, 
                0.f, 1.f, 0.f,
                
                3.f, 1.f, 2.f,
                2.f, 4.f, 5.f,
                1.f, 2.f, 3.f,
                
                1.f, 0.f, 3.f, 
                2.f, 0.f, 3.f, 
                1.f, 2.f, 3.f,
            };
            float[] normals = {
                0.f, 0.f, 1.f,
                0.f, 0.f, 1.f, 
                0.f, 0.f, 1.f,
                
                0.f, 0.f, 1.f,
                0.f, 0.f, 1.f,
                0.f, 0.f, 1.f,
                
                0.f, 0.f, 1.f,
                0.f, 0.f, 1.f,
                0.f, 0.f, 1.f,
                };
            int[] indices = {
                0, 1, 2,
                3, 4, 5,
                6, 7, 8
            };
            
            root = new Mesh(vertices, normals, indices);
        }

    }    
    <test scenes>+=
    new TriangleTest2(),
    <unit tests>+=
    @Test 
    public void testTriangleTest2() {
        assertImgEquals(
            "output/rt.testscenes.TriangleTest2.png", 
            "testimages/rt.testscenes.TriangleTest2 1SPP.png"
        );
    }

    
<img src="output/rt.testscenes.TriangleTest3.png"></img>    
    [rt/testscenes/TriangleTest3.java]= 
    package rt.testscenes;
    <common imports>
    public class TriangleTest3 extends TriangleTest2 {

        public TriangleTest3()
        {
            super();
            integratorFactory = new IntersectableIdDebugIntegratorFactory();
        }

    }    
    
<h4>Mesh Primitives</h4>
We provide some meshes that are constructed computationally (procedurally) 
just because we can.
<h5>MeshUnitCylinder</h5>
The parameter n is the amount of sides.
Issue: Uncapped as of now - this was only added to investigate a
problem with the triangle intersection test. 
Creates every triangle separately (not making use of index buffer).

    [rt/intersectables/MeshUnitCylinder.java]=
    package rt.intersectables;
    <common imports>
    public class MeshUnitCylinder extends IntersectableList {
        public MeshUnitCylinder(int n) {
            int m = <compute amount of indices>;
            float z = 1;
            float[] vertices = new float[3*m];  int cv = 0;
            float[] normals  = new float[3*m];  int cn = 0;
            int  [] indices     = new int[m];         int ci = 0;
            
            <compute angle step>
            for (int i = 0; i < n; i++) {
                float x = <compute x>, y = <compute y>;
                float nx = <compute nx>, ny = <compute ny>;
                <construct vertices>
                <advance indices>
            }
            
            add(new Mesh(vertices, normals, indices));
        }
    }
    
We have n sides, each with two triangles.
    <compute amount of indices>=
    3*(n*2)
We step an angle of 1/n-th of the whole circle in each step.
    <compute angle step>=
    float a = (float)Math.PI*2.f/n;
    
    <compute x>=
    (float)Math.cos((i+0)*a)
    <compute y>=
    (float)Math.sin((i+0)*a)
    
    <compute nx>=
    (float)Math.cos((i+1)*a)
    <compute ny>=
    (float)Math.sin((i+1)*a)
    
We must construct triangles such that their vertices are in counter-clockwise order when seen from the outside.
<img src=cyltri.jpg></img>
    <construct vertices>=
    <vertex a>
    <vertex b>
    <vertex c>
    
    <vertex b>
    <vertex d>
    <vertex c>
    
Where the vertices are
    <vertex a>=
    vertices[cv++] = x; vertices[cv++] = y; vertices[cv++] = z; 
    normals[cn++] = x; normals[cn++] = y; normals[cn++] = 0; 
    <vertex b>=
    vertices[cv++] = x; vertices[cv++] = y; vertices[cv++] = -z;
    normals[cn++] = x; normals[cn++] = y; normals[cn++] = 0; 
    <vertex c>=
    vertices[cv++] = nx; vertices[cv++] = ny; vertices[cv++] = z;
    normals[cn++] = nx; normals[cn++] = ny; normals[cn++] = 0; 
    <vertex d>=
    vertices[cv++] = nx; vertices[cv++] = ny; vertices[cv++] = -z;
    normals[cn++] = nx; normals[cn++] = ny; normals[cn++] = 0; 
    
Just advance by the six vertices we created.
    <advance indices>=
    for (int k = 0; k < 6; k++, ci++) 
        indices[ci] = ci;
    
<img src=ut.jpg></img>
    <unit tests>+=
    @Test
    public void testMeshUnitCylinder() {
        float f = 1/M.sqrtf(2);
        MeshUnitCylinder p = new MeshUnitCylinder(8);
        HitRecord r = p.intersect(new Ray(new Vector3f(1, f, 0.5f), new Vector3f(-1,0,0)));
        assertTrue(r != null);
        assertEquals(1-f, r.t, 0.001f);
        System.out.println(r.position());
        assertEquals(f, r.position().x, 0.001f);
        assertEquals(f, r.position().y, 0.001f);
        assertEquals(0.5f, r.position().z, 0.001f);

    }
    
In the test scene, we look at it from the side, i.e. from the +x axis, from
    <muc origin>=
    3.f, 0.f, 0.f
to be precise.

<img src="output/rt.testscenes.MUC.png"></img>
    [rt/testscenes/MUC.java]= 
    package rt.testscenes;
    <common imports>
    public class MUC extends ObjectTest {
        public MUC()
        {
            super(new Vector3f(<muc origin>));
            root = new MeshUnitCylinder(8);
        }
    }
    <test scenes>+=
    new MUC(),
    
<img src="output/rt.testscenes.MUC2.png"></img>
    [rt/testscenes/MUC2.java]= 
    package rt.testscenes;
    <common imports>
    public class MUC2 extends ObjectTest {//PinholeCameraScene {
        public MUC2()
        {
            super(new Vector3f(<muc origin>));
            root = new MeshUnitCylinder(8);
            integratorFactory = new MaterialIntegratorFactory();
            
            root.setMaterial(new XYZGrid(
                new Spectrum(1,0,0), 
                new Vector3f(0.1f,0.1f,0.1f),
                new Spectrum(1), 
                new Vector3f(1,1,1),
                
                new Vector3f()
            ));
        }
    }
    <test scenes>+=
    new MUC2(),
    <unit tests>+=
    @Test 
    public void testMUC2() {
        assertImgEquals(
            "output/rt.testscenes.MUC2.png", 
            "testimages/rt.testscenes.MUC2 1SPP.png"
        );
    }
    
<img src="output/rt.testscenes.MU3.png"></img>
    [rt/testscenes/MU3.java]= 
    package rt.testscenes;
    <common imports>
    public class MU3 extends ObjectTest {//PinholeCameraScene {
        public MU3()
        {
            super(new Vector3f(3.f, 0.f, 3.f));
            root = new IntersectableList(
                new MeshUnitCylinder(8),
                new CSGPlane(new Vector3f(0,0,1), 0.5f),
                new CSGPlane(new Vector3f(1,0,0), 0.5f)
            );
            integratorFactory = new MaterialIntegratorFactory();
            
            root.setMaterial(new XYZGrid(
                new Spectrum(0,1,0), 
                new Vector3f(0.1f,0.1f,0.1f),
                new Spectrum(1), 
                new Vector3f(1,1,1),
                
                new Vector3f()
            ));
        }
    }
    <test scenes>+=
    new MU3(),
    <unit tests>+=
    @Test 
    public void testMU3() {
        assertImgEquals(
            "output/rt.testscenes.MU3.png", 
            "testimages/rt.testscenes.MU3.png"
        );
    }
    
    
<h5>Rectangle</h5>
A rectangle given by origin and two delta vectors.
It points into the direction of the cross product of da with db.
    <rectangle normal>=
    n = M.cross(da, db); 
<img src=rect.jpg></img>
        
    <rvertex a>=
    vertices[cv++] = a.x; vertices[cv++] = a.y; vertices[cv++] = a.z;     
    <rvertex b>=
    vertices[cv++] = b.x; vertices[cv++] = b.y; vertices[cv++] = b.z;     
    <rvertex c>=
    vertices[cv++] = c.x; vertices[cv++] = c.y; vertices[cv++] = c.z;     
    <rvertex d>=
    vertices[cv++] = d.x; vertices[cv++] = d.y; vertices[cv++] = d.z; 
    
    [rt/intersectables/Rectangle.java]=
    package rt.intersectables;
    <common imports>
    public class Rectangle extends IntersectableList {
        public Vector3f a, da, db, n;
        public Rectangle(Vector3f a, Vector3f da, Vector3f db) {
            this.a = a; this.da = da; this.db = db;
            
            int m = 2 * 3;
            float z = 1;
            float[] vertices = new float[3*m]; int cv = 0;
            float[] normals  = new float[3*m];  
            int  [] indices     = {0,1,2,3,4,5};     
            
            Vector3f b = M.add(a,da);
            Vector3f c = M.add(a,db);
            Vector3f d = M.add(c,da);
            
            <rvertex a>
            <rvertex b>
            <rvertex c>
            
            <rvertex b>
            <rvertex d>
            <rvertex c>
            
            <rectangle normal>
            for (int i = 0; i < m; i++) {
                normals[3*i+0] = n.x; normals[3*i+1] = n.y; normals[3*i+2] = n.z;
            }
            
            add(new Mesh(vertices, normals, indices));
        }
        
        <additional rectangle methods>
    }
    <additional rectangle methods>=
<h2>Acceleration Structures</h2>
The naive approach to determining
    hit = first intersection with scene
used in for example the Aggregate, 
has a complexity of O(n), where n is the amount of objects in the scene.
We can improve this to circa O(log n).
For this we partition the scene's space or object groups recursively in say halfs,
such that we can ignore groups of objects at once when their bounding box is not even hit.
We could also use bounding spheres, or arbitrarily oriented shapes as bounding volumes, but
axis alighned bounding boxes are particularly easy to work with.

<h3>AABB</h3>
Every accelerateable intersectable returns its axis aligned bounding box via the aabb method.
    <additional intersectable methods and data>+=
    public AABB aabb() {
        throw new RuntimeException(this.getClass()+" does not implement aabb()");
    } 
        
An axis aligned bounding box is uniquely defined by its lower left and 
upper right corner coordinates a and b.
    <aabb attributes>=
    Vector3f a, b;
  
An aabb can be constructed such that it encloses a set of points
    <construct aabb>=
        public AABB(Vector3f... ps) {
            float xmin = Float.POSITIVE_INFINITY, ymin = xmin, zmin = xmin, 
                  xmax = Float.NEGATIVE_INFINITY, ymax = xmax, zmax = xmax;
            for (Vector3f p : ps) {
                xmin = Math.min(xmin, p.x); ymin = Math.min(ymin, p.y); zmin = Math.min(zmin, p.z);
                xmax = Math.max(xmax, p.x); ymax = Math.max(ymax, p.y); zmax = Math.max(zmax, p.z);
            }
            a = new Vector3f(xmin, ymin, zmin);
            b = new Vector3f(xmax, ymax, zmax);
        }
        
Or by copying an existing
    <construct aabb>+=
        public AABB(AABB o) {
            a = new Vector3f(o.a); b = new Vector3f(o.b);
        }
The first way of construction can be used to create an aabb that encloses two given ones
    <aabb union>=
    public AABB union(AABB o) {
        return new AABB(a, b, o.a, o.b);
    }
        
We can intersect an aabb with a ray quite easily:
        <ray aabb intersection>=
        public float[] getIntersections(Ray ray) {
            float e_x = ray.origin.x;
            float e_y = ray.origin.y;
            float e_z = ray.origin.z;
            float d_x = ray.direction.x;
            float d_y = ray.direction.y;
            float d_z = ray.direction.z;
            float 
                x_min = a.x, x_max = b.x,
                y_min = a.y, y_max = b.y,
                z_min = a.z, z_max = b.z;
            float t_xmin, t_xmax,
                  t_ymin, t_ymax,
                  t_zmin, t_zmax;
            
            if( d_x >= 0 ) {
                t_xmin = ( x_min - e_x ) / d_x;
                t_xmax = ( x_max - e_x ) / d_x;
            } else {
                t_xmin = ( x_max - e_x ) / d_x;
                t_xmax = ( x_min - e_x ) / d_x;
            }
            
            if( d_y >= 0 ) {
                t_ymin = ( y_min - e_y ) / d_y;
                t_ymax = ( y_max - e_y ) / d_y;
            } else {
                t_ymin = ( y_max - e_y ) / d_y;
                t_ymax = ( y_min - e_y ) / d_y;
            }
            
            if( d_z >= 0 ) {
                t_zmin = ( z_min - e_z ) / d_z;
                t_zmax = ( z_max - e_z ) / d_z;
            } else {
                t_zmin = ( z_max - e_z ) / d_z;
                t_zmax = ( z_min - e_z ) / d_z;
            }

            if (t_xmin>t_ymax || t_ymin>t_xmax) return null;
            if (t_xmin>t_zmax || t_zmin>t_xmax) return null;
            if (t_ymin>t_zmax || t_zmin>t_ymax) return null;
            return new float[] {
                Math.max(Math.max(t_xmin, t_ymin), t_zmin),
                Math.min(Math.min(t_xmax, t_ymax), t_zmax)
            };
        }
The intersection times returned by this are ordered by t. 
We return null if there are none.

<p>
For convenience, we also create a method that, assuming two Intersectables whose
AABBs don't overlap, intersects a ray with both of them and returns them
in the order they are hit. If either is not hit, set it to null.
    <ray aabb intersect and order>=
       public static <T extends Intersectable> T[] intersectAndSort(Ray r, T[] o) {
            assert o != null;
            assert o[0] != null;
            assert o[1] != null;
            assert o[0].aabb() != null;
            assert o[1].aabb() != null;
            float i1[] = o[0].aabb().getIntersections(r);
            float i2[] = o[1].aabb().getIntersections(r);
            
            if (i1 == null) {o[0] = null; return o;}
            if (i2 == null) {o[1] = null; return o;}
            if (i2[0] < i1[0]) {T x = o[0]; o[0] = o[1]; o[1] = x;}
            return o;
        }
    
A method to test whether two axis aligned bounding boxes overlap is straightforward to
implement: two axis aligned boxes are guaranteed to overlap if all of their extents in
x, y, or z coordinates overlap.
<img src=ioverlap.jpg></img>
    <overlaps with other aabb>=
    private static boolean intervalsOverlap(float min, float max, float omin, float omax) {
        return min <= omax && max >= omin;
    }
    public boolean overlapsWith(AABB o) {
        return intervalsOverlap(a.x, b.x,   o.a.x, o.b.x)
            && intervalsOverlap(a.y, b.y,   o.a.y, o.b.y)
            && intervalsOverlap(a.z, b.z,   o.a.z, o.b.z);
    }
    
    
    [rt/AABB.java]= 
    package rt;
    <common imports>
    public class AABB {
        <aabb attributes>
        <construct aabb>
        <aabb union>
        <ray aabb intersection>
        <ray aabb intersect and order>
        <overlaps with other aabb>
        
        public String toString() {
            return "AABB ["+a +", "+b+"]";
           }
    }
    
    <unit tests>+=
    @Test
    public void testAABB() {
        AABB aabb = new AABB(new Vector3f(0,0,0),new Vector3f(2.f,0.5f,0),new Vector3f(1.f,1.f,1.f));
        assertTrue(aabb.a.x == 0 && aabb.b.x == 2.f);
        assertTrue(aabb.a.y == 0 && aabb.b.y == 1.f);
        assertTrue(aabb.a.z == 0 && aabb.b.z == 1.f);
        
        AABB aabb3 = new AABB(new Vector3f(0,0,0),new Vector3f(1.f,1.f,1.f));
        
        AABB aabb2 = aabb.union(aabb3);
        assertTrue(aabb2.overlapsWith(aabb));
        
        float[] ts = aabb3.getIntersections(new Ray(
            new Vector3f(-1,0.5f,0.5f),
            new Vector3f(1,0,0)));
        assertEquals(1.f,ts[0],0.0001f);
        assertEquals(2.f,ts[1],0.0001f);
    }
    
<h4>Triangle AABB</h4>
For the moment, we confine ourselves to computing the AABB for triangle primitives,
which is straightforward:
    <additional mesh triangle construction tasks>=
        <extract indices>
        <extract vertices>
        aabb = new AABB(tv0, tv1, tv2);
                
    <additional mesh triangle methods>=
        private AABB aabb;
        public AABB aabb() {
            return aabb;
        }
Notice that for efficiency reasons, we only construct this once, assuming that 
the mesh will not change.

<h4>Aggregate AABB</h4>
The aabb of an aggregate is simply the union of all child aabbs.
    <additional aggregate methods>=
    public AABB aabb() {
        AABB aabb = null;
        for (Intersectable o : this)
            aabb = (aabb == null) ? o.aabb() : aabb.union(o.aabb());
        return aabb;
    }
    
<h3>BSP, Binary Space partitioning</h3>
Main idea: Recursively divide bounding box into two disjoint parts using
dividing planes (with arbitrary position, orientation).
We fix our orientation to the three axis in space 
(axis aligned splitting planes and bounding boxes).
    <axis enum>=
    public static enum Axis {
        X,Y,Z;
        Axis next() { return this == X ? Y : this == Y ? Z : X; }
    }
        
We implement the BSPAccelerator root node as an IntersectableList containing just one 
BSPNode.
    [rt/BSPAccelerator.java]= 
    package rt;
    <common imports>
    public class BSPAccelerator extends IntersectableList {
        public BSPAccelerator(Aggregate primitives) {
            BSPNode root = new BSPNode();
            
            root.aabb = primitives.aabb();
            root.primitives = primitives;
            
            int n = primitives.size();
            
            root.construct(Axis.X, 0, <maximum depth>);
            
            add(root);
        }
    }
<h4>BSPNode</h4>
By convention the children in the binary tree that a BSP is are called 
'below' and 'above'. 'below' represents that 
part of space with coordinate values lower than that of the split plane along
the axis of it.
A node then either stores two child nodes or a list of primitives when it is a leaf:
    <bsp node attributes>=
        BSPNode below, above;
        Aggregate primitives;
        boolean isLeaf() {
            return primitives != null && below == null && above == null;
        }
        @Override
        public Iterator<Intersectable> iterator() {
            return isLeaf() ? 
                Collections.<Intersectable>emptyList().iterator() :
                Arrays.<Intersectable>asList(below, above).iterator();
        }
          
        
It stores the axis aligned bounding box that intersects all the objects it contains
    <bsp node attributes>+=
    AABB aabb;
    public AABB aabb() {return aabb;}
    
<h4>Construction</h4>
The construct method of a bsp node assumes 'primitives' and 'aabb' were already set.
'axis' represents the split plane normal's direction (we don't care about orientation).

    <construct bsp>=
    void construct(Axis axis, int depth, int maxdepth) {
        <no further children>
        <prepare above and below child>
        <compute child aabb>
        
        <assign primitives to children>
        <construct children>
    }
    
Basic BSP tree construction splits BSP nodes
in their geometric middle
    <compute child aabb>=
    float p;
    switch (axis) {
        case X: p = (aabb.a.x + aabb.b.x)/2; below.aabb.b.x = p; above.aabb.a.x = p; break;
        case Y: p = (aabb.a.y + aabb.b.y)/2; below.aabb.b.y = p; above.aabb.a.y = p; break;
        case Z: p = (aabb.a.z + aabb.b.z)/2; below.aabb.b.z = p; above.aabb.a.z = p; break;
    }

Splitting continues until each node includes fewer objects (e.g., triangles) 
than 
    <max objects per leaf>=
    5
or the tree reaches a maximum depth, which might be computed from the amount n 
of primitives in the tree
    <maximum depth>=
    8 + (int)(1.3 * Math.log(n))
    
    <no further children>=
    if (primitives.size() <= <max objects per leaf> ||
        depth > maxdepth) return;
        
    <prepare above and below child>=
        below = new BSPNode();
        above = new BSPNode();
        
        IntersectableList 
            obelow = new IntersectableList(),
            oabove = new IntersectableList();
        below.primitives = obelow;
        above.primitives = oabove;
        
        below.aabb = new AABB(aabb); // lower values
        above.aabb = new AABB(aabb); // higher values
    
    <assign primitives to children>=
        for (Intersectable o : primitives) {
            if (o.aabb().overlapsWith(below.aabb)) obelow.add(o);
            if (o.aabb().overlapsWith(above.aabb)) oabove.add(o);
        }
        primitives = null;
        
The children will use the cyclically next splitting axis.
    <construct children>=
        depth++;
        axis = axis.next();
        below.construct(axis, depth, maxdepth);
        above.construct(axis, depth, maxdepth);
        
<h4>Intersection</h4>
For intersection, we simply traverse the children that are hit in order.
    <child is hit>=
        float[] ts = aabb.getIntersections(ray); 
        if (ts == null) return null;
        float tmin = ts[0], tmax = ts[1];
    
<ul>
<li>    
When we arrive at a leaf, we intersect with all primitives and keep the hit record
if the intersection happens within the volume.
    <leaf intersection>=
        if (isLeaf()) {
            HitRecord a = primitives.intersect(ray);
            if (a != null && a.t >= tmin && a.t <= tmax) return a;
            return null;
        }
We cannot use other hits, because they might not be globally closest as illustrated below.
<img src=bspisec.png></img>
<li>Otherwise we 
traverse the children:
    <intersect bsp children>=
        BSPNode[] xs = AABB.intersectAndSort(ray, new BSPNode[]{below, above});
        for (BSPNode x : xs) { 
            if (x == null) continue;
            
            HitRecord a = x.intersect(ray);
            if (a != null) return a;
        }
</ul>
Overall:
    <intersect bsp>=
        public HitRecord intersect(Ray ray) {
            <child is hit>
            <leaf intersection>
            <intersect bsp children>
            return null;
        }
        
    [rt/BSPNode.java]= 
    package rt;
    <common imports>
    public class BSPNode extends Intersectable {
        <bsp node attributes>
        <axis enum>
        
        <intersect bsp>
        
        <construct bsp>
    }

<h4>Test: BSPScene</h4>
<img src="output/rt.testscenes.BSPScene.png"></img>
    [rt/testscenes/BSPScene.java]= 
    package rt.testscenes;
    <common imports>
    public class BSPScene extends ObjectNormalTest {
        public BSPScene()
        {
            super(new Vector3f(0.f,0.f,2.f));
            root = new BSPAccelerator(ObjReader.read("obj/Specter_GT3.obj", 0.95f));
        }
    }
    <test scenes>+=
    new BSPScene(),
    <unit tests>+=
    @Test 
    public void testBSPScene() {
        assertImgEquals(
            "output/rt.testscenes.BSPScene.png", 
            "testimages/rt.testscenes.BSPScene 1SPP.png"
        );
    }
    
<h2>Spectrum</h2>
Let us now implement the line   
    color = shade( hit )
of the raytracing pseudocode.
<p>
We first need a representation of 'color' or 'light' that we will let our rays transport from the scene to the camera.
<p>
A 'Spectrum' stores a spectrum of color value intensities. 
In this implementation, we work with RGB colors.
<img src=spec.png></img>
    <math utilities>+=
    public static float random() {return (float)Math.random();}
    [rt/Spectrum.java]= 
    package rt;
    <common imports>
    public class Spectrum {
        public float r, g, b;

        public String toString() {return "("+r +" "+g+" "+b+")";}
        public Spectrum()
        {
            r = 0.f;
            g = 0.f;
            b = 0.f;
        }
        
        @Override
        public boolean equals(Object other) {
            if (other == null) return false;
            if (other == this) return true;
            if (!(other instanceof Spectrum)) return false;
            Spectrum s = (Spectrum)other;
            return s.r == r && s.g == g && b == s.b;
            }

        public Spectrum(float r, float g, float b)
        {
            this.r = r;
            this.g = g;
            this.b = b;
        }
        
        public Spectrum(float s) {this(s,s,s);}

        public Spectrum(Spectrum s)
        {
            this.r = s.r;
            this.g = s.g;
            this.b = s.b;
        }
        
        public static Spectrum random(float base, float scale)
        {
            return new Spectrum(
                     base+M.random()*scale,
                     base+M.random()*scale,
                     base+M.random()*scale);
        }
        
        public static Spectrum randomBright()
        {
            return random(0.5f, 0.5f);
        }
        
        public Spectrum mult(float t)
        {
            r = r*t;
            g = g*t;
            b = b*t;
            return this;
        }
        
        /**
         * Stretch this. Returns this.
         */
        public Spectrum mult(Spectrum s)
        {
            r = r*s.r;
            g = g*s.g;
            b = b*s.b;
            return this;
        }
        
        /**
         * Adds s to this and returns this.
         */
        public Spectrum add(Spectrum s)
        {
            r = r+s.r;
            g = g+s.g;
            b = b+s.b;
            return this;
        }
        
        /**
         * Clamp all components of this returns this.
         */
        public Spectrum clamp(float min, float max)
        {
            r = M.clamp(r, min, max);
            g = M.clamp(g, min, max);
            b = M.clamp(b, min, max);
            return this;
        }
        
        public Spectrum clamp()
        {
            return clamp(0, 1.f);
        }
    }
    
    <unit tests>+=
    @Test
    public void testSpectrum() {
        Spectrum h = new Spectrum(2,-1.f,0);
        assertTrue(h.r == 2 && h.g == -1.f && h.b == 0);
        h.clamp();
        assertEquals(h.r, 1.f, 0.0001f);
        assertEquals(h.g, 0.f, 0.0001f);
    }
    
<h2>Integrator</h2>
Recall that we make an integrator responsible for getting the color, that is,
the pseudocode line
    color = shade( hit )
is implemented by
    Spectrum s = integrator.integrate(r);    
In fact, we let the integrator also execute the command 
    hit = first intersection with scene
via
    <get first intersection with scene>=
    HitRecord hitRecord = scene.getIntersectable().intersect(r);
    
    if (hitRecord == null) return Integrator.BACKGROUND;
    if (hitRecord.t <= 0.f) return Integrator.ERROR; // should not happen
    
An integrator thus takes a ray r
(that might be starting at the camera, or some point on an object’s surface) 
and evaluates the color of the surface it hits.
<p>
The name "integrator" refers to the fact that solving the (physically based)
„rendering equation“ requires integrating over the space of all 
light paths connecting the camera and a 'light source'.
Various implementations of this interface may make different 
approximations and simplifications regarding the solution
of the rendering equation, see below.    


    [rt/Integrator.java]= 
    package rt;
    <common imports>
    public abstract class Integrator {
        public Sampler sampler;
        public Scene scene;
        public Integrator(Scene scene) {
            this.scene = scene;
            sampler = scene.getSamplerFactory().make();
        }
        
        <integrator methods>
        
        public static final Spectrum 
            ERROR = new Spectrum(254/255.f, 20/255.f, 237/255.f), 
            ERROR2 = new Spectrum(0/255.f, 255/255.f, 128/255.f),
            BACKGROUND = new Spectrum();
    }
    
To compute the contribution of a ray to the image, we call
    <integrator methods>+=
    public abstract Spectrum integrate(Ray r);
    
The method
    <integrator methods>+=
    public float[][] makePixelSamples(Sampler sampler, int n) {
        return sampler.makeSamples(n, 2);
    }
    
Generates n two dimensional samples (i.e. an n by 2 array of floats in range 0 to 1). 
This is required by the integrator to evaluate light paths and possibly by other parts
of the system to approximate integrals by montecarlo sampling. This is also used to
determine subpixel sample locations.
The sampler might be a specialized implementation of random noise, or a dummy
implementation without any randomness. 
<p>
We also provide a method to create only one 2d sample. 
This can be used to sample surfaces of e.g. lightsources.
    <integrator methods>+=
    public float[] make2dSample() {
        return makePixelSamples(sampler, 1)[0];
    }

<h3>(Integrator Factory)</h3>
For technical reasons, we don't just create integrator objects directly.
We use the factory pattern of object creation instead.
    [rt/IntegratorFactory.java]= 
    package rt;

    public abstract class IntegratorFactory {
        public abstract Integrator make(Scene scene);
        public void prepareScene(Scene scene) {}
    }
    
<h3>Debug Integrators</h3>
The simplest integrators we can write visualize

For example, they can simply return a white spectrum if the ray hits something, and black otherwise.
Any other visualization of data associated with a hit record may be useful:
<ul>
<li>Intersection time and position
<li>Hit point surface normal
<li>Visualization of intersectable id
</ul> 

<h4>World position</h4>
Here is an example:
<img src=debug.png></img>
This image was obtained by encoding the xyz world coordinates of the hitpoints into the rgb channels.
We use the transformation
    <infinity to one>=
    0.5f+0.5f*(float)Math.atan(a)/((float)Math.PI*0.5f)
which transforms the range [-∞, ∞] to [0, 1], with high resolution around small values:
<img src=scale.png></img>
    [rt/integrators/DebugIntegrator.java]= 
    package rt.integrators;
    <common imports>
    public class DebugIntegrator extends Integrator {
        
        public DebugIntegrator(Scene scene) {super(scene);}

        public static float posf(float a) {
            return <infinity to one>;
        }
        
        public static Spectrum positionToColor(Vector3f v) {
            <apply posf to vector components>
        }
        
        public Spectrum integrate(Ray r) {
            <get first intersection with scene>
            return positionToColor(hitRecord.position());
        }

    }
    
    <apply posf to vector components>=
    return new Spectrum(posf(v.x),posf(v.y),posf(v.z));
        
    [rt/integrators/DebugIntegratorFactory.java]= 
    package rt.integrators;
    import rt.*;
    public class DebugIntegratorFactory extends IntegratorFactory {
        public Integrator make(Scene scene) {return new DebugIntegrator(scene);}
    }
<h4>Normal</h4>    
Here is one that shows the world-space normals of the hitpoints
<img src=normals.png></img>
    [rt/integrators/NormalDebugIntegrator.java]= 
    package rt.integrators;
    <common imports>
    public class NormalDebugIntegrator extends DebugIntegrator {
        public NormalDebugIntegrator(Scene scene) {super(scene);}

        // [-1, 1] to [0, 1] linearly
        public static float posf(float a) {
            return (a+1)*0.5f;
        }
        
        public static Spectrum normalToColor(Vector3f v) {
            <apply posf to vector components>
        }
        
        public Spectrum integrate(Ray r) {
            <get first intersection with scene>
            return normalToColor(hitRecord.normal);
        }
    }
        
    [rt/integrators/NormalDebugIntegratorFactory.java]= 
    package rt.integrators;
    import rt.*;
    public class NormalDebugIntegratorFactory extends IntegratorFactory {
        public Integrator make(Scene scene) {return new NormalDebugIntegrator(scene);}
    }
<h4>Intersectable Id</h4>
    <additional intersectable methods and data>+=
    public Spectrum id = Spectrum.randomBright();
    
    [rt/integrators/IntersectableIdDebugIntegrator.java]= 
    package rt.integrators;
    <common imports>
    public class IntersectableIdDebugIntegrator extends DebugIntegrator {
        public IntersectableIdDebugIntegrator(Scene scene) {super(scene);}

        public Spectrum integrate(Ray r) {
            <get first intersection with scene>
            return hitRecord.intersectable.id;
        }
    }
        
    [rt/integrators/IntersectableIdDebugIntegratorFactory.java]= 
    package rt.integrators;
    import rt.*;
    public class IntersectableIdDebugIntegratorFactory extends IntegratorFactory {
        public Integrator make(Scene scene) {return new IntersectableIdDebugIntegrator(scene);}
    }
    
<h3>Material Based Integrators</h3>
All of the more complex integrators give more complex color output derived from 
data and surface properties assigned to the objects and dependent on other objects in the scene.
They use secondary rays starting at the first intersection point to 
obtain information about the environment.

<h4>Surface Materials</h4>
Recall that our hit reccord only records the Intersectable that was hit so far.
To create nice images with possibly repeated objects sharing their appearance,
objects of the scenes are assigned so called materials 
which give parameters and algorithms for 'shading'
(that is, computing the color of) the corresponding surface.

    <additional intersectable methods and data>+=
    public Material material = null;
    
    public void setMaterial(Material m) {
        this.material = m;
        for (Intersectable i : this) { 
            i.setMaterial(m);
        }
    }
    
    <unit tests>+=
    @Test
    public void testMeshMaterial() {
        Mesh mesh = ObjReader.read("obj/teapot.obj", 1.f);
        Material mat = new Diffuse();
        mesh.setMaterial(mat);
        Matrix4f t = new Matrix4f();
        t.setIdentity();
        
        t.setScale(0.5f);
        t.setTranslation(new Vector3f(0.f, -0.35f, 0.f));
        Instance instance = new Instance(mesh, t);
        
        HitRecord h = instance.intersect(new Ray(new Vector3f(0.f,0.f,2.f),new Vector3f(0.f,0.f,-1.f)));
        
        assertTrue(h != null);
        assertTrue(h.intersectable != null);
        assertTrue(h.intersectable.material != null);
        assertEquals(mat, h.intersectable.material);
    }
    
    @Test
    public void testMeshMaterial2() {
        Mesh mesh = ObjReader.read("obj/teapot.obj", 1.f);
        Matrix4f m = new Matrix4f();
        m.setIdentity();
        Instance instance = new Instance(mesh, m);
        
        Material mat = new Diffuse();
        instance.setMaterial(mat);
        
        for (Intersectable i : mesh)
            assertEquals(mat, i.material);
    }
    
    @Test
    public void testMeshMaterial3() {
        try {
            Instance instance = new Instance(new CSGXYPlane(), new Matrix4f());
        }
        catch (SingularMatrixException e) {
            return;
        }
        assertTrue(false);
    }
        
    [rt/Material.java]= 
    package rt;
    <common imports>
    public abstract class Material {
        <material methods and data>
    }
    
<h5>Material Id Debug Integrator</h5>
This assignment immediately gives raise to an alternative to the intersectable id integrator:
We can visualize the material id (if present)
    <material methods and data>+=
    public Spectrum id = Spectrum.randomBright();
    
    [rt/integrators/MaterialIdDebugIntegrator.java]= 
    package rt.integrators;
    <common imports>
    public class MaterialIdDebugIntegrator extends DebugIntegrator {
        public MaterialIdDebugIntegrator(Scene scene) {super(scene);}

        public Spectrum integrate(Ray r) {
            <get first intersection with scene>
            if (hitRecord.intersectable.material == null)
                return Integrator.ERROR2;
            return hitRecord.intersectable.material.id;
        }
    }
        
    [rt/integrators/MaterialIdDebugIntegratorFactory.java]= 
    package rt.integrators;
    <common imports>
    public class MaterialIdDebugIntegratorFactory extends IntegratorFactory {
        public Integrator make(Scene scene) {return new MaterialIdDebugIntegrator(scene);}
    }

<h4>Material Shading</h4>
A material's job is to give a color for a given hitRecord. 
It may also refer back to the Integrator to cast more rays.
To stop this process from recursing indefinitely, we impose a maximum recursion limit
and keep track of recursion depth. If the limit is reached, we return black.
    <recursion depth limit>=
    5
<p>
If you happen to be familiar with (realtime) computer graphics, the 'shade' function 
is basically supposed to do what a pixel shader does. 
Only with vastly extended capabilities.
    <material methods and data>+=
    public Spectrum shade(HitRecord hitRecord, Integrator integrator) {
        return shade(hitRecord, integrator, 0);
    }
    public abstract Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth);
    
    <integrator methods>+=
    public Spectrum integrate(Ray r, int depth) {throw new RuntimeException(this.getClass() + " does not implement integrate with depth (recursive)");}
    
<h5>Material Integrator</h5>
Everything an integrator for materials has to do is call the shade method.
    [rt/integrators/MaterialIntegrator.java]= 
    package rt.integrators;
    <common imports>
    public class MaterialIntegrator extends Integrator {
        public MaterialIntegrator(Scene scene) {super(scene);}

        public Spectrum integrate(Ray r) {
            return integrate(r, 0);
        }
        
        public Spectrum integrate(Ray r, int depth) {
            if (depth > <recursion depth limit>) return new Spectrum();
        
            <get first intersection with scene>
            if (hitRecord.intersectable.material == null)
                return Integrator.ERROR2;
            return hitRecord.intersectable.material.shade(hitRecord, this, depth+1);
        }
        
    }
        
    [rt/integrators/MaterialIntegratorFactory.java]= 
    package rt.integrators;
    <common imports>
    public class MaterialIntegratorFactory extends IntegratorFactory {
        public Integrator make(Scene scene) {return new MaterialIntegrator(scene);}
    }

<h5>Debug Materials</h5>
We could for example outsource what the debug integrators do to a material shader:
<h4>Position Debug</h4>
Same result as DebugIntegrator.
    [rt/materials/DebugMaterial.java]= 
    package rt.materials;
    <common imports>
    public class DebugMaterial extends Material {
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            return DebugIntegrator.positionToColor(hitRecord.position());
        }
    }
<h4>Normal Debug</h4>
Same result as NormalDebugIntegrator.
    [rt/materials/NormalDebugMaterial.java]= 
    package rt.materials;
    <common imports>
    public class NormalDebugMaterial extends Material {
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            return NormalDebugIntegrator.normalToColor(hitRecord.normal);
        }
    }
<h4>Intersectable Id</h4>
    [rt/materials/IntersectableIdDebugMaterial.java]= 
    package rt.materials;
    <common imports>
    public class IntersectableIdDebugMaterial extends Material {
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            return hitRecord.intersectable.id;
        }
    }
<h4>Material Id</h4>
    [rt/materials/MaterialIdDebugMaterial.java]= 
    package rt.materials;
    <common imports>
    public class MaterialIdDebugMaterial extends Material {
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            return id;
        }
    } 
    
<h4>XYZGrid</h4>
Instead of converting 3d positions to color continuously, we can modulo them to get 
a grid pattern.
    <math utilities>+=
    public static float modf(float x, float d) {
        float y = x % d;
        if (y < 0) y = d + y;
        return y;
    }
    
    <unit tests>+=
    @Test
    public void testModf() {
        assertEquals(.05f,M.modf(1.05f,0.1f), 0.0001f);
        assertEquals(.05f,M.modf(-1.05f,0.1f),0.0001f);
        
        assertEquals(0.2f,M.modf(0.2f,1.f),0.0001f);
    }
    
    [rt/materials/XYZGrid.java]= 
    package rt.materials;
    <common imports>
    public class XYZGrid extends Material {
        Spectrum lineColor, backgroundColor;
        Vector3f offset, lineThickness, backgroundRep;

        public XYZGrid() {
            this(
                new Spectrum(0.2f, 0.f, 0.f), 
                new Vector3f(0.1f, 0.1f, 0.1f),
                new Spectrum(1.f, 1.f, 1.f), 
                new Vector3f(0.3f, 0.3f, 0.3f),
                new Vector3f());
        }
        public XYZGrid(
                Spectrum lineColor, 
                Vector3f lineThickness,
                
                Spectrum backgroundColor, 
                Vector3f backgroundRep,
                
                Vector3f offset) {
            this.backgroundColor = new Spectrum(backgroundColor);
            this.lineColor = new Spectrum(lineColor);
            this.offset = new Vector3f(offset);
            this.backgroundRep = new Vector3f(backgroundRep);
            this.lineThickness = new Vector3f(lineThickness);
        }
        
        private boolean c(float x, float p, float d) {
            return M.modf(x, d) < p;
        }
        
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            if (c(hitRecord.position().x + offset.x, lineThickness.x, backgroundRep.x) 
             || c(hitRecord.position().y + offset.y, lineThickness.y, backgroundRep.y) 
             || c(hitRecord.position().z + offset.z, lineThickness.z, backgroundRep.z))
                return new Spectrum(lineColor);
            return new Spectrum(backgroundColor);
        }

    }
    
        
    <unit tests>+=
    @Test
    public void testXYZGrid() {
        Material m = new XYZGrid(
            new Spectrum(0),
            new Vector3f(0.1f,0.1f,0.1f),
            new Spectrum(1),
            new Vector3f(1.f,1.f,1.f),
            
            new Vector3f()
        );
        
        Spectrum s = m.shade(
            new HitRecord(
                new Ray(new Vector3f(),new Vector3f(0.2f,0.2f,0.2f)), 
                1.f, 
                new CSGXYPlane(),
                new Vector3f(1,0,0)
                ), null, 0);
        
        assertEquals(1.f, s.r, 0.0001f);
        
        s = m.shade(
            new HitRecord(
                new Ray(new Vector3f(),new Vector3f(0.05f,0.2f,0.2f)), 
                1.f, 
                new CSGXYPlane(),
                new Vector3f(1,0,0)
                ), null, 0);
        
        assertEquals(0.f, s.r, 0.0001f);
    }
    
    @Test
    public void testXYZGrid2() {
        Material m = new XYZGrid(
                new Spectrum(1,0,0), 
                new Vector3f(0.1f,0.1f,0.1f),
                new Spectrum(1), 
                new Vector3f(1,1,1),
            
            new Vector3f()
        );
        
        Spectrum s = m.shade(
            new HitRecord(
                new Ray(new Vector3f(),new Vector3f(0.2f,0.2f,0.2f)), 
                1.f, 
                new CSGXYPlane(),
                new Vector3f(1,0,0)
                ), null);
        
        assertEquals(1.f, s.g, 0.0001f);
        
        s = m.shade(
            new HitRecord(
                new Ray(new Vector3f(),new Vector3f(0.05f,0.2f,0.2f)), 
                1.f, 
                new CSGXYPlane(),
                new Vector3f(1,0,0)
                ), null);
        
        assertEquals(0.f, s.g, 0.0001f);
    }
<h4>Light Transport Simulation</h4>
Interesting and more (photo) realistic images are obtained once we add 
a true simulation of light and light-transport to the scene.

<h5>Distinction of light sources</h5>
Some of the techniques illustrated below require that we 
can distinguish between objects that 
emit light into the scene from those which do not.
We also need to be able to enumerate all of these.
We can achieve this by simply adding a flag to intersectables and collecting 
those intersectables with the flag set into a list of "light sources".
    <additional intersectable methods and data>+=
    public boolean isLight = false;
    
    <additional scene data>+=
        protected IntersectableList lightList;
        public IntersectableList getLightList() {
            if (lightList != null) return lightList;
            lightList = new IntersectableList();
            addToLightList(lightList, root);
            return lightList;
        }
        private void addToLightList(IntersectableList l, Intersectable i) {
            assert l != null;
            assert i != null : "addToLightList: i must be non null";
            if (i.isLight) l.add(i);
            
            for (Intersectable j : i) 
                addToLightList(l, j);
        }

We have to precompute this before running, otherwise the multiple integrators will 
get 'concurrent modification conflicts' for redefining it from different threads (the scene is shared!).
    <scene preparation tasks>+=
    getLightList();
    
<h5>Direct lighting, simple shading, no sampling</h5>
For the following simple approach to shading simulation with point lights 
traditionally used in realtime computer graphics, it is useful to add the following 
terminology:
<ul>
<li>w points away from the surface, in the direction opposite to that of the incident ray,
i.e. it points towards the observer (eye).
    <hit record datastructure>+=
        public Vector3f w() {return M.normalize(M.negate(ray.direction));}
<li>
    [rt/intersectables/Point.java]= 
    package rt.intersectables;
    <common imports>
    public class Point extends Intersectable {
        public Vector3f position;
        public Point(Vector3f position) {
            this.position = new Vector3f(position);
        }
        public HitRecord intersect(Ray r) {return null;}
    }
<li>
    [rt/lightsources/PointLight.java]= 
    package rt.lightsources;
    <common imports>
    public class PointLight extends Point {
        public Spectrum emission;        
        public PointLight(Vector3f position, Spectrum emission)
        {
            super(position);
            this.emission = emission;
            this.isLight = true;
        }
    }
    
<li>
    [rt/lightsources/AreaLight.java]= 
    package rt.lightsources;
    <common imports>
	public class AreaLight extends Rectangle {
		public Spectrum emission;
		public AreaLight(Vector3f a, Vector3f da, Vector3f db, Spectrum emission)
		{
			super(a,da,db);
            this.emission = emission;
            this.isLight = true;
		}
	}
    
Given a two dimensional random uniformly distributed sample in (0,1)^2,
this should return a uniformly sampled location on the surface of the intersectable.
    <additional intersectable methods and data>+=
        public Vector3f sample(float[] s) {
            throw new RuntimeException(this.getClass() + " does not implement sample() method");
        }

This is easy to implement for a rectangle:
    
        <additional rectangle methods>+=
        public Vector3f sample(float[] s) {
            assert s.length == 2;
            assert s[0] >= 0 && s[1] <= 1;
            return M.add(a, M.add(M.scale(s[0], da), M.scale(s[1], db)));
        }
        
We also need the area to figure out the probability density
    <additional intersectable methods and data>+=
        public float area() {
            throw new RuntimeException(this.getClass() + " does not implement area() method");
        }

This is easy to implement for a rectangle:
    
        <additional rectangle methods>+=
        public float area() {
            return da.length()*db.length();
        }
        
        <unit tests>+=
        @Test
        public void testRect() {
            Rectangle r = new Rectangle(new Vector3f(), new Vector3f(1,0,0),
            new Vector3f(0,1,0));
            assertEqualsX(1 ,r.area());
            Vector3f s = r.sample(
                new RandomSampler().makeSamples(1,2)[0]
                );
            assert s.x >= 0 && s.x <= 1;
            
            assert s.y >= 0 && s.y <= 1;
            
            assertEqualsX(0, s.z);
        }
</ul>

<h6>Lambert Diffuse + Blinn Specular</h6>
This lighting model is completely additive.
<img src=shade.png></img>
The formula for a single light source thus translates to:
    <blinn evaluate brdf>=
    private Spectrum evaluateBlinnPhong(Vector3f n, Vector3f e, Vector3f L) {
        Vector3f h = <unit halfway vector>;
        return 
            new Spectrum(kd).mult(M.clamp(L.dot(n))).add(
            new Spectrum(ks).mult(M.powf (h.dot(n), s))
        );
    }
    <unit halfway vector>=
        M.normalize(M.add(L, e))
        
ks is the specular color, which is white for most real materials.
s is the shininess parameter.
The power deposited per area by and isotropic point light source decreases with 1/r^2,
and the color of the light source simply multiplies with whatever is reflected.
    <compute contribution s of lightsource l>=
    Vector3f lightDir = M.sub(lightPos, hitRecord.position());
    float r2 = M.normalizeAndGetLength(lightDir);
    r2 *= r2;
    
    Spectrum s = evaluateBlinnPhong(hitRecord.normal, hitRecord.w(), lightDir); 
    s.mult(l.emission);
    s.mult(1.f/r2);
    
<h7>Hard Shadows</h7>
We also add to the integrator the possibility to determine the (mutual) visibility v(a, b) 
between two points a and b. 
    <integrator methods>+=
    public HitRecord visibilityIntersect(Vector3f a, Vector3f b) {
        Vector3f d = M.sub(b, a);
        HitRecord shadowHit = scene.getIntersectable().intersect(Ray.biased(a, d));
        if (shadowHit == null || <hit after b>) return null;
        return shadowHit;
    }
    
    public boolean mutuallyVisible(Vector3f a, Vector3f b) {
        return visibilityIntersect(a,b) == null;
    }
    
    <hit after b>=
    shadowHit.t > 1.f
    
Where
    <ray methods>+=
    private static final float BIAS = 0.0001f; // 0.000001f is not enough for floats!
    public static Ray biased(Vector3f o, Vector3f d) {
        return new Ray(M.t(o, d, BIAS), d);
    }
    <unit tests>+=
    @Test
    public void testRayBiased() {
        Vector3f x = new Vector3f(1,2,3);
        assertTrue (x.equals(new Ray(x,x).origin));
        assertFalse(x.equals(Ray.biased(x,x).origin));
    }
   
avoids "shadow acne".
    <shadow test>=
    if (!integrator.mutuallyVisible(hitRecord.position(), lightPos)) 
        continue;
    
    [rt/materials/Blinn.java]= 
    package rt.materials;
    <common imports>
    public class Blinn extends Material {
        float s;
        Spectrum ks;
        Spectrum kd;
        public Blinn(Spectrum kd, Spectrum ks, float s) {
            this.kd = kd; this.ks = ks; this.s = s;
        }
        
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            return shade(kd, hitRecord, integrator, depth);
        }
        
        <blinn evaluate brdf>
        
        public Spectrum shade(Spectrum kd, HitRecord hitRecord, Integrator integrator, int depth) {
            Spectrum outgoing = new Spectrum();    
            
            for (Intersectable i : integrator.scene.getLightList()) {
                if (!(i instanceof PointLight)) continue;
                PointLight l = (PointLight)i;
                Vector3f lightPos = l.position;
                <shadow test>
                <compute contribution s of lightsource l>
                
                outgoing.add(s);
            }
            
            return outgoing;
        }
    }
for reasons that will become apparant in the next slide, the diffuse color is a parameter to 
the shade method.

Diffuse term only
    [rt/materials/Diffuse.java]= 
    package rt.materials;
    <common imports>
    public class Diffuse extends Blinn {
        public Diffuse(Spectrum kd) {
            super(kd, new Spectrum(), 1.f);
        }
        public Diffuse() {this(new Spectrum(1.f));}
    }
    
Take the diffuse term from some other material's shading function and multiply:
    [rt/materials/DiffuseFrom.java]= 
    package rt.materials;
    <common imports>
    public class DiffuseFrom extends MultiplyMaterial {
        public DiffuseFrom(Material m, Spectrum kd) {
            super(new Diffuse(kd), m);
        }
        public DiffuseFrom(Material m) {
            this(m, new Spectrum(1.f));
        }
    }

    [rt/materials/MultiplyMaterial.java]= 
    package rt.materials;
    <common imports>
    public class MultiplyMaterial extends Diffuse {
        Material m1, m2;
        public MultiplyMaterial(Material m1, Material m2) {
            this.m1 = m1; this.m2 = m2;
        }
        
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            Spectrum kd = m1.shade(hitRecord, integrator, depth);
            Spectrum mkd = m2.shade(hitRecord, integrator, depth);
            return mkd.mult(kd);
        }
    }
    
<h7>Blinn sample scene</h7>
Simple scene using a Blinn material.    
<img src="output/rt.testscenes.BlinnTest.png"></img>
    [rt/testscenes/BlinnTest.java]= 
    package rt.testscenes;
    <common imports>
    public class BlinnTest extends PinholeCameraScene {
        public PointLight pl1, pl2;
        public BlinnTest()
        {
            setDimensions(512,512);
            setSPP(1);
            Vector3f eye = new Vector3f(0.f, 0.f, 3.f);
            Vector3f lookAt = new Vector3f(0.f, 0.f, 0.f);
            setCamera(eye, lookAt, <up vector>);
            
            // Specify which integrator and sampler to use
            integratorFactory = new MaterialIntegratorFactory();
            samplerFactory = new OneSamplerFactory();

            // Ground plane
            CSGPlane groundPlane = new CSGPlane(new Vector3f(0.f, 1.f, 0.f), 1.f);
            groundPlane.setMaterial(
                new Blinn(new Spectrum(1.f), new Spectrum(.4f, .4f, .4f), 50.f)
            );
            // Sphere with Blinn material
            CSGSphere sphere = new CSGSphere();
            sphere.setMaterial(
                new Blinn(new Spectrum(.8f, 0.f, 0.f), new Spectrum(.4f, .4f, .4f), 50.f)
            );
            
            // Light sources
            pl1 = new PointLight(new Vector3f(.5f, .5f, 2.f), new Spectrum(1.f, 1.f, 1.f));
            pl2 = new PointLight(new Vector3f(-.75f, .75f, 2.f), new Spectrum(1.f, 1.f, 1.f));
            
            root = new IntersectableList().add(groundPlane, sphere, pl1, pl2);
        }
    }
    <test scenes>+=
    new BlinnTest(),
    <unit tests>+=
    @Test 
    public void testBlinnTest2() {
        assertImgEquals(
            "output/rt.testscenes.BlinnTest.png", 
            "testimages/rt.testscenes.BlinnTest.png"
        );
    }
    
    <unit tests>+=
    @Test
    public void testBlinnTest() {
        BlinnTest b = new BlinnTest();
        assertTrue(b.getLightList().contains(b.pl1));
        assertTrue(b.getLightList().contains(b.pl2));
    }
    
<h7>ShadowScene</h7>
In the following scenes, we have a backplane at z=
    <backplane z>=
    -3.15f
    
and a groundplane at y
    <groundplane y>=
    -1.6f
    
The sphere in the center is at the origin and the camera at 0,0,5.

The light sources are at y = 3, z = 2 and shifted left and right:
    <some light sources>=
    PointLight pointLight1 = new PointLight(
        new Vector3f(-1.f, 3.f, 2.f), 
        new Spectrum(44.f));
    PointLight pointLight2 = new PointLight(
        new Vector3f(1.f, 3.f, 2.f),
        new Spectrum(44.f));
    
<img src="output/rt.testscenes.ShadowScene.png"></img>
    [rt/testscenes/ShadowScene.java]= 
    package rt.testscenes;
    <common imports>
    public class ShadowScene extends PinholeCameraScene {
        public ShadowScene()
        {
            super(new Vector3f(0.f, 0.f, 5.f));
            setDimensions(512);
            integratorFactory = new MaterialIntegratorFactory();
            
            <lit ground and back plane>
            
            CSGSphere sph = new CSGSphere();
            sph.setMaterial(
            new Blinn(new Spectrum(.08f, 0.f, 0.f), new Spectrum(.4f, .4f, .4f), 50.f)
            );
            <some light sources>
            root =  new IntersectableList(
                groundPlane,
                backPlane,
                sph,
                pointLight1,
                pointLight2
                );
        }
    }
    <test scenes>+=
    new ShadowScene(),
    
    <unit tests>+=
    @Test 
    public void testShadowScene() {
        assertImgEquals(
            "output/rt.testscenes.ShadowScene.png", 
            "testimages/rt.testscenes.ShadowScene.png"
        );
    } 
    
    <ground and back plane>=
    Material grid = new XYZGrid(
        new Spectrum(0.2f, 0.f, 0.f),
        new Vector3f(0.1f, 0.1f, 0.1f),
        new Spectrum(1.f, 1.f, 1.f), 
        new Vector3f(0.3f, 0.3f, 0.3f),
        
        new Vector3f());
    CSGPlane groundPlane = new CSGPlane(new Vector3f(0.f, 1.f, 0.f), - <groundplane y>);
    groundPlane.setMaterial(grid);
    CSGPlane backPlane = new CSGPlane(new Vector3f(0.f, 0.f, 1.f), - <backplane z>);
    backPlane.setMaterial(grid);
    
    <lit ground and back plane>=
    <ground and back plane>
    grid = new DiffuseFrom(grid);
    groundPlane.setMaterial(grid);
    backPlane.setMaterial(grid);

    
<h6>Reflection</h6>
As a simple variant, we can determine the diffuse color by reflecting the incoming 
direction on the surface normal and looking up the color there.
This gives mirror-like reflection.

    <hit record datastructure>+=
    public Vector3f reflectedW() { return M.reflect(normal, w()); }
    
    [rt/materials/Reflective.java]= 
    package rt.materials;
    <common imports>
    public class Reflective extends Material {
        public Spectrum evaluateReflection(HitRecord hitRecord, Integrator integrator, int depth) {
            Vector3f d = hitRecord.reflectedW();
            <evaluate spectrum in direction d>
        }
        
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            return evaluateReflection(hitRecord, integrator, depth);
        }
    }
    
    <evaluate spectrum in direction d>=
        assert hitRecord.ray != null : "ray must be non-null";
        assert hitRecord.position() != null : "hitRecord.position() must be non-null";
        assert d != null : "d must be non-null";
        return integrator.integrate(Ray.biased(hitRecord.position(), d), depth);
        
<h4>ReflectionScene</h4>
<img src="output/rt.testscenes.ReflectionScene.png"></img>
    [rt/testscenes/ReflectionScene.java]= 
    package rt.testscenes;
    <common imports>
    public class ReflectionScene extends PinholeCameraScene {
        public ReflectionScene() {
            super(new Vector3f(0.f, 0.f, 5.f));
            setDimensions(1024);
            setSPP(32);
            integratorFactory = new MaterialIntegratorFactory();
            <lit ground and back plane>

            CSGSphere sph = new CSGSphere();
            sph.setMaterial(new Reflective());
            
            CSGSphere sph2 = new CSGSphere(new Vector3f(2.f, 0, 0));
            sph2.setMaterial(new Diffuse());
            
            CSGSphere sph3 = new CSGSphere(new Vector3f(-2.f, 0, 0));
            sph3.setMaterial(new DiffuseFrom(new Reflective()));
            
            <some light sources>
            root = new IntersectableList(
                groundPlane,
                backPlane,
                sph,sph2,sph3,
                pointLight1,
                pointLight2
                );
        }
    }
    <beautiful scenes>+=
    new ReflectionScene(),

<h6>Refraction</h6>
We can also look up the diffuse color by casting a ray through the surface of the object, 
distroting its direction according to snell's law of refraction
<h7>The 'Hit Plane'</h7>    
For constructing rays that lie within the plane 
spanned by the normal and the incident direction 
w (call this the hit plane), it is useful to have the surface's
tangent that lies in this plane. 
We call this vector ipt and compute it on-demand.
    <hit record datastructure>+=
        private Vector3f ipt;
        private void updateIpt() {
            assert normal != null : "normal must be non-null";
            Vector3f cnw = M.cross(normal, w()); 
            ipt = cnw; ipt.cross(normal, cnw);
            ipt.normalize();
        }
        
ipt and the normal then form a cartesian coordinate system on the hit plane, on which we can now construct arbitrary points.
    <hit record datastructure>+=
        public Vector3f hitPlanePoint(float x, float y) {
            updateIpt();
            Vector3f r = M.scale(x, ipt);
            r.add(M.scale(y, normal));
            return r;
        }
        
We can of course give these in polar coordinates.
    <hit record datastructure>+=
        public Vector3f hitPlanePointPolar(float ang, float len) {
            return hitPlanePoint((float)Math.cos(ang)*len, (float)Math.sin(ang)*len);
        }
        public Vector3f hitPlanePointPolar(float ang) {
            return hitPlanePointPolar(ang, 1.f);
        }
        
This will be used for refraction.
In the following image, the black arrow is the surface normal, red is cnw, green is ipt, purple is w. 
In blue, we show a vector constructed using polar coordinates on the ipt-normal plane (hit plane).
<img src=refex.png></img>

    <unit tests>+=
    @Test
    public void testHitPlanePointPolar() {
        HitRecord h = new HitRecord(
            new Ray(new Vector3f(), new Vector3f(1.f, -1.f, 0)), 
            0, 
            new CSGUnitSphere(),
            new Vector3f(0.f, 1.f, 0)
        );
        Vector3f o = h.hitPlanePointPolar(M.PI/4.f);
        assertEquals(0.707107f, o.x, 0.0001f);
        assertEquals(0.707107f, o.y, 0.0001f);
        assertEquals(0, o.z, 0.0001f);
    }
    
    @Test
    public void testHitPlanePointPolar2() {
        HitRecord h = new HitRecord(
            new Ray(new Vector3f(), new Vector3f(1.f, 1.f, 0)), 
            0, new CSGUnitSphere(),
            new Vector3f(0.f, 1.f, 0)
        );
        Vector3f o = h.hitPlanePointPolar(M.PI/4.f);
        assertEquals(0.707107f, o.x, 0.0001f);
        assertEquals(0.707107f, o.y, 0.0001f);
        assertEquals(0, o.z, 0.0001f);
    }

To determine the refracted angle, 
we need to be able to tell the incident angle.
    <hit record datastructure>+=
    public float angleToNormal(Vector3f v) {
        v = M.normalize(v);
        assert normal != null : "normal must be non-null";
        double a = (double)v.dot(normal);
        return (float)Math.acos(a);
    }
Computes the angle between the given vector and the normal of the surface, 
assuming both vectors point to the same hemisphere.
v need not be normalized.
    <unit tests>+=
    @Test
    public void testAngleToNormal() {
        HitRecord h = new HitRecord(
            new Ray(new Vector3f(), new Vector3f(1,0,0)), 
            0, new CSGUnitSphere(), new Vector3f(1.f, 0, 0));
        float w = h.angleToNormal(new Vector3f(1.f, 1.f, 0));
        assertEquals(Math.PI/4.f, w, 0.0001f);
    }
<h7>Refraction angle in physics</h7>
In physics, the „amount“ of refraction of a material is characterized by its refractive index n. 
As a parameter for our surface material here, n is the refractive index of the medium below the surface (pointing in the direction of the normal) using this material.
Refraction is computed using the incoming angle of the light and the refractive indices on both sides of the surface according to Snell’s law:
<img src=snell.png></img>

    <define refraction>=
    public Vector3f getRefractionDirection(HitRecord hitRecord) {
        <determine incoming angle>
        <determine medium and adjust angle>
        
        // TODO these should really hold...
        //assert th1 >= 0 && th1 <= M.PI/2 : "th1 must be in 0, pi/2, was "+th1;
        float a = (float)Math.sin(th1)*n1/n2;
        
        <check total internal reflection>
        float th2 = (float)Math.asin(a);
        //assert th2 >= 0 && th2 <= M.PI/2 : "th2 must be in 0, pi/2, was "+th1;
        <compute thout>

        return hitRecord.hitPlanePointPolar(thout);
    }
    
We only use the ‚direction‘ value of the ShadingSample (I have no idea what the rest is for).
We make this method return null if there should be total internal reflection.
    <check total internal reflection>=
    if (a > 1) return null; 
We also have
    <determine incoming angle>=
    float th1 = hitRecord.angleToNormal(hitRecord.w());
and
    <determine medium and adjust angle>=
    float n1, n2;
    boolean leaving = false;
    if (th1 > Math.PI/2) { // leaving medium 
        n1 = n; n2 = 1.f;
        th1 = (float)Math.PI - th1;
        leaving = true;
    } else {
        n1 = 1.f; n2 = n;
    }

determines whether we are leaving or entering the medium represented by this material’s n and sets n1 and n2 accordingly. The „outside“ medium is assumed to be air (vacuum actually).

<p>
The „outgoing angle“ thout is measured, by definition of the .hitPlanePointPolar method, relative to the +x axis in the ipt, n coordinate system in the hit-plane. This is the line surrounded by n1, v1, n2, v2 in the above picture. Since th2 is measured against the normal (or against -normal if we are entering the medium) we need to adjust accordingly 
    <compute thout>=
    float thout = leaving ? (M.PI/2 - th2) : (-M.PI/2 + th2);
    
In the following image, the black arrow is the surface normal, green is ipt (green, black form the x and y axis of the coordinate system against which thout is measured), red is cnw, purple is w (see definition of hitPlanePointPolar). 
Blue is the refracted vector.
<img src=refex.png></img>
If w comes from the direction opposite to the normal, the angle of the refracted vector must be measured against the non-inverted normal.
<img src=refex2.png></img>
<h8>Test Refraction</h8>
Let us refract a ray coming from -1,-1,0 on the yz plane at a surface with refractive index 2.
    <unit tests>+=
    @Test
    public void testRefract() {
        HitRecord h = new HitRecord(
            new Ray(new Vector3f(), M.negate(
                new Vector3f(1.f, 1.f, 0) // to camera
            )),
            0.f,
            new CSGUnitSphere(),
            new Vector3f(1.f, 0.f, 0)
        );
        Refractive m = new Refractive(2.f);
        
        Vector3f o = m.getRefractionDirection(h);
        
        assertEquals(-0.935414f, o.x, 0.0001f);
        assertEquals(-0.353553f, o.y, 0.0001f);
        assertEquals(o.z, 0, 0.0001f);
    }
    
    @Test
    public void testRefract2() {
        HitRecord h = new HitRecord(
            new Ray(new Vector3f(), M.negate(
                new Vector3f(-1.f, 1.f, 0) // to camera
            )),
            0.f,
            new CSGUnitSphere(),
            new Vector3f(1.f, 0.f, 0)
        );
        Refractive m = new Refractive(1.3f);
        
        Vector3f o = m.getRefractionDirection(h);
         
        assertEquals(0.3937f, o.x, 0.0001f);
        assertEquals(-0.919239f, o.y, 0.0001f);
        assertEquals(o.z, 0, 0.0001f);
    }
    @Test
    public void testRefract3() {
        HitRecord h = new HitRecord(
            new Ray(new Vector3f(), M.negate(
                new Vector3f(-0.309017f, 0.951057f, 0.f) // to camera
            )),
            0.f,
            new CSGUnitSphere(),
            new Vector3f(1.f, 0.f, 0)
        );
        Refractive m = new Refractive(1.3f);
        
        Vector3f o = m.getRefractionDirection(h);
        assertEquals(null, o);
    }
    
    
<h7>Refractive Material</h7>
Returns black on total internal reflection.
    [rt/materials/Refractive.java]= 
    package rt.materials;
    <common imports>
    public class Refractive extends Reflective {
        float n;
        public Refractive(float n) {
            this.n = n;
        }
        
        <define refraction>
        
        public Spectrum evaluateRefraction(HitRecord hitRecord, Integrator integrator, int depth) {
            Vector3f d = getRefractionDirection(hitRecord);
            if (d == null) return new Spectrum();
            <evaluate spectrum in direction d>
        }
        
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            return evaluateRefraction(hitRecord, integrator, depth);
        }
    }
    
    
<img src="output/rt.testscenes.RefractionScene.png"></img>
    [rt/testscenes/RefractionScene.java]= 
    package rt.testscenes;
    <common imports>
    public class RefractionScene extends PinholeCameraScene {
        public RefractionScene()
        {
            super(new Vector3f(0.f, 3.f, 1.f));
            setDimensions(512);
            integratorFactory = new MaterialIntegratorFactory();
            <lit ground and back plane>
            
            CSGSphere sph = new CSGSphere();
            sph.setMaterial(new Refractive(1.03f));
            
            <some light sources>
            root =  new IntersectableList(
                groundPlane,
                backPlane,
                sph,
                pointLight1,
                pointLight2
                );
        }
    }
    <test scenes>+=
    new RefractionScene(),
    
    <unit tests>+=
    @Test 
    public void testRefractionScene() {
        assertImgEquals(
            "output/rt.testscenes.RefractionScene.png", 
            "testimages/rt.testscenes.RefractionScene.png"
        );
    } 

<img src="output/rt.testscenes.RefractionScene2.png"></img>
    [rt/testscenes/RefractionScene2.java]= 
    package rt.testscenes;
    <common imports>
    public class RefractionScene2 extends PinholeCameraScene {
        public RefractionScene2()
        {
            super(new Vector3f(0.f, 0.f, 5.f));
            setDimensions(512);
            integratorFactory = new MaterialIntegratorFactory();
            <ground and back plane>
            
            CSGPlane a = new CSGPlane(new Vector3f(0,0,1.f),0);
            a.setMaterial(new Refractive(1.3f));
            CSGPlane b = new CSGPlane(new Vector3f(1.f,0,0),0);
            b.setMaterial(new Refractive(1.3f));
            
            root =  new IntersectableList(
                groundPlane,
                backPlane,
                CSGNode.intersect(a,b)
                );
        }
    }
    <beautiful scenes>+=
    new RefractionScene2(),
    
Test scene with a refractive glass block.
Features a background plane with a debug world position material:
    <construct backplane>=
    CSGPlane backPlane = new CSGPlane(new Vector3f(0.f, 1.f, 0.f), -0.2f);
    backPlane.setMaterial(new XYZGrid());
and a glass block occupying half of it (notice that plane-origin offsets are given in the direction opposite to the normal)
    <construct glassblock>=
    Material refractive = new Refractive(1.3f);
    CSGSolid glassblock = CSGNode.intersect(
        new CSGPlane(new Vector3f(0.f, 1.f, 0.f), -1.f),
        new CSGPlane(new Vector3f(0.f, -1.f, 0.f), 0.5f),
        new CSGPlane(new Vector3f(1.f, 0.f, 0.f), 0.f)
        );
    glassblock.setMaterial(refractive);
    
<img src=glassplane.JPG></img>
<img src="output/rt.testscenes.RefractiveGlassplane.png"></img>    
    [rt/testscenes/RefractiveGlassplane.java]= 
    package rt.testscenes;
    <common imports>
    public class RefractiveGlassplane extends PinholeCameraScene {
        public RefractiveGlassplane()
        {
            super(new Vector3f(0.f, 3.f, 3.f));
            setDimensions(512);
            
            integratorFactory = new MaterialIntegratorFactory();
            
            <construct backplane>
            <construct glassblock>
            
            root = new IntersectableList().add(
                backPlane,
                glassblock
                );
        }
        
    }
    <beautiful scenes>+=
    new RefractiveGlassplane(),
    
By the way, when you place the back plane, which is using an xyz grid material exactly at 0, it will get strange patterns caused by numerical inaccuracies. (It should theoretically be all red).
<img src="output/rt.testscenes.RefractiveGlassplane2.png"></img>    
    [rt/testscenes/RefractiveGlassplane2.java]= 
    package rt.testscenes;
    <common imports>
    public class RefractiveGlassplane2 extends PinholeCameraScene {
        public RefractiveGlassplane2()
        {
            super(new Vector3f(0.f, 3.f, 3.f));
            setDimensions(512);
            
            integratorFactory = new MaterialIntegratorFactory();
            
    CSGPlane backPlane = new CSGPlane(new Vector3f(0.f, 1.f, 0.f), 0.f);
    backPlane.setMaterial(new XYZGrid());
            <construct glassblock>
            
            root = new IntersectableList().add(
                backPlane,
                glassblock
                );
        }
        
    }
    <beautiful scenes>+=
    new RefractiveGlassplane2(),
    <unit tests>+=
    @Test 
    public void testRefractiveGlassplane2() {
        assertImgEquals(
            "output/rt.testscenes.RefractiveGlassplane2.png", 
            "testimages/rt.testscenes.RefractiveGlassplane2.png"
        );
    }
    
<h6>Fresnel</h6>
Natural transparent materials (glass, water) reflect part of the light
and refract part of it, depending 
on the angle of incidence (among other factors).
Fresnel gave the following approximation for these fractions:
<img src=fresnel.png></img>
    <schlick fresnel factor>=
    public float schlickF(HitRecord hitRecord) {
        <determine incoming angle>
        <determine medium and adjust angle>
            
        float f = (1-n1/n2)*(1-n1/n2) / ((1+n1/n2)*(1+n1/n2));
        float F = f + (1-f)*M.powf(1-hitRecord.w().dot(hitRecord.normal), 5);
        assert 0 <= F && F <= 1 : "bad F "+F;
        return F;
    }
This gives the interpolation factor in [0,1] to be used between the 
reflected and refracted color.
    [rt/materials/Fresnel.java]= 
    package rt.materials;
    <common imports>
    public class Fresnel extends Material {
        float n;
        public Fresnel(float n) {
            this.n = n;
        }
        <schlick fresnel factor>
        
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            return new Spectrum(schlickF(hitRecord));
        }
    }
In the following image, white means fully reflective, black fully refractive.
<img src="output/rt.testscenes.FresnelTest.png"></img>
    [rt/testscenes/FresnelTest.java]= 
    package rt.testscenes;
    <common imports>
    public class FresnelTest extends ObjectTest {
        public FresnelTest()
        {
            super(new Vector3f(3.f, 0.f, 3.f));
            root = new CSGUnitSphere();
            
            integratorFactory = new MaterialIntegratorFactory();
            root.setMaterial(new Fresnel(1.3f));
        }
    }
    <test scenes>+=
    new FresnelTest(),
    
    [rt/materials/FresnelReflectRefract.java]= 
    package rt.materials;
    <common imports>
    public class FresnelReflectRefract extends MixMaterials {
        public FresnelReflectRefract(float n) {
            super(new Reflective(), new Refractive(n), new Fresnel(n));
        }
    }
    
    
<h4>Physically based material, sampling</h4>
<h5>Area Light Importance Sampling</h5>
    <compute contribution s of area lightsource l>=
    Vector3f lightDir = M.sub(lightPos, hitRecord.position());
    float r2 = M.normalizeAndGetLength(lightDir);
    r2 *= r2;
    
    
                float cospsi = -lightDir.dot(l.n);
    
    Spectrum s = new Spectrum(hitRecord.normal.dot(lightDir)); 
    s.mult(l.emission);
    s.mult(cospsi);
    s.mult(1.f/r2);
    
    [rt/materials/MaterialArealightSample.java]= 
    package rt.materials;
    <common imports>
    public class MaterialArealightSample extends Material {
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            Spectrum outgoing = new Spectrum();    
            
            for (Intersectable i : integrator.scene.getLightList()) {
                if (!(i instanceof AreaLight)) continue;
                AreaLight l = (AreaLight)i;
                
                
    Vector3f lightPos = l.sample(integrator.make2dSample());
                <shadow test>
                <compute contribution s of area lightsource l>
                
                outgoing.add(s);
            }
            
            return outgoing;
        }
    } 
    
<h4>AreaLightScene</h4>
<img src="output/rt.testscenes.AreaLightScene 32SPP.png"></img>
	[rt/testscenes/AreaLightScene.java]= 
	package rt.testscenes;
	<common imports>
	public class AreaLightScene extends PinholeCameraScene {
		public AreaLightScene()
		{
			super(new Vector3f(0.f, 0.f, 5.f));
			setDimensions(512);
            setSPP(32);
			integratorFactory = new MaterialIntegratorFactory();
			
            // Arealight requires random samples
            samplerFactory = new RandomSamplerFactory();
            
            <ground and back plane>
            Material m = new MaterialArealightSample();
            
            
            Intersectable sph = 
				new CSGSphere();
                
    groundPlane.setMaterial(m);
    backPlane.setMaterial(m);
    sph.setMaterial(m);
			
			root =  new IntersectableList().add(
				groundPlane,
				backPlane,sph,
                
                new AreaLight(
                new Vector3f(0,3.f,0), 
                new Vector3f(4.f,0,0), 
                new Vector3f(0,4.f,0), 
                new Spectrum(80.f))
				);
		}
	}
	<beautiful scenes>+=
	new AreaLightScene(),
 
	


        
<h5>BRDF Importance Sampling</h5>
    [rt/materials/MaterialSampleCos.java]= 
    package rt.materials;
    <common imports>
    public class MaterialSampleCos extends Material {
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
        Vector3f d = integrator.sampler.sampleCosDistributionHemisphere();
        
        d = M.xyzAroundNormal(d, hitRecord.normal);
        
        <evaluate spectrum in direction d>
        
        }
    } 
    
        
<img src="output/rt.testscenes.PBCosScene.png"></img>
    [rt/testscenes/PBCosScene.java]= 
    package rt.testscenes;
    <common imports>
    public class PBCosScene extends PinholeCameraScene {
        public PBCosScene()
        {
            super(new Vector3f(0.f, 3.f, 1.f));
            setDimensions(512);
            integratorFactory = new MaterialIntegratorFactory();
            samplerFactory = new RandomSamplerFactory();
            
            <ground and back plane>
            groundPlane.setMaterial(new MaterialSampleCos());
            backPlane.setMaterial(new MaterialSampleCos());
            
            CSGSphere sph = new CSGSphere();
            sph.setMaterial(new DebugMaterial());
            
            root =  new IntersectableList(
                groundPlane,
                backPlane,
                sph
                );
        }
    }
    <test scenes>+=
    new PBCosScene(),
<h5>Uniform Sampling</h5>
    [rt/materials/MaterialSampleUniform.java]= 
    package rt.materials;
    <common imports>
    public class MaterialSampleUniform extends Material {
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
        Vector3f d = integrator.sampler.sampleHemisphere();
        assert integrator.sampler.sampleHemisphere().x != d.x : "random sampling broken";
        d = M.xyzAroundNormal(d, hitRecord.normal);
        
        <evaluate spectrum in direction d>
        
        }
    } 
    
    <math utilities>+=
    // z translates to normal, others are measured in tangent plane to n
    public static Vector3f xyzAroundNormal(Vector3f d, Vector3f n) {
        Vector3f t1 = M.tangentTo(n);
        Vector3f t2 = M.cross(n, t1);
        float x = d.x, y = d.y, z = d.z;
        
        Vector3f out = new Vector3f(n);
        out.scale(z);
        
        t1.scale(x); t2.scale(y);
        
        out.add(t1); out.add(t2);
        
        return out;
    }
    <unit tests>+=
    
    @Test
    public void testxyzAroundNormal() {
        // no change for normal z
        Vector3f n = new Vector3f(0,0,1);
        
        Vector3f d = new Vector3f(0,0,1);
        assertEquals(
            d,
            M.xyzAroundNormal(d, n)
            
            );
        
        assertEquals(n, new Vector3f(0,0,1));
        
        // z becomes x
        
        // no change for normal z
        n = new Vector3f(1,0,0);
        
        d = new Vector3f(0,0,1);
        assertEquals(
            new Vector3f(1,0,0),
            M.xyzAroundNormal(d, n)
            );
            
        // translate a hemisphere sample to point in y direction
        d = new RandomSampler().sampleHemisphere();
        
        n = new Vector3f(0,1,0);
        Vector3f o = M.xyzAroundNormal(d, n);
        assert o.y >= 0;
        assert M.isApproxUnitvector(o);
        assert o.y != 1;
        assert o.x >= -1 && o.x <= 1;
        assert o.y >= -1 && o.y <= 1;
    }
    
        
<img src="output/rt.testscenes.PBScene.png"></img>
    [rt/testscenes/PBScene.java]= 
    package rt.testscenes;
    <common imports>
    public class PBScene extends PinholeCameraScene {
        public PBScene()
        {
            super(new Vector3f(0.f, 3.f, 1.f));
            setDimensions(512);
            integratorFactory = new MaterialIntegratorFactory();
            samplerFactory = new RandomSamplerFactory();
            
            <ground and back plane>
            groundPlane.setMaterial(new MaterialSampleUniform());
            backPlane.setMaterial(new MaterialSampleUniform());
            
            CSGSphere sph = new CSGSphere();
            sph.setMaterial(new DebugMaterial());
            
            root =  new IntersectableList(
                groundPlane,
                backPlane,
                sph
                );
        }
    }
    <test scenes>+=
    new PBScene(),
    <unit tests>+=
    @Test 
    public void testSamHemiPBScene() {
    Scene s;
        Sampler ms = (s=new PBScene()).getIntegratorFactory().make(s).sampler;
        Vector3f h = ms.sampleHemisphere();
        assertEqualsX(1, h.length());
        
        Vector3f h2 = ms.sampleHemisphere();
        assertEqualsX(1, h2.length());
        
        assertNotEqualsX(h, h2);
    }
    
<h3>Mix Materials</h3>
Like the opengl mix function, this mixes between two materials
based on a third one that should give values between 0 and 1.
If it is 1 we return the first, if 0 the second material.
    [rt/materials/MixMaterials.java]= 
    package rt.materials;
    <common imports>
    public class MixMaterials extends Material {
        Material m1, m2, blend;
        public MixMaterials(Material m1, Material m2, Material blend) {
            this.m1 = m1; this.m2 = m2; this.blend = blend;
        }
        
        public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            Spectrum a = m1.shade(hitRecord, integrator, depth);
            Spectrum b = m2.shade(hitRecord, integrator, depth);
            <mix colors a and b>
            return a.add(b);
        }
    }
    
    <mix colors a and b>=
    Spectrum s = blend.shade(hitRecord, integrator, depth);
    a.mult(s);
    b.mult(new Spectrum(1-s.r,1-s.g,1-s.b));
    
<h2>Sampler</h2>
Samplers make random samples, which are used for Monte Carlo rendering. The 
samples always need to lie in the range [0,1]. Various versions such 
as purely random, jittered, or low discrepancy samplers could be 
implemented.
<p>
makeSamples makes an array of samples. The samples need to lie in the range [0,1]^d,
where d is the dimensionality of the samples.
    <make samples>=
    public abstract float[][] makeSamples(int n, int d);  
    [rt/Sampler.java]= 
    package rt;
    <common imports>
    public abstract class Sampler {
        <make samples>
        <sampler methods>
    }
        
    [rt/SamplerFactory.java]= 
    package rt;
    <common imports>
    public interface SamplerFactory {
        public Sampler make();
    }
<h3>Uniform Disk sampling</h3>
    <sampler methods>+=
     public float[] sampleUnitDisk() {
        float[] xi = makeSamples(1,2)[0];
        
        return new float[] {
            M.cosf(2 * M.PI * xi[1]) * M.sqrtf(xi[0]),
            M.sinf(2 * M.PI * xi[1]) * M.sqrtf(xi[0])
        };
    }
    
    <unit tests>+=
    @Test 
    public void testDisk() {
        float f[] = new RandomSampler().sampleUnitDisk();
        assertEquals(2, f.length);
        assertTrue(
            f[1]*f[1]+f[0]*f[0]
            <= 1
        );
    }
    @Test 
    public void testDisk2() {
        int bin[] = {0,0};
        for (int i = 0; i < 10000; i++) {
            float f[] = new RandomSampler().sampleUnitDisk();
            if (f[0] > 0 && f[1] > 0) bin[0]++;
            if (f[0] < 0 && f[1] < 0) bin[1]++;
        }
        assert Math.abs(bin[0] - bin[1]) < 2000;
    }
    
<h3>Uniform Hemisphere sampling</h3>
From <a href=http://stackoverflow.com/a/7280889/524504>here</a>.
    <sampler methods>+=
     public Vector3f sampleHemisphere() {
     
        float[] xi = makeSamples(1,2)[0];
        
        float azimuthal = 2 * M.PI * xi[0];
        float z = xi[1];
        
        float xyproj = M.sqrtf(1 - z*z);
        return new Vector3f(
            M.cosf(azimuthal) * xyproj,
            M.sinf(azimuthal) * xyproj,
            z
        );
    }
    
    <unit tests>+=
    @Test 
    public void testSamHemi() {
        Vector3f h = new RandomSampler().sampleHemisphere();
        assertEqualsX(1, h.length());
        
        Vector3f h2 = new RandomSampler().sampleHemisphere();
        assertEqualsX(1, h2.length());
        
        assertNotEqualsX(h, h2);
    }
    
<h3>Cosine distribution hemisphere sampling</h3>
   <sampler methods>+=
    public Vector3f sampleCosDistributionHemisphere() {
        float[] xi = makeSamples(1,2)[0];
        
        return new Vector3f(
            M.cosf(2 * M.PI * xi[1]) * M.sqrtf(xi[0]),
            M.sinf(2 * M.PI * xi[1]) * M.sqrtf(xi[0]),
            M.sqrtf(1 - xi[0])
        );
    }
    
    <unit tests>+=
    @Test 
    public void testSamHemiCos() {
        Vector3f h = new RandomSampler().sampleCosDistributionHemisphere();
        assertEqualsX(1, h.length());
        
        Vector3f h2 = new RandomSampler().sampleCosDistributionHemisphere();
        assertEqualsX(1, h2.length());
        
        assertNotEqualsX(h, h2);
    }
    
    
    @Test 
    public void testSamHemiCosDistr() {
        // partition into n bins,
        int n = 20;
        float bin[] = new float[n];
        int N = 10*1000;
        for (int i = 0; i < N; i++) {
            Vector3f h = new RandomSampler().sampleCosDistributionHemisphere();
            
            float costheta = h.dot(new Vector3f(0,0,1));
            bin[ (int)Math.floor((double)costheta * (double)n)]++;
        }
        
        for (int j = 0; j < n; j++) {
            float ct = (float)j/n;
            out("testSamHemiCosDistr "  + bin[j]/N);
            assertEqualsX(M.cosf(ct), bin[j]/N);
        }
    }
    
<h3>OneSampler</h3>
Returns always one sample at 0.5 in all dimensions.
    [rt/samplers/OneSampler.java]= 
    package rt.samplers;

    <common imports>

    public class OneSampler extends Sampler {        
        public float[][] makeSamples(int n, int d)
        {
            float[][] samples = new float[1][d];
            for(int i=0; i<d; i++)
                samples[0][i] = 0.5f;
            
            return samples;
        }
    }
        
    [rt/samplers/OneSamplerFactory.java]= 
    package rt.samplers;

    <common imports>
    public class OneSamplerFactory implements SamplerFactory {
        public Sampler make() {return new OneSampler();}
    }
        
<h3>RandomSampler</h3>
Makes uniform random samples in the range [0,1].
    [rt/samplers/RandomSampler.java]= 
    package rt.samplers;

    <common imports>
    public class RandomSampler extends Sampler {
        Random random = new Random();
        public float[][] makeSamples(int n, int d)
        {
            float samples[][] = new float[n][d];
            
            for(int i=0; i<n; i++) for(int j=0; j<d; j++) {
                samples[i][j] = random.nextFloat();
            }
            return samples;
        }
        
    }
        
    [rt/samplers/RandomSamplerFactory.java]= 
    package rt.samplers;
    <common imports>
    public class RandomSamplerFactory implements SamplerFactory {
        public Sampler make() {return new RandomSampler();}
    }
    
    
<h2>Film</h2>
This and the next section are concerned with the pseudocode
    set pixel color
of the basic raytracing algorithm.
<p>
A film captures the samples generated for (sub) pixels
    <add sample>=
    public void addSample(double x, double y, Spectrum s);
and accretes them in discrete pixels, much like a photo sensor in a digital camera integrates
the light arriving at the square shaped sensors.
The final image is a rectangular array of light spectra.
    <retrieve array>=
    public Spectrum[][] getImage();
    public int getWidth();
    public int getHeight();
    
So a film stores a 2D grid of Spectrum representing an image.
Rendered samples can be added one by one to a film. Samples are
filtered using some filter (depending on the implementation of this 
interface) when added.
    [rt/Film.java]= 
    package rt;
    public interface Film {
        <add sample>
        <retrieve array>
    }
    
<h3>BoxFilterFilm</h3>    
This film uses a box filter when accumulating samples on a film.
A box filter means that samples s contribute only to the pixel (x,y) that they lie in.
    <add sample to film>=
    int idx_x = (int)x;
    int idx_y = (int)y;
    
    unnormalized[idx_x][idx_y].add(s);
    nSamples[idx_x][idx_y]++;
    
Sample values are simply averaged for the final image.
    <average sample values>=
    image[i][j] = new Spectrum(unnormalized[i][j]).mult(1.f/nSamples[i][j]);

    [rt/films/BoxFilterFilm.java]= 
    package rt.films;
    <common imports>
    public class BoxFilterFilm implements Film {
        private Spectrum[][] image;
        public int width, height;
        private Spectrum[][] unnormalized;
        private float nSamples[][];
        
        public BoxFilterFilm(int width, int height)
        {
            this.width = width;
            this.height = height;
            image = new Spectrum[width][height];
            unnormalized = new Spectrum[width][height];
            nSamples = new float[width][height];
            
            for(int i=0; i<width; i++) for(int j=0; j<height; j++) {
                image[i][j] = new Spectrum();
                unnormalized[i][j] = new Spectrum();
            }
        }
        
        public void addSample(double x, double y, Spectrum s)
        {
            if((int)x>=0 && (int)x<width && (int)y>=0 && (int)y<height) {
                <add sample to film>
            }
        }
        
        public int getWidth() {return width;}
        public int getHeight() {return height;}
        
        public Spectrum[][] getImage()
        {
            for(int i=0; i<width; i++) for(int j=0; j<height; j++) {
                <average sample values>
            }
            return image;
        }
    }
        
<h2>Tonemapper</h2>
A Tonemapper compresses a raw rendered Film to an image that can be displayed on typical 8-bit displays.
    [rt/Tonemapper.java]= 
    package rt;
    <common imports>

    public interface Tonemapper {
        BufferedImage process(Film film);
    }
    
Tone maps a film by clamping all color channels to range [0,1].
    <do clamping>=
    Spectrum s = filmImg[i][j].clamp();
    
Then we convert these to 24 bit (24 bpp) 8-bit per channel colors.
    <convert spectrum to rgb integer>=
     ((int)(255.f*s.r) << 16) 
    | ((int)(255.f*s.g) << 8) 
    | ((int)(255.f*s.b))
    
    [rt/tonemappers/ClampTonemapper.java]= 
    package rt.tonemappers;
    
    <common imports>

    public class ClampTonemapper implements Tonemapper {
        public BufferedImage process(Film film)
        {
            BufferedImage img = new BufferedImage(film.getWidth(), film.getHeight(), BufferedImage.TYPE_3BYTE_BGR);
            
            Spectrum[][] filmImg = film.getImage();
            for(int i=0; i<film.getWidth(); i++) for(int j=0; j<film.getHeight(); j++) {
                <do clamping>
                
                img.setRGB(i, film.getHeight()-1-j, 
                    <convert spectrum to rgb integer>
                );
            }
            return img;
        }
    }

<h2>Test Scenes</h2>
<h3>Rendered Scenes</h3>

The following class encapsulates some defaults shared by most scenes.
    [rt/basicscenes/AbstractScene.java]= 
    package rt.basicscenes;
    <common imports>
    public abstract class AbstractScene extends Scene {
        public void setDimensions(int w, int h) {
            width = w; height = h;
            film = new BoxFilterFilm(width, height);
            camera = new FixedCamera(width, height);
        }
        
        public void setDimensions(int wh) {
            setDimensions(wh, wh);
        }
        
        public void setSPP(int s) {
            SPP = s;
            if (s > 1) samplerFactory = new RandomSamplerFactory();
            else samplerFactory = new OneSamplerFactory();
        }
        
        public AbstractScene() {
            setDimensions(512);
            setSPP(1);
            integratorFactory = new NormalDebugIntegratorFactory();
            tonemapper = new ClampTonemapper();
            samplerFactory = new OneSamplerFactory();
        }
    }
        
Here are two tests demonstrating that the FixedCamera works:
<img src="output/rt.basicscenes.Box.png"></img>
    [rt/basicscenes/Box.java]= 
    package rt.basicscenes;
    <common imports>
    public class Box extends AbstractScene {
        public Box() {
            root = new CSGCappedZTunnel();
        }
    }
    <test scenes>+=
    new Box(),
    <unit tests>+=
    @Test 
    public void testBox() {
        assertImgEquals(
            ImageReader.read("output/rt.basicscenes.Box.png"), 
            ImageReader.read("testimages/rt.basicscenes.Box 1SPP.png")
        );
    }
        
<img src="output/rt.basicscenes.Dodecahedron.png"></img>
    [rt/basicscenes/Dodecahedron.java]= 
    package rt.basicscenes;
    <common imports>
    public class Dodecahedron extends AbstractScene {
        public Dodecahedron()
        {
            root = CSGNode.add(
                new CSGPlane(new Vector3f(0.f, 1.f, 0.f), 1.f),
                new CSGPlane(new Vector3f(0.f, 0.f, 1.f), 1.f),
                new CSGDodecahedron()
            );
        }
    }    
    <test scenes>+=
    new Dodecahedron(),
    
    [rt/testscenes/PinholeCameraScene.java]= 
    package rt.testscenes;
    <common imports>
    public abstract class PinholeCameraScene extends AbstractScene {
        public Vector3f eye, lookAt, up;
        
        public void setDimensions(int w, int h) {
            super.setDimensions(w, h);
            setCamera(eye == null ? new Vector3f() : eye, 
                    lookAt == null ? new Vector3f() : lookAt, 
                            up == null ? new Vector3f() : up);
        }
        
        public PinholeCameraScene() {}
        public PinholeCameraScene(Vector3f eye) {setCamera(eye, new Vector3f(), <up vector>);}
        
        public void setCamera(Vector3f eye,
                Vector3f lookAt,
                Vector3f up) {
            this.eye = eye;
            this.lookAt = lookAt;
            this.up = up;
            float verticalFovInDegrees = 60.f;
            float aspect = (width * 1.f)/height;
            camera = new PinholeCamera(eye, lookAt, up, verticalFovInDegrees, aspect, width, height);
        }
    }
            
A test baseclass for objects that looks at the origin and uses the debug integrator
    [rt/testscenes/ObjectTest.java]= 
    package rt.testscenes;
    <common imports>
    public abstract class ObjectTest extends PinholeCameraScene {
        public ObjectTest() {this(new Vector3f());}
        public ObjectTest(Vector3f eye) {
            setCamera(eye, new Vector3f(), <up vector>);
            integratorFactory = new DebugIntegratorFactory();
        }
    }
Same thing but with the normal debug integrator.
    [rt/testscenes/ObjectNormalTest.java]= 
    package rt.testscenes;
    <common imports>
    public abstract class ObjectNormalTest extends ObjectTest {
        public ObjectNormalTest() {this(new Vector3f());}
        public ObjectNormalTest(Vector3f eye) {
            super(eye);
            integratorFactory = new NormalDebugIntegratorFactory();
        }
    }
    [rt/testscenes/ObjectIdTest.java]= 
    package rt.testscenes;
    <common imports>
    public abstract class ObjectIdTest extends PinholeCameraScene {
        public ObjectIdTest() {this(new Vector3f());}
        public ObjectIdTest(Vector3f eye) {
            setCamera(eye, new Vector3f(), <up vector>);
            integratorFactory = new IntersectableIdDebugIntegratorFactory();
        }
    }
Test scene for pinhole camera specifications.
<img src="output/rt.testscenes.CameraTestScene.png"></img>
    [rt/testscenes/CameraTestScene.java]= 
    package rt.testscenes;
    <common imports>
    public class CameraTestScene extends ObjectNormalTest {
        public CameraTestScene()
        {
            setDimensions(1280, 720);
            Vector3f eye = new Vector3f(0.5f, 0.5f, 3.f);
            Vector3f lookAt = new Vector3f(0.5f, 0.f, 0.f);
            Vector3f up = new Vector3f(0.2f, 1.f, 0.f);
            setCamera(eye, lookAt, up);
            root = new CSGCappedZTunnel();
        }
    }
    <test scenes>+=
    new CameraTestScene(),

    <unit tests>+=
    @Test 
    public void testCameraTestScene() {
        assertImgEquals(
            ImageReader.read("output/rt.testscenes.CameraTestScene.png"), 
            ImageReader.read("testimages/rt.testscenes.CameraTestScene 1SPP.png")
        );
    }
    
<h4>CSGScene</h4>
<img src="output/rt.testscenes.CSGScene.png"></img>
    [rt/testscenes/CSGScene.java]= 
    package rt.testscenes;
    <common imports>
    public class CSGScene extends PinholeCameraScene {
        public CSGScene()
        {
            setSPP(32);
            setDimensions(640, 360);

            Vector3f eye = new Vector3f(0.f, 0.f, 5.f);
            Vector3f lookAt = new Vector3f(0.f, -.5f, 0.f);
            setCamera(eye, lookAt, <up vector>);
            
            integratorFactory = new MaterialIntegratorFactory();
            
            Material refractive = new Refractive(1.3f);
            
            // Make a conical "bowl" by subtracting cross-sections of two cones
            CSGSolid outerCone = coneCrossSection(60.f);
            // Make an inner cone and subtract it
            Matrix4f trafo = new Matrix4f();
            trafo.setIdentity();
            trafo.setTranslation(new Vector3f(0.f, 0.f, 0.25f));
            CSGInstance innerCone = new CSGInstance(outerCone, trafo);        
            CSGSolid doubleCone = new CSGNode(outerCone, innerCone, CSGNode.OperationType.SUBTRACT);
            
            // Place it in the scene
            Matrix4f rot = new Matrix4f();
            rot.setIdentity();
            rot.rotX(-(float)Math.PI/2.f);
            Matrix4f trans = new Matrix4f();
            trans.setIdentity();
            trans.setTranslation(new Vector3f(-1.5f, -1.5f, 0.f));
            trans.mul(rot);        
            doubleCone = new CSGInstance(doubleCone, trans);
            doubleCone.setMaterial(refractive); 
            
            // Something like a"soap bar"
            Material yellow = new Diffuse(new Spectrum(1.f, 0.8f, 0.2f));
            CSGSolid soap = new CSGUnitCylinder();
            CSGSolid cap = new CSGTwoSidedInfiniteCone();
            // Smoothen the edges
            trans.setIdentity();
            trans.m23 = -0.8f;
            CSGSolid cap1 = new CSGInstance(cap, trans); 
            soap = new CSGNode(soap, cap1, CSGNode.OperationType.INTERSECT);
            trans.m23 = 1.8f;
            CSGSolid cap2 = new CSGInstance(cap, trans); 
            soap = new CSGNode(soap, cap2, CSGNode.OperationType.INTERSECT);
            
            // Transform it and place it in the scene
            Matrix4f scale = new Matrix4f();
            // Make it elliptical and rotate a bit around the cylinder axis
            scale.setIdentity();
            scale.m11 = 0.5f;
            scale.m22 = 0.5f;
            trafo = new Matrix4f();
            trafo.rotZ((float)Math.toRadians(-20));
            trafo.mul(scale);
            // Rotate it "up"
            rot = new Matrix4f();
            rot.setIdentity();
            rot.rotX(-(float)Math.PI/2.f);        
            rot.mul(trafo);
            // Place in scene by translating
            trans = new Matrix4f();
            trans.setIdentity();
            trans.setTranslation(new Vector3f(1.5f, -1.5f, 1.f));
            trans.mul(rot);
            soap = new CSGInstance(soap, trans);
            soap.setMaterial(yellow);
            
            // Ground and back plane
            Material grid = new DiffuseFrom(new XYZGrid(
                new Spectrum(0.2f, 0.f, 0.f), 
                new Vector3f(0.1f, 0.1f, 0.1f),
                new Spectrum(1.f, 1.f, 1.f), 
                new Vector3f(0.3f, 0.3f, 0.3f),
                new Vector3f()));
            
            CSGPlane groundPlane = new CSGPlane(new Vector3f(0.f, 1.f, 0.f), 1.51f);
            groundPlane.setMaterial(grid);
            CSGPlane backPlane = new CSGPlane(new Vector3f(0.f, 0.f, 1.f), 3.15f);
            backPlane.setMaterial(grid);        
            
            // Sphere
            CSGSphere sph = new CSGSphere();
            sph.setMaterial(new Refractive(1.01f));
            
            // Set the root node for the scene
            <some light sources>
            root =  new IntersectableList().add(
                
                groundPlane,
                backPlane,
                
                doubleCone,
                soap,
                
                sph,
                
                pointLight1,
                pointLight2
                );
            
            
        }
        
        <cone cross section>
    }
    <beautiful scenes>+=
    new CSGScene(),
    
Where
    <cone cross section>=
    private CSGSolid coneCrossSection(float a)
    {
        // Makes a two-sided infinite cone with apex angle 90 degrees
        CSGTwoSidedInfiniteCone doubleCone = new CSGTwoSidedInfiniteCone();
        // Scaling factor along the cone axis corresponding to apex angle
        float s = (float)Math.tan((90-a/2)/180.f*(float)Math.PI);
        
        // Scale and translate cone
        Matrix4f scale = new Matrix4f();
        scale.setIdentity();
        scale.m22 = s;
        Matrix4f trans = new Matrix4f();
        trans.setIdentity();
        trans.setTranslation(new Vector3f(0.f, 0.f, -s));
        trans.mul(scale);
        CSGInstance scaledCone = new CSGInstance(doubleCone, trans);
        
        // Cut off at z=0 and z=1
        return CSGNode.intersect(
            scaledCone, 
            new CSGPlane(new Vector3f(0.f, 0.f, -1.f), 0.f),
            new CSGPlane(new Vector3f(0.f, 0.f, 1.f), -1.f)
        );
    }
Makes a "horizontal" cross section through a cone with apex angle a (in degrees).
The bottom plane is at z=0, the top at z=1. The radius of the bottom circle 
in the cross section is one (the top circle is bigger depending on the apex angle).
<img src=ccs.jpg></img>


    
<h4>Refractive Sphere</h4>
Test scene for refractive objects, renders a sphere in front of a planar background.
<img src="output/rt.testscenes.RefractiveSphere.png"></img>    
    [rt/testscenes/RefractiveSphere.java]= 
    package rt.testscenes;
    <common imports>
    public class RefractiveSphere extends PinholeCameraScene {
            
        public RefractiveSphere()
        {
            setDimensions(512);
            setSPP(32);
            
            // Specify which camera, film, and tonemapper to use
            Vector3f eye = new Vector3f(0.f, 0.f, 3.f);
            Vector3f lookAt = new Vector3f(0.f, 0.f, 0.f);
            setCamera(eye, lookAt, <up vector>);
            
            // Specify which integrator and sampler to use
            integratorFactory = new MaterialIntegratorFactory();
            samplerFactory = new RandomSamplerFactory();        
            
            Material refractive = new Refractive(1.3f);

            
            // Ground and back plane
            // A grid with red and white lines, 
            // line thickness 0.01, zero offset shift, and tile size 0.125, all in world coordinates
            XYZGrid grid = new XYZGrid(
                new Spectrum(0.2f, 0.f, 0.f), 
                new Vector3f(0.01f, 0.01f, 0.01f), 
                new Spectrum(1.f, 1.f, 1.f), 
                new Vector3f(0.125f,0.125f,0.125f),
                new Vector3f(0.f, 0.f, 0.f));
            CSGPlane backPlane = new CSGPlane(new Vector3f(0.f, 0.f, 1.f), 3.15f);
            backPlane.setMaterial(grid);
            
            // A sphere for testing
            CSGSphere sphere = new CSGSphere();
            sphere.setMaterial(refractive);
            
            // Collect objects in intersectable list
            root = new IntersectableList(
            sphere, backPlane);

        }
        
    }
    <beautiful scenes>+=
    new RefractiveSphere(),
   
<h4>InstancingTeapots</h4>
<img src="output/rt.testscenes.InstancingTeapots.png"></img>
    [rt/testscenes/InstancingTeapots.java]= 
    package rt.testscenes;
    <common imports>
    public class InstancingTeapots extends PinholeCameraScene {
        public InstancingTeapots()
        {    
            super(new Vector3f(0.f,0.f,2.f));
            setDimensions(256);
            integratorFactory = new MaterialIntegratorFactory();
            // List of objects
            IntersectableList objects = new IntersectableList();    
                    
            // Box
            CSGPlane plane = new CSGPlane(new Vector3f(0.f, 1.f, 0.f), 1.f);
            plane.setMaterial(new Diffuse(new Spectrum(0.f, 0.8f, 0.8f)));
            objects.add(plane);        
            
            plane = new CSGPlane(new Vector3f(0.f, 0.f, 1.f), 1.f);
            plane.setMaterial(new Diffuse(new Spectrum(0.3f, 0.8f, 0.8f)));
            objects.add(plane);
            
            plane = new CSGPlane(new Vector3f(-1.f, 0.f, 0.f), 1.f);
            plane.setMaterial(new Diffuse(new Spectrum(1.f, 0.8f, 0.8f)));
            objects.add(plane);
            
            plane = new CSGPlane(new Vector3f(1.f, 0.f, 0.f), 1.f);
            plane.setMaterial(new Diffuse(new Spectrum(0.f, 0.8f, 0.0f)));
            objects.add(plane);
            
            plane = new CSGPlane(new Vector3f(0.f, -1.f, 0.f), 1.f);
            plane.setMaterial(new Diffuse(new Spectrum(0.8f, 0.8f, 0.8f)));
            objects.add(plane);
            
            // Add objects
            Mesh mesh = ObjReader.read("obj/teapot.obj", 1.f);
            mesh.setMaterial(new Diffuse());
            Matrix4f t = new Matrix4f();
            t.setIdentity();
            
            // Instance one
            t.setScale(0.5f);
            t.setTranslation(new Vector3f(0.f, -0.35f, 0.f));
            Instance instance = new Instance(mesh, t);
            objects.add(instance);    
            
            
            // TODO this should not be necessary
            instance.setMaterial(new Diffuse());
            
            // Instance two
            t.setScale(0.5f);
            t.setTranslation(new Vector3f(0.f, 0.25f, 0.f));
            Matrix4f rot = new Matrix4f();
            rot.setIdentity();
            rot.rotX((float)Math.toRadians(30.f));
            t.mul(rot);
            instance = new Instance(mesh, t);
            objects.add(instance);
                    
            // TODO this should not be necessary
            instance.setMaterial(new Diffuse());
            
            // List of lights
            PointLight light = new PointLight(new Vector3f(0.f,0.8f,0.8f), new Spectrum(3.f, 3.f, 3.f));
            objects.add(light);
            
            light = new PointLight(new Vector3f(-0.8f,0.2f,1.f), new Spectrum(1.5f, 1.5f, 1.5f));
            objects.add(light);        
            
            root = objects;
        }
    }
    <beautiful scenes>+=
    new InstancingTeapots(),
        
<h2>Appendix: Utilities</h2>
The dot product can be used to determine whether two vectors n and d lie in the same halfspace:
<img src=dothalfspace.JPG></img>
    <determine halfspace>=
    public static boolean sameHalfspace(Vector3f n, Vector3f d) {
        return n.dot(d) > 0;
    }
    <unit tests>+=
    @Test 
    public void testsameHalfspace() {
        assertTrue(M.sameHalfspace(new Vector3f(1,0,0), new Vector3f(1,1,1)));
        assertFalse(M.sameHalfspace(new Vector3f(1,0,0), new Vector3f(-1,-1,0)));
    }
    
The following function computes ray-sphere intersection times 
(<a href=http://sci.tuomastonteri.fi/programming/sse/example3>source</a>
). 
Note: we can return all hit points,
also the ones with negative t-value, that is, points that lie "behind"
the origin of the ray.
Use dFac -1 to solve for first, 1 for second hitpoint.
    <ray sphere intersection>=
        public static float intersectSphere(Vector3f center, float radius, Ray r, float dFac) {
            float a = r.direction.dot(r.direction); // Squared length of ray direction vector. > 0.
            float b = r.direction.dot(M.scale(2.0f, M.sub(r.origin, center)));
            float c = center.dot(center) + r.origin.dot(r.origin) 
                    - 2.0f*r.origin.dot(center)
                    - radius*radius;
            // ^^ end of vector stuff
            
            // Discriminant of quadratic equation.
            float D = b*b + (-4.0f)*a*c;
            
            // If ray can not intersect then stop
            if (D < 0) return Float.NEGATIVE_INFINITY;
            D = (float)Math.sqrt(D);

            // Ray can intersect the sphere, solve the closer hitpoint (negative D)
            float a2 = 2 * a;
            float t = -b/a2 + dFac*D/a2;
            return t;
        }
    
We can easily compute tangents to a given normal.    
The first tangent is obtained by taking the cross product of the normal with an arbitrarily chosen vector.
    <math utilities>+=
    public static Vector3f tangentTo(Vector3f normal) {
        Vector3f t1 = new Vector3f(1,0,0);
        t1.cross(t1, normal);
        <correct tangent failure>
        t1.normalize();
        return t1;
    }
In the unlikely case that the normal and this vector happened to point in the same direction (such that the area of their parallelogram and thus the length of the cross product is 0), take another one.
    <correct tangent failure>=
        if (t1.length() == 0) {
            t1 = new Vector3f(0,1,0);
            t1.cross(t1, normal);
        }
        
    <unit tests>+=
    @Test 
    public void testMinMax() {
        assertEqualsX(1.f, M.min(1,2,3));
        assertEqualsX(1.f, M.max(1,-2,-3));
        
    }
    
    @Test 
    public void testPlaneIntersection() {
        float f = M.intersectPlane(new Ray(new Vector3f(0,0,1), new Vector3f(0,0,-1)),
            new Vector3f(0,0,1),
            0.f);
        assertEqualsX(1, f);
        
        assert new Vector3f(0,0,1).dot(new Vector3f(0,1,0)) == 0;
        f =  M.intersectPlane(
            new Ray(new Vector3f(0,0,1), new Vector3f(0,1,0)), // start at z in direction w
            new Vector3f(0,0,1), 0.f // xy plane
            );
            out("testPlaneIntersection "+f);
        assertTrue(Float.NaN == f);
        
        f =  M.intersectPlane(
            new Ray(new Vector3f(0,1,0), new Vector3f(0,-1,0)),
            new Vector3f(0,1,0),
            1.f);
        assertEqualsX(2, f);
    }
    
    [rt/M.java]= 
    package rt;
    <common imports>
    public class M {
        public static final float PI = (float)Math.PI;
        
        <ray sphere intersection>
        
        /**
		 * Computes ray-plane intersection. 
		 * 
		 * Note: we return all hit points,
		 * also the ones with negative t-value, that is, points that lie "behind"
		 * the origin of the ray. This is necessary for CSG operations to work
		 * correctly!  
		 * 
		 * @param r the ray
		 * @return the hit record of the intersection point, or null 
		 */
		public static float intersectPlane(Ray r, Vector3f normal, float d) {

			float tmp = normal.dot(r.direction);
			
			if (tmp!=0)
			{
				// t parameter of hit point
				float t = -(normal.dot(r.origin) + d) / tmp;
				
				return t;
			}
            return Float.NaN;
		}
        
        <determine halfspace>
        
        public static float min(float... f) {
            float m = Float.MAX_VALUE;
            for (float x : f) 
                m = Math.min(m, x);
            return m;
        }
        
        public static float max(float... f) {
            float m = Float.MIN_VALUE;
            for (float x : f) 
                m = Math.max(m, x);
            return m;
        }
        
        public static Vector3f reflect(Vector3f normal, Vector3f d) {
            return M.sub(M.scale(2 * d.dot(normal), normal), d);
        }
        
        public static Vector3f normalizedTowards(Vector3f from, Vector3f to) {
            return M.normalize(M.sub(to, from));
        }
        
        /** Squared distance between v1 and v2, ||v1 - v2||^2 */
        public static float dist2(Tuple3f v1, Tuple3f v2)
        {
            return sub(v1, v2).lengthSquared();
        }
        
        /** v1 - v2, Vector that points from v2 to v1. */
        public static Vector3f sub(Tuple3f v1, Tuple3f v2)
        {
            Vector3f r = new Vector3f(v1);
            r.sub(v2);
            return r;
        }
        
        public static Vector3f normalize(Vector3f v) {
            Vector3f r = new Vector3f(v);
            r.normalize();
            return r;
        }
        
        public static float clamp(float f, float min, float max) {
            return f < min ? min : f > max ? max : f; // TODO would Math.min/max be faster?
        }

        public static float clamp(float f) {
            return clamp(f, 0.f, 1.f);
        }
        
        public static float sqrtf(float f) {
            return (float)Math.sqrt(f);
        }
        
        public static float cosf(float f) {
            return (float)Math.cos(f);
        } 
        public static float sinf(float f) {
            return (float)Math.sin(f);
        }
        public static float absf(float f) {
            return (float)Math.abs(f);
        }
        public static float sqr(float f) {
            return f*f;
        }

        public static float expf(float a) {
            return (float)Math.exp(a);
        }

        public static float powf(float a, float b) {
            return (float)Math.pow(a, b);
        }
        
        /** v1 + v2 */
        public static Vector3f add(Tuple3f v1, Tuple3f v2)
        {
            Vector3f r = new Vector3f(v1);
            r.add(v2);
            return r;
        }
        
        /** v1 x v2, vector that is perpendicular to both v1 and v2 and has length = area of parallelogramm
         * spanned by the two. */
        public static Vector3f cross(Vector3f v1, Vector3f v2)
        {
            Vector3f r = new Vector3f();
            r.cross(v1, v2);
            return r;
        }
        
        /** - v */
        public static Vector3f negate(Vector3f v)
        {
            Vector3f r = new Vector3f(v);
            r.negate();
            return r;
        }
        
        /** s (Scalar) * v */
        public static Vector3f scale(float s, Vector3f v)
        {
            Vector3f r = new Vector3f(v);
            r.scale(s);
            return r;
        }
        
        public static Vector3f scale(Vector3f v, float s) {return scale(v,s);}
        
        /** m^-1 */
        public static Matrix4f invert(Matrix4f m)
        {
            Matrix4f r = new Matrix4f(m);
            r.invert();
            return r;
        }

        public static Vector3f transformVectorAsPoint(Matrix4f t, Vector3f v) {
            Point3f p = new Point3f(v);
            t.transform(p);
            return new Vector3f(p);
        }

        /** o + d * t */
        public static Vector3f t(Vector3f o, Vector3f d, float t) {
            Vector3f n = new Vector3f(d);
            n.scaleAdd(t, o);
            return n;
        }

        <math utilities>
    }
        
    <unit tests>+=
    @Test
    public void testReflect() {
        assertTrue(M.reflect(
             new Vector3f(0,1,0),new Vector3f(1,1,0)
            ).equals(
            new Vector3f(-1,1,0)
            ));
    }
        
A utility class to help us run benchmarks.
    [rt/Timer.java]= 
    package rt;
    <common imports>
    public class Timer {
        private long _startTime;
        
        public Timer() { _startTime = this.timeNow(); }
        
        public long timeElapsed() {
            return this.timeNow() - _startTime;
        }

        private long timeNow() {return new Date().getTime();}
    }     
   
<h2>Appendix: Texture</h2> 
    [rt/Texture.java]=
    package rt;
    <common imports>
    import ij.process.ColorProcessor;
    public class Texture {
        public ColorProcessor cp;
        public Texture(BufferedImage i) {
            cp = new ColorProcessor(i);
        }
        public Texture(String i) {
            this(ImageReader.read(i));
        }
        public Spectrum lookup(float x, float y) {
            assert x >= 0 && x <= 1;
            assert y >= 0 && y <= 1;
            int c = cp.getInterpolatedRGBPixel(x*cp.getWidth(),y*cp.getHeight());
            Color cc = new Color(c, false);
            return new Spectrum(cc.getRed()/255.f, cc.getGreen()/255.f, cc.getBlue()/255.f);
        }
    }
    
    <unit tests>+=
    
    @Test 
    public void testTexturefail() {
        BufferedImage bufferedImage = new BufferedImage(1, 1, BufferedImage.TYPE_INT_RGB);
        bufferedImage.setRGB(0,0,Color.WHITE.getRGB());
        
        Texture t = new Texture(bufferedImage);
        try {
        t.lookup(-1,1);
        } catch (AssertionError e) {return;}
        assert false;
    }
    
    @Test 
    public void testTexture() {
        BufferedImage bufferedImage = new BufferedImage(1, 1, BufferedImage.TYPE_INT_RGB);
        bufferedImage.setRGB(0,0,Color.WHITE.getRGB());
        
        Texture t = new Texture(bufferedImage);
        assertEquals(
        new Spectrum(1,1,1),
        t.lookup(0,0)
        );
    }
    
    @Test 
    public void testTexture2() {
        BufferedImage bufferedImage = new BufferedImage(2, 2, BufferedImage.TYPE_INT_RGB);
        bufferedImage.setRGB(0,0,Color.RED.getRGB());
        bufferedImage.setRGB(0,1,Color.RED.getRGB());
        bufferedImage.setRGB(1,0,Color.RED.getRGB());
        bufferedImage.setRGB(1,1,Color.RED.getRGB());
        
        Texture t = new Texture(bufferedImage);
        
        System.out.println("testTexture2 " + t.lookup(0,0));
        assertEquals(
        new Spectrum(1,0,0),
        t.lookup(0,0)
        );
    }
    @Test 
    public void testTexture3() {
        BufferedImage bufferedImage = new BufferedImage(2, 2, BufferedImage.TYPE_INT_RGB);
        bufferedImage.setRGB(0,0,Color.RED.getRGB());
        bufferedImage.setRGB(0,1,Color.RED.getRGB());
        bufferedImage.setRGB(1,0,Color.RED.getRGB());
        bufferedImage.setRGB(1,1,Color.BLUE.getRGB());
        
        Texture t = new Texture(bufferedImage);
        
        out("testTexture3(1,1) " +  t.lookup(1,1));
        
        int c = t.cp.getInterpolatedRGBPixel(2* t.cp.getWidth(),2* t.cp.getHeight());
        Color cc = new Color(c, false);
        Spectrum ss = new Spectrum(cc.getRed()/255.f, cc.getGreen()/255.f, cc.getBlue()/255.f);
            
        assertEquals(0, ss.r, 0.01f
        );assertEquals(0, ss.g, 0.01f
        );assertEquals(1, ss.b, 0.01f
        );
        
        // in fact, the grid only ranges from 0,0 to w-1,h-1, so the points are on the corners.
        // then it seems to clamp
         ss = t.lookup(1,1);
        assertEquals(0, ss.r, 0.01f
        );assertEquals(0, ss.g, 0.01f
        );assertEquals(1, ss.b, 0.01f
        );
    }
    
<h3>Texture Material</h3>
    [rt/materials/TextureMaterial.java]=
    package rt.materials;
    <common imports>
    public class TextureMaterial extends Material {
        Texture t;
        public TextureMaterial(Texture t) {this.t = t;}
        
        public TextureMaterial(String i) {
            this(new Texture(i));
        }
        
        public Spectrum shade(HitRecord r, Integrator i, int depth) {
            return t.lookup(r.u, r.v);
        }
    }
    
    <hit record datastructure>+=
    public float u, v;
    
    <triangle hit record post processing>+=
    float texu0 = mesh.textureUvs[v0*2], texu1 = mesh.textureUvs[v1*2], texu2 = mesh.textureUvs[v2*2];
    float texv0 = mesh.textureUvs[v0*2+1], texv1 = mesh.textureUvs[v1*2+1], texv2 = mesh.textureUvs[v2*2+1];
        
    h.u = (1-s-t)*texu0 + s*texu1 + t*texu2;
    h.v = (1-s-t)*texv0 + s*texv1 + t*texv2;
    
    <additional mesh data>+= 
    public float[] textureUvs;
    
    <default mesh constructor>+=
    textureUvs = new float[vertices.length/3 * 2];
    
    
    <additional mesh constructors>+=
    public Mesh(float[] vertices, float[] normals, float[] textureUvs, int[] indices)
    {
        this(vertices, normals, indices);
        this.textureUvs = textureUvs;
    }    
        
    <unit tests>+=
    @Test
    public void testTriUv() {
        float[] vertices = {
                0.f, 0.f, 0.f, 
                1.f, 0.f, 0.f, 
                0.f, 1.f, 0.f};
        float[] normals = {
            0.f, 0.f, 1.f,
            0.f, 0.f, 1.f,
            0.f, 0.f, 1.f};
        int[] indices = {0, 1, 2};
        float[] textureUvs = {
            0.f, 1.f,
            1.f, 0.f,
            0.f, 0.f};
        Mesh m = new Mesh(vertices, normals, textureUvs, indices);
        
        assertEquals(textureUvs, m.textureUvs);
        assertEqualsX(m.textureUvs[0], 0.f);
        assertEqualsX(m.textureUvs[1], 1.f);
    }
    
    @Test
    public void testTriUvObj() {
        Mesh m = ObjReader.read("obj/male.obj", 1.f);
        assertEqualsX(m.textureUvs[0], 0.630557f);
        assertEqualsX(m.textureUvs[1], 0.465076f);
    }
    
<img src="output/rt.testscenes.TriangleTextureTest.png"></img>
    [rt/testscenes/TriangleTextureTest.java]= 
    package rt.testscenes;
    <common imports>
    public class TriangleTextureTest extends ObjectTest {//PinholeCameraScene {
        public TriangleTextureTest()
        {
            super(new Vector3f(0.f, 0.f, 3.f));

            float[] vertices = {
                0.f, 0.f, 0.f, 
                1.f, 0.f, 0.f, 
                0.f, 1.f, 0.f};
            float[] normals = {
                0.f, 0.f, 1.f,
                0.f, 0.f, 1.f,
                0.f, 0.f, 1.f};
            int[] indices = {0, 1, 2};
            
        float[] textureUvs = {
            0.f, 1.f,
            1.f, 0.f,
            0.f, 0.f};
            
            root = new Mesh(vertices, normals, textureUvs, indices);
            
            
            integratorFactory = new MaterialIntegratorFactory();
            
            root.setMaterial(new TextureMaterial("testimages/testTexture.jpg"));
        }
    }
    <test scenes>+=
    new TriangleTextureTest(),
    <unit tests>+=
    @Test 
    public void testTriangleTextureTest() {
        assertImgEquals(
            "output/rt.testscenes.TriangleTextureTest.png", 
            "testimages/rt.testscenes.TriangleTextureTest.png"
        );
    }
 
    
<h3>Envmap, Cubemap</h3>
    [rt/Envmap.java]=
    package rt;
    <common imports>
    public abstract class Envmap {
        public abstract Spectrum f(Vector3f v);
    }
    
    [rt/Cubemap.java]=
    package rt;
    <common imports>
    public class Cubemap extends Envmap {
        float planes[] = {
            1,0,0, -1,
            -1,0,0, 1,
            
            0,1,0, -1,
            0,-1,0, 1,
            
            0,0,1, -1,
            0,0,-1, 1,
        };
        
        Texture[] textures;
        public Cubemap(Texture[] textures) {
            this.textures = textures;
        }
    
        public Spectrum f(Vector3f v) {
            assert M.isApproxUnitvector(v) : "normal "+v+" must be unit vector, len "+v.length();
            
            float mint = Float.MAX_VALUE;
            int mini = -1; 
            for (int i = 0; i < 6; i++) {
                float t = M.intersectPlane(new Ray(new Vector3f(), v), 
                    new Vector3f(planes[4*i+0],planes[4*i+1],planes[4*i+2]),
                    planes[4*i+3]);
                    
                if (t < 0 || t == Float.NaN) continue;
                
                if (t < mint) {
                    mint = t; mini = i;
                   }
            }
            assert mint != Float.MAX_VALUE;
            assert 0 <= mini && mini < 6;
            assert mint+UnitTests.APPROX >= 1.f; // time must be larger than one.
            
            // TODO sample correct orientation
            Vector3f p = M.scale(mint, v);
            assert M.isApprox(1, M.absf(p.x)) || M.isApprox(1, M.absf(p.y)) || M.isApprox(1, M.absf(p.z));
            float u, vv;
            u  = M.canonicTo01Interval(p.x);
            vv = M.canonicTo01Interval(p.y);
            
            if (M.isApprox(1, u)) u = p.z;
            if (M.isApprox(1, vv)) vv = p.z;
            return textures[mini].lookup(u, vv);
        }
    }
    
    <math utilities>+=
    // -1, 1 to 0 ,1 
    public static float canonicTo01Interval(float x) {
        assert x >= -1.1 && x <= 1.1 : "out of range [-1,1]: "+x;
        return (x+1)/2;
       }
       
       <unit tests>+= 
       @Test
       public void testctu() {
        assertEqualsX(.5f, M.canonicTo01Interval(0));
       }
    
    [rt/materials/EnvmapMaterial.java]=
    package rt.materials;
    <common imports>
    public class EnvmapMaterial extends Material {
    Envmap m;
        public EnvmapMaterial(Envmap m) {
            this.m = m;
            }
            
         public Spectrum shade(HitRecord hitRecord, Integrator integrator, int depth) {
            return m.f(hitRecord.normal);
         }
       
    }
    

<img src="output/rt.testscenes.EnvmapMaterialTest.png"></img>
    [rt/testscenes/EnvmapMaterialTest.java]= 
    package rt.testscenes;
    <common imports>
    public class EnvmapMaterialTest extends ObjectTest {//PinholeCameraScene {
        public EnvmapMaterialTest()
        {
            super(new Vector3f(0.f, 0.f, 3.f));
            root = new CSGUnitSphere();
            integratorFactory = new MaterialIntegratorFactory();
            
            root.setMaterial(new EnvmapMaterial(new Cubemap(
                new Texture[] {
                new Texture("testimages/testTexture.jpg"),
                new Texture("testimages/testTexture.jpg"),
                new Texture("testimages/testTexture.jpg"),
                new Texture("testimages/testTexture.jpg"),
                new Texture("testimages/testTexture.jpg")
                }
                )));
        }
    }
    <test scenes>+=
    new EnvmapMaterialTest(),
    
<h2>Appendix: Image Reader</h2>
    [rt/ImageReader.java]=
    package rt;
    <common imports>
    public class ImageReader {
        public static boolean equals(BufferedImage image1, BufferedImage image2) {
            assert image1 != null;
            assert image2 != null;
            int width;
            int height;
            boolean imagesEqual = true;
            if ( image1.getWidth()  == ( width  = image2.getWidth() ) && 
                image1.getHeight() == ( height = image2.getHeight() ) ) {

                for(int x = 0;imagesEqual == true && x < width; x++){
                    for(int y = 0;imagesEqual == true && y < height; y++){
                        if( image1.getRGB(x, y) != image2.getRGB(x, y) ){
                            imagesEqual = false;
                        }
                    }
                }
            } else {
                imagesEqual = false;
            }
            return imagesEqual;
        }
        
        public static BufferedImage read(String fn) {
            try {
            File f= new File(fn);
            String ext = Files.probeContentType(f.toPath());
            System.out.println("ext "+ext);
            //assert ext.equalsIgnoreCase("png") ||  ext.equalsIgnoreCase("jpg"); // TODO fix
            
                return ImageIO.read(f);
            } catch (Exception e) {
                throw new RuntimeException("fatal, cannot load: "+fn);
            }
        }
    }
    <unit tests>+=
    public static void assertImgEquals(BufferedImage i, BufferedImage i2) {
        assertTrue(ImageReader.equals(i, i2));
    }
    
    public static void assertImgEquals(String a, String b) {
        assertImgEquals(
            ImageReader.read(a), 
            ImageReader.read(b)
        );
    }
    
    
    <unit tests>+=
    @Test 
    public void testImageReaderEquals() {
        BufferedImage in = ImageReader.read("testimages/test.png");
        assertImgEquals(in, in);
        
        BufferedImage in2 = ImageReader.read("testimages/test.png");
        assertImgEquals(in, in2);
        
        BufferedImage in3 =  ImageReader.read("testimages/test2.png");
        assertFalse(ImageReader.equals(in, in3));
    }
    @Test 
    public void testImageReaderEquals2() {
        assertImgEquals(ImageReader.read("testimages/rt.testscenes.InstancingTest.png"), ImageReader.read("testimages/rt.testscenes.InstancingTest.png"));
    }
<h2>Appendix: Obj Reader</h2>
The only external scene and data description format that we currently support are obj files.
This reads an .obj file including normals and stores it in a Mesh.
scale scales the object to fit into a cube of the given size
    [rt/ObjReader.java]= 
    package rt;
    <common imports>
    public class ObjReader {
        public static Mesh read(String fileName, float scale) {
            Mesh mesh;
            try {
                mesh = ObjReader._read(fileName, scale);
            } catch(IOException e) {
                throw new RuntimeException("Could not read .obj file: "+fileName);
            }
            return mesh;
        }
        
        private static Mesh _read(String fileName, float scale) throws IOException
        {
            BufferedReader reader;
            ArrayList<float[]> vertices = new ArrayList<float[]>();
            ArrayList<float[]> texCoords = new ArrayList<float[]>();
            ArrayList<float[]> normals = new ArrayList<float[]>();
            ArrayList<int[][]> faces = new ArrayList<int[][]>();
            
            boolean hasNormals, hasTexCoords;
            hasNormals = true;
            hasTexCoords = true;
            
            // Extents for normalization
            float xMin, xMax, yMin, yMax, zMin, zMax;
            xMin = Float.MAX_VALUE;
            xMax = Float.MIN_VALUE;
            yMin = Float.MAX_VALUE;
            yMax = Float.MIN_VALUE;
            zMin = Float.MAX_VALUE;
            zMax = Float.MIN_VALUE;
            
            reader = new BufferedReader(new FileReader(fileName));

            String line = null;
            while((line = reader.readLine()) != null)
            {    
                // Read line
                String[] s = line.split("\\s+");
                
                // Parse
                if(s[0].compareTo("v")==0)
                {
                    // Position
                    float[] v = new float[3];
                    v[0] = Float.valueOf(s[1]).floatValue();
                    v[1] = Float.valueOf(s[2]).floatValue();
                    v[2] = Float.valueOf(s[3]).floatValue();
                    vertices.add(v);
                    
                    // Update extent
                    if(v[0] < xMin) xMin = v[0];
                    if(v[0] > xMax) xMax = v[0];
                    if(v[1] < yMin) yMin = v[1];
                    if(v[1] > yMax) yMax = v[1];
                    if(v[2] < zMin) zMin = v[2];
                    if(v[2] > zMax) zMax = v[2];
                } 
                else if(s[0].compareTo("vn")==0)
                {
                    // Normal
                    float[] n = new float[3];
                    n[0] = Float.valueOf(s[1]).floatValue();
                    n[1] = Float.valueOf(s[2]).floatValue();
                    n[2] = Float.valueOf(s[3]).floatValue();
                    normals.add(n);
                }
                else if(s[0].compareTo("vt")==0)
                {
                    // Texture
                    float[] t = new float[2];
                    t[0] = Float.valueOf(s[1]).floatValue();
                    t[1] = Float.valueOf(s[2]).floatValue();
                    texCoords.add(t);
                }
                else if(s[0].compareTo("f")==0)
                {
                    // Indices
                    int[][] indices = new int[3][3];
                    
                    // For all vertices
                    int i=1;
                    while(i < s.length)
                    {    
                        // Get indices for vertex position, tex. coords., and normals
                        String[] ss = s[i].split("/");
                        int k=0;
                        while(k < ss.length)
                        {
                            if(ss[k].length()>0)
                                indices[i-1][k] = Integer.valueOf(ss[k]).intValue();
                            else
                            {
                                indices[i-1][k] = -1;
                                if(k == 1) hasTexCoords = false;
                                if(k == 2) hasNormals = false;
                            }
                            k++;
                        }
                        if(ss.length == 1)
                        {
                            hasTexCoords = false;
                            hasNormals = false;
                        }
                        i++;
                    }
                    faces.add(indices);
                }
                else if(s[0].length()>0 && s[0].charAt(0)!='#')
                {
                    // usemtl statements etc generate this
                    //System.err.print("Unknown token '".concat(line).concat("'\n"));
                }
            }

            // Normalization
            float xTrans = -(xMax+xMin)/2;
            float yTrans = -(yMax+yMin)/2;
            float zTrans = -(zMax+zMin)/2;
            float xScale = 2/(xMax-xMin);
            float yScale = 2/(yMax-yMin);
            float zScale = 2/(zMax-zMin);
            float s = yScale;
            if(xScale < yScale) s = xScale;
            if(zScale < s) s = zScale;
            scale = s*scale;
            
            // Brute force approach to generate single index per vertex
            // Expand arrays
            int nFaces = faces.size();
            float[] verticesFinal = new float[nFaces*9];
            float[] normalsFinal = new float[nFaces*9];
            float[] texCoordsFinal = new float[nFaces*6];
            int[] indices = new int[nFaces*3];
            
            // For all faces
            int vertexNr = 0;
            for(int i=0; i<nFaces; i++)
            {
                // For all vertices
                for(int j=0; j<3; j++)
                {
                    // Copy positions, tex. coords., and normals to expanded arrays
                    // Note: we subtract one from the index because indexing in the obj
                    // file is 1-based, whereas our arrays are 0-based
                    verticesFinal[vertexNr*3] = vertices.get(faces.get(i)[j][0]-1)[0];
                    verticesFinal[vertexNr*3+1] = vertices.get(faces.get(i)[j][0]-1)[1];
                    verticesFinal[vertexNr*3+2] = vertices.get(faces.get(i)[j][0]-1)[2];
                    
                    verticesFinal[vertexNr*3] = scale*(verticesFinal[vertexNr*3]+xTrans);
                    verticesFinal[vertexNr*3+1] = scale*(verticesFinal[vertexNr*3+1]+yTrans);
                    verticesFinal[vertexNr*3+2] = scale*(verticesFinal[vertexNr*3+2]+zTrans);
                    
                    if(hasNormals)
                    {
                        normalsFinal[vertexNr*3] = normals.get(faces.get(i)[j][2]-1)[0];
                        normalsFinal[vertexNr*3+1] = normals.get(faces.get(i)[j][2]-1)[1];
                        normalsFinal[vertexNr*3+2] = normals.get(faces.get(i)[j][2]-1)[2];
                    } 
                    
                    if(hasTexCoords)
                    {
                        texCoordsFinal[vertexNr*2] = texCoords.get(faces.get(i)[j][1]-1)[0];
                        texCoordsFinal[vertexNr*2+1] = texCoords.get(faces.get(i)[j][1]-1)[1];
                    }
                    
                    indices[vertexNr] = vertexNr;
                    vertexNr++;
                }
                
                if(!hasNormals)
                {
                    Vector3f d0 = new Vector3f(
                        verticesFinal[(vertexNr-1)*3  ]-verticesFinal[(vertexNr-3)*3],
                        verticesFinal[(vertexNr-1)*3+1]-verticesFinal[(vertexNr-3)*3+1],
                        verticesFinal[(vertexNr-1)*3+2]-verticesFinal[(vertexNr-3)*3+2]);
                    Vector3f d1 = new Vector3f(
                        verticesFinal[(vertexNr-2)*3  ]-verticesFinal[(vertexNr-3)*3],
                        verticesFinal[(vertexNr-2)*3+1]-verticesFinal[(vertexNr-3)*3+1],
                        verticesFinal[(vertexNr-2)*3+2]-verticesFinal[(vertexNr-3)*3+2]);
                    Vector3f n = new Vector3f();
                    n.cross(d1,d0);
                    n.normalize();
                    for(int j=0; j<3; j++)
                    {
                        normalsFinal[(vertexNr-(j+1))*3]   = n.x;
                        normalsFinal[(vertexNr-(j+1))*3+1] = n.y;
                        normalsFinal[(vertexNr-(j+1))*3+2] = n.z;
                    }
                }
            }

            reader.close();
            return new Mesh(verticesFinal, normalsFinal, texCoordsFinal, indices);
        }
    }
    
    <unit tests>+=
    @Test
    public void testObjAABB() {
        Intersectable a = ObjReader.read("obj/teapot.obj", 1.f);
        AABB aabb = a.aabb();
        out("testObjAABB "+ aabb);
        assertEqualsX(M.min(aabb.a.x, aabb.a.y, aabb.a.z), -1.f);
        assertEqualsX(M.max(aabb.b.x, aabb.b.y, aabb.b.z), 1.f);
    }