<h1>A Raytracer</h1>
What follows is a raytracer written in Java for the course 
"Rendering Algorithms" of the University of Bern in the first half of 2015.

<p>
In computer graphics, ray tracing is a technique for generating an image 
by tracing the path of light through pixels in an image plane and simulating
the effects of its encounters with virtual objects. 
The technique is capable of producing a very high degree of visual realism [...]

<h2>This is a literate program</h2>
This is written in a "literate programming" style and completely contained in this single file.
We write an indented
	<multi word identifier>=
or
	<multi word identifier>+=
to start or expand a section of code that can be inserted elsewhere by referring to <multi word identifier> as in
	<multi word identifier>
Furthermore, [folder/filename.ext]= marks the start of a section that will be written to a file once all abbreviations are fully expanded.

<h2>Known Issues/TODO</h2>
This is a work in progress project, and as such it has a lot of problems, including but not limited to:
<ul>
<li>The colors it computes for Blinn shading do not match the example images.
<li>There are no interesting example scenes.
<li>Refraction does not work
<li>Distance fields are not well tested or understood.
And their maximumRadius property is not properly updated.
It might also be more efficient to have a bounding box instead.
<li>There seem to be some issues with reflection
<li>Raytracing lots of primitives is very slow
<li>The creator does not understand why the camera's projection matrices work, but they do
<li>There is something wrong with the teapot normals or they are too bright for some other reason
<li>The BSP traversal should use a custom stack instead of relying on the runtime callstack for efficiency 
and to support any amount of levels. Well for the latter, the construction would also need a custom stack.
<li>It would be nice to extract texture coordinates from the .obj files and store them in the meshes.
<li>This literate program has some things that are not so nice. For example, it still uses packages, 
which are useless in this context. Also it repeats itself quite often in class names and some other things, 
e.g. the names of images generated by code, in particular the amount of samples.

<p>It would also be nice if we could have inline math formulas via MathJax.
</ul>

<h2>Running</h2>
This program can be "tangled" (i.e. the Java files it encodes created) and then compiled using the prepared
script tt, i.e. by calling
	tt.bat
under windows or
	./tt.sh
under an Unix os with a recent version of Java properly installed.

<p>
You can always delete the rt and outputs subfolders created here - running tt will recreate them with all
their content.

<h2>Basic Raytracing</h2>
The basic raytracing algorithm is this:
	rayTrace() {
		construct scene representation
        
		for each pixel
			ray = computePrimary()
			hit = first intersection with scene
			color = shade( hit )
			set pixel color
	}
    
The subsequent sections will motivate and define algorithms and data structures
that implement this.

<h3>Ray</h3>	
A ray is represented by an origin and a direction (need not be a unit vector) in three dimensional space.
	[rt/Ray.java]= 
	package rt;
    <common imports>
	public class Ray {
		public Vector3f origin, direction;
		
		public Ray(Vector3f origin, Vector3f direction)
		{
			<copy origin and direction>
		}
		<ray methods>
	}
We always need to make defensive copies of mutable arguments supplied to constructors if we want to
enforce encapsulation. The javax.vecmath vector objects are all mutable.
	<copy origin and direction>=
	this.origin = new Vector3f(origin); 
	this.direction = new Vector3f(direction);
For convenience, we provide the method t to construct the point o + t*d on the ray:
	<ray methods>=
	public Vector3f t(float t) {
		return M.t(origin, direction, t);
	}
    
<h3>Scene Representation</h3>
    construct scene representation
Defines 'scene' properties (list of objects, 'camera' position, final image resolution etc.)
that need to be made accessible to the renderer. 
	[rt/Scene.java]= 
	package rt;
    <common imports>
	public abstract class Scene {
        <scene image capturing device>
	
		protected IntegratorFactory integratorFactory;
		public IntegratorFactory getIntegratorFactory() {return integratorFactory;}

		protected SamplerFactory samplerFactory;
		public SamplerFactory getSamplerFactory() {return samplerFactory;}
		protected Intersectable root;
		public Intersectable getIntersectable() {return root;}
        <additional scene data>
	}
    
    <scene image capturing device>=
    	protected String outputFilename;
		public String getOutputFilename() {return outputFilename;}
		protected int width;
		protected int height;
		protected Film film;
		public Film getFilm() {return film;}
		/** Number of samples per pixel */
		protected int SPP;
		public int getSPP() {return SPP;}
		protected Tonemapper tonemapper;
		public Tonemapper getTonemapper() {return tonemapper;}
        
		protected Camera camera;
		public Camera getCamera() {return camera;}

        
We will define all of these things along the way.

<h3>Multithreaded rendering</h3>	
We use a multi-threaded approach to casting the rays for the image pixels, that is, to
implement the loop
    for each pixel
We partition the image into blocks, called RenderTasks, that are then submitted to
	<number of threads>=
	Runtime.getRuntime().availableProcessors()
worker threads. 
We call the final image a Film and the component responsible for intersection testing and
computing the color value (shading, illumination) at a point is called an Integrator,
so the code goes something like:
	for all pixels in block {
		Ray r = camera.makeWorldSpaceRay(pixel);
		Spectrum s = integrator.integrate(r);
		film.addSample(pixel, s);
	}
The camera is the component responsible for creating rays that originate at some
point and are directed towards the pixels mapped to an image plane in three dimensional space.
Think camera obscura, but with the image plane in front of the camera.
We allow the film to accumulate multiple samples gathered by shooting multiple rays
through points (randomly) sampled on the area covered by a pixel
(so called subpixel locations) on the image plane. 
The process of generating the random samples is left to the integrator.
	for all pixels in block {
		float samples[][] = integrator.makePixelSamples(sampler,spp);
		for all samples {
			Ray r = camera.makeWorldSpaceRay(pixel, sample);
			Spectrum s = integrator.integrate(r);
			film.addSample(pixel + sample_offset, s);
		}
	}
„spp“ is the amount of samples per pixel.
The final code is then
	<blockwise raytracing>=
	for (int j = bottom; j < top; j++) for (int i = left; i < right; i++) {
        float samples[][] = integrator.makePixelSamples(sampler, scene.getSPP());
        for (int k = 0; k < samples.length; k++) {
            Ray r = scene.getCamera().makeWorldSpaceRay(i, j, samples[k]);
            Spectrum s = integrator.integrate(r);	
            scene.getFilm().addSample(i + samples[k][0], j + samples[k][1], s);
        }
	}
		
We make sure that class names do not clash in our raytracer, so we can always import all of it.
	<common imports>=
	import javax.vecmath.*;
	import rt.*;
	import rt.materials.*;
	import rt.Material.*;
	import rt.lightsources.*;
	import rt.samplers.*;
	import rt.tonemappers.*;
	import rt.intersectables.*;
	import rt.integrators.*;
	import rt.films.*;
	import rt.cameras.*;
	import rt.basicscenes.*;
	import rt.testscenes.*;
	import java.util.*;
	import java.io.*;
	import rt.intersectables.CSGSolid.*;
	import rt.intersectables.CSGNode.*;
	import rt.intersectables.DFNode.*;
    import rt.BSPNode.*;
	import java.awt.image.*;
	import java.util.concurrent.*;
	import javax.imageio.*;

The main executable Java file serves to set up and render some scenes.
We will render the following (instances of) scenes:
	<rendered scenes>=
        <test scenes>
        <beautiful scenes>
that are defined along the way.
	[rt/Main.java]= 
	package rt;
	<common imports>
	public class Main {
		public static Scene[] scenes = {
			<rendered scenes>
		};
		
        <render task>
		
		public static void main(String[] args) 
		{	
			for (Scene s : scenes) 
                try { 
                    render(s);
                } catch (Exception e) {
                    System.err.println(e);e.printStackTrace(System.err);
                }
		}
		
		public static void render(Scene scene) throws Exception
		{	
			<render scene>
		}
	}	
    
<h4>RenderTask</h4>
    <render task>=
    static class RenderTask implements Runnable
    {
        public int left, right, bottom, top;
        public Integrator integrator;
        public Scene scene;
        public Sampler sampler;
        
        public RenderTask(Scene scene, int left, int right, int bottom, int top) 
        {			
            this.scene = scene;
            this.left = left; this.right = right; this.bottom = bottom; this.top = top;

            <create sampler and integrator>
        }

        public void run() {
            <blockwise raytracing>
        }
    }
    
The render task has its own sampler and integrator. This way threads don't 
compete for access to a shared sampler/integrator, and thread contention
can be reduced. 
    <create sampler and integrator>=
        integrator = scene.getIntegratorFactory().make(scene);
        sampler = scene.getSamplerFactory().make();
        
<h4>Render scene</h4>    
To render a scene, we do the following
	<render scene>=
	<determine amount of blocks and create thread pool>

	<start timer>
	<create and dispatch render tasks>
	<wait for threads to end reporting progress>
	<stop timer>

	<tone map output image and write to file>
			
Each task renders a square image block of size
	<image block size>=
	4
The amount of tasks then computes as
	<determine amount of blocks and create thread pool>=
	int taskSize = <image block size>;	
	int nThreads = <number of threads>;
	int width = scene.getFilm().getWidth(); int height = scene.getFilm().getHeight();
	int nTasks = (int)(Math.ceil(width/(double)taskSize) * Math.ceil(height/(double)taskSize));
	ThreadPoolExecutor executor = new ThreadPoolExecutor(nThreads, nThreads, 60, TimeUnit.SECONDS, new ArrayBlockingQueue<Runnable>(nTasks) );

	<create and dispatch render tasks>=
	ArrayList<Future<?>> futures = new ArrayList<>(nTasks);
	for (int j=0; j < Math.ceil(height/(double)taskSize); j++) {
		for (int i=0; i < Math.ceil(width/(double)taskSize); i++) {
			RenderTask task = new RenderTask(scene, 
				i*taskSize, Math.min((i+1)*taskSize, width), 
				j*taskSize, Math.min((j+1)*taskSize, height));
			futures.add(executor.submit(task));
		}
	}
			
			
	<wait for threads to end reporting progress>=
	System.out.printf("Rendering scene %s (%d spp) with %s threads to file %s: \n", scene.getClass().getName(), scene.getSPP(), nThreads, scene.outputFilename);
	System.out.println("0%                                                50%                                           100%");
	System.out.println("|---------|---------|---------|---------|---------|---------|---------|---------|---------|--------|");
	executor.shutdown();
	
	int printed = 0;
	for (Future<?> f: futures) {
		<wait for f to finish>
		int toPrint = (int) (<get percentage completed>);
		for (; printed < toPrint; printed++) System.out.print("*");
	}
	System.out.println();
    
	<wait for f to finish>=
	f.get();

	<get percentage completed>=
	executor.getCompletedTaskCount()/(float)executor.getTaskCount()*100
	
	<tone map output image and write to file>=
	BufferedImage image = scene.getTonemapper().process(scene.getFilm());
	ImageIO.write(image, "png", new File(scene.getOutputFilename()+".png"));
	
We record the time the rendering takes:
	<start timer>=
	Timer timer = new Timer();
    
	<stop timer>=
	long time_ms = timer.timeElapsed();
	long time_s = time_ms / 1000;
	long time_min =  time_s / 60;
	System.out.printf("Image computed in %d ms = %d min, %d sec.\n", time_ms, time_min, time_s - time_min*60);

<h2>Tests</h2>
We will define simple JUnit 3-tests for certain components as we go.
    [rt/AllTests.java]=
    package rt;
    <common imports>
	import org.junit.runner.*;
	import org.junit.runners.*;
	import org.junit.runners.Suite.*;

	@RunWith(Suite.class)
	@SuiteClasses({rt.UnitTests.class})
	public class AllTests {}
where
	[rt/UnitTests.java]=
    package rt;
	import static org.junit.Assert.*;
	import org.junit.*;
    <common imports>
	public class UnitTests {
        <unit tests>
	}
They can be run with
    java -ea -cp *;. org.junit.runner.JUnitCore rt.AllTests
    
<h2>Coordinates</h2>
The ray-tracer operates in three-dimensional space in a right handed coordinate system where
positive y is the up direction
<img src=right-handed.png></img>
	<up vector>=
	new Vector3f(0.f, 1.f, 0.f)
Units are scaled arbitrarily.

<h2>Camera</h2>
A camera is any object that can return rays given pixel coordinates.
It implements the pseudocode
    ray = computePrimary()
of the basic raytracing algorithm.
Given a pixel in image space, the method should make a ray in world space according 
to the camera specifications. The method receives a sample that 
the camera can use to generate the ray with subpixel offset. Typically the first two
sample dimensions are used to sample a sub-location in the current 
pixel (i.e. determine a sub-pixel location). The samples are assumed to be in the range [0,1].
	[rt/Camera.java]= 
	package rt;
    <common imports>
	public interface Camera {
		public Ray makeWorldSpaceRay(int i, int j, float sample[]);
	}
	
<h3>Specific Cameras</h3>
<h4>FixedCamera</h4>
A simple camera with fixed position 
	<fixed camera position>=
	eye = new Vector3f(0.f, 0.f, 3.0f);
(in world coordinates) and no rotation. Thus the camera to world transform is just
	<fixed camera to world>=
	Matrix4f c = new Matrix4f();
	c.setIdentity();
	c.m03 = eye.x;
	c.m13 = eye.y;
	c.m23 = eye.z;

„The view frustum of the camera points to -z direction (in both camera and world space) and
goes through the points [-1,-1,-1], [1,-1,-1], [-1,1,-1], [1,1,-1] in camera coordinates.
The projection matrix is constructed by inverting the matrix that goes from camera coordinates to the 
canonic view volume, which is the cube [-1..1]x[-1..1]x[-1..1] centered at origin.“
<p>
I do not understand how this whole story with the projection matrix, 
homogeneous coordinates, canonic view volume and perspective divide/homogeneous divide works.
<img src=perproj.png></img>
	<fixed projection matrix>=
	Matrix4f p = new Matrix4f();
	p.setIdentity();
	float near = 1.f,  far = 10.f;
	
	p.m22 = -(far+near)/(far-near); p.m23 = -(2*far*near)/(far-near);
	p.m32 = -1.f; 		    p.m33 = 0.f;
	
	p.invert();
The viewport matrix transforms points in the range [0..width]x[0..height] linearly to the range [-1..1]x[-1..1], where width and height give the size of the final image. We start off with the matrix that transforms [-1..1]x[-1..1] to [0..width]x[0..height] and then invert.
	<fixed viewport matrix>=
	Matrix4f v = new Matrix4f();
	v.setIdentity();		
	v.m00 = width/2.f;  v.m03 = width/2.f;
	v.m11 = height/2.f; v.m13 = height/2.f;
	v.m22 = 1.f;		       v.m23 = 0.f;
	v.invert();

Finally we combine all of them to get the matrix c*p*v that transforms a viewport pixel coordinate
to a world space point.
	<make viewport to world matrix>=
	p.mul(v); c.mul(p); viewportToWorld = c;

The viewport pixels are defined with z -1 coordinate. In homogeneous 3d coordinates, 
the 4th component being 1 defines it as a point.
    <make point on image plane in viewport coordinates>=
    Vector4f d = new Vector4f(i+sample[0], j+sample[1], -1.f, 1.f);
The assumption is that pixel [i,j] is the square [i,i+1] x [j,j+1] in viewport coordinates
            
	[rt/cameras/FixedCamera.java]= 
	package rt.cameras;
	<common imports>
	public class FixedCamera implements Camera {
		Vector3f eye;
		Matrix4f viewportToWorld;
		
		FixedCamera() {}
		public FixedCamera(int width, int height)
		{
			<fixed camera position>
			<fixed camera to world>
			
			<fixed projection matrix>
			<fixed viewport matrix>

			<make viewport to world matrix>
		}
		
		public Ray makeWorldSpaceRay(int i, int j, float[] sample) {
			<make point on image plane in viewport coordinates>
            
			viewportToWorld.transform(d);
			
			return new Ray(eye, M.sub(new Vector3f(d.x, d.y, d.z), eye));
		}

	}
	
<h4>PinholeCamera</h4>
A camera with a given position, look-at and up direction and view frustum 
determined by aspect and fov. 
fov is the vertical field of view angle (opening of the view trapezoid) in degrees.
<img src=cam.png></img>
	<pinhole camera to world matrix>=
	Vector3f w = M.sub(eye, to); w.normalize();
	Vector3f u = M.cross(up, w); u.normalize();
	Vector3f v_ = M.cross(w,  u);
			
	// Camera to world transform matrix - take:
	// 	x to u
	// 	y to v
	//	z coordinates to w,
	// and translate by eye.
	Matrix4f c = new Matrix4f(); c.setIdentity();

	c.m00 = u.x; c.m01 = v_.x; c.m02 = w.x; c.m03 = eye.x;
	c.m10 = u.y; c.m11 = v_.y; c.m12 = w.y; c.m13 = eye.y;
	c.m20 = u.z; c.m21 = v_.z; c.m22 = w.z; c.m23 = eye.z;
		
Perspective projection matrix	
<img src=perproj.png></img>
	<pinhole projection matrix>=
	Matrix4f p = new Matrix4f();
	float tfo2 = (float)Math.tan(Math.toRadians(fov) / 2);
	float near = 1.f, far = 10.f;

	p.m00 = 1/(aspect * tfo2);
	p.m11 = 1/tfo2;
	p.m22 = (near+far)/(near-far);   p.m23 = (2*far*near)/(near-far);
	p.m32 = -1.f;	
	p.invert();

	[rt/cameras/PinholeCamera.java]= 
	package rt.cameras;

	<common imports>

	public class PinholeCamera extends FixedCamera {
		public PinholeCamera(
				Vector3f eye,
				Vector3f to,
				Vector3f up,
				float fov,
				float aspect,
				int width, int height)
		{
			this.eye = eye;
			
			<pinhole camera to world matrix>
			<pinhole projection matrix>
            
			<fixed viewport matrix>
			
			<make viewport to world matrix>
		}
	}
	

<h2>Ray-Object Intersection</h2>
This section is concerned with the statement 
    hit = first intersection with scene
of the basic raytracing algorithm.

<p>
Our scenes are represented as a set of surfaces in three dimensional space.
We call individual surfaces primitives or objects of the scene.
We need to be able to efficiently intersect rays with all surfaces in
the scene. 
<h3>HitRecord</h3>
A HitRecord stores information about a ray-surface intersection.
It is the type of the 'hit' variable above.
<p>
The information recorded about the hit surface 
is typically used for shading and certain advanced object intersection algorithms.
We will extend this datastructure as needed.
	[rt/HitRecord.java]= 
	package rt;
	<common imports>
	public class HitRecord  {
		<hit record datastructure>
	}
    
At minimum it includes 
<ul>
<li>a reference to the object (or surface, intersectable) that 
was hit
    <hit record datastructure>+=
		public Intersectable intersectable;	
<li>the ray parameter at the intersection point
	<hit record datastructure>+=
        public float t;	
such that the hit position is
    <hit record datastructure>+=
        public Vector3f position() {
            return ray.t(t);
        }
<li>and a reference to the ray
	<hit record datastructure>+=
        public Ray ray;	
</ul>
These are in principle enough to construct a hit record.

<h4>Surface Normals</h4> 
All of the shading techniques we use as well as some of the algorithms for ray-surface
intersection (e.g. the CSG algorithm described below) make use of the surface normal
at the intersection point. This is a normalized (that is unit-) vector
perpendicular to the suface or the tangent plane to the surface at the 
intersection point.
We thus only support differentiable surfaces (or '2d manifolds' embedded in 3d space).
    <hit record datastructure>+=
        public Vector3f normal;
For surfaces obtained as implicit functions (c.f. CSG and distance field primitives), 
the normal is the normalized gradient at the intersection point.
<p>
A hit record is thus constructed as
    <hit record datastructure>+=
    public HitRecord(Ray r, float tt, Intersectable i, Vector3f n) {
        ray = r; t = tt; intersectable = i; 
        normal = n;
    }

<h3>Intersectables</h3>
An Intersectable is an object with a surface that supports ray-surface intersection.
HitRecord intersect(Ray r) determines whether r hits this surface and if so 
constructs a corresponding hit record, otherwise returns null.
	[rt/Intersectable.java]= 
	package rt;
	public abstract class Intersectable extends HasAABB {
		public abstract HitRecord intersect(Ray r);
        <additional intersectable methods and data>
	}
    
<h4>Aggregate</h4>
A group of Intersectable objects is called an aggregate.
To determine the closest hit, we try to intersect with all the objects in the 
group and keep track of only the closest intersection.
We leave it up to implementations of this abstract class how to store the iterable list of 
objects.
	<intersect all objects in group determine closest hit>=
    HitRecord closestHitRecord = null;
    float t = Float.MAX_VALUE;

	for (Intersectable o : this) {
		HitRecord tmp = o.intersect(r);
		if (tmp != null && tmp.t < t) {
			t = tmp.t;
			closestHitRecord = tmp;
		}
	}
    return closestHitRecord;

	[rt/intersectables/Aggregate.java]= 
	package rt.intersectables;
	<common imports>
	public abstract class Aggregate extends Intersectable implements Iterable<Intersectable> {

		public HitRecord intersect(Ray r) {
			<intersect all objects in group determine closest hit>
		}
		
		public abstract Iterator<Intersectable> iterator();
        
        public int size() {
            int n = 0;
            for (Intersectable b : this) n++;
            return n;
        }
        
        <additional aggregate methods>
	}
	
The most straightforward way to implement this is of course by storing the objects in a list.
	[rt/intersectables/IntersectableList.java]= 
	package rt.intersectables;
	<common imports>
	public class IntersectableList extends Aggregate {
		public LinkedList<Intersectable> list;
		public IntersectableList() {list = new LinkedList<Intersectable>();}
		public IntersectableList(Collection<Intersectable> i) {add(i);}
		public IntersectableList(Intersectable... i) {add(i);}
		public IntersectableList add(Collection<Intersectable> i) {list.addAll(i); return this;}
		public IntersectableList add(Intersectable... i) {list.addAll(Arrays.asList(i)); return this;} 
		public Iterator<Intersectable> iterator() {return list.iterator();}
	}
	
<h3>CSG</h3>
<img src=csg.png></img>
CSG objects are volumetric collections of points.
That is, they do not only have a surface but also a contained volume of points.
These point sets can be combined using set-theoretic operations, 
resulting in an tree with basic objects at the
leafs and operations at the internal nodes.

<p>
If a CSG object is intersected
by a ray, we determine all intersection intervals and their boundaries, that is, 
the intervals along the ray where the ray is either inside or outside the object. 
Each interval has two 
boundaries, a start and an end, where the ray enters and leaves the solid. 
	<get interval boundaries>=
	abstract ArrayList<IntervalBoundary> getIntervalBoundaries(Ray r);

The returned boundaries of intersection intervals have to be sorted by increasing t.
	<natural order of interval boundaries>=
	public int compareTo(IntervalBoundary b) {
		return (this.t <= b.t) ? -1 : 1; 
	}

An interval boundary is characterized as follows
	<interval boundary class>=
	class IntervalBoundary implements Comparable<IntervalBoundary>
	{		
		<t value of csg intersection>
		BoundaryType type;		
		HitRecord hitRecord;	
		BelongsTo belongsTo;
		
		public IntervalBoundary() {}
		public IntervalBoundary(float t) {this.t = t;}
		public IntervalBoundary(float t, HitRecord r) {this(t); this.hitRecord = r;}
		
		<natural order of interval boundaries>
	}
	
where
	<interval boundary class>+=
	public enum BoundaryType {START, END};
START marks a boundary where we enter the solid volume, END one where we leave it.
The member of type
	<interval boundary class>+=
	public enum BelongsTo {LEFT, RIGHT};
is used during merging of intervals in the Roth algorithm for internal CSG-graph nodes,
which have a left (‚A‘) and right (‚B‘) child.
It marks to which child an interval boundary belonged to in the merged list of boundaries.
<p>
The t value of intersection, i.e. distance the ray traveled before hitting can be
Float.POSITIVE_INFINITY and Float.NEGATIVE_INFINITY.
These values indicate that the volume is never left. 
In this case, the hitRecord attribute of this IntervalBoundary must be null.
t should also always be equal to hitRecord.t if hitRecord is set.
	<t value of csg intersection>=
	float t;	

CSGSolid is the base class of all CSG objects. 
	[rt/intersectables/CSGSolid.java]= 
	package rt.intersectables;
	<common imports>

	public abstract class CSGSolid extends Intersectable {
		<interval boundary class>
		<csg intersect with ray>
		<get interval boundaries>	
	}

<h4>Intersection</h4>
The actual intersection point with a csg object is the first interval boundary with positive t.
	<csg intersect with ray>=
	public HitRecord intersect(Ray r) {
		ArrayList<IntervalBoundary> intervalBoundaries = getIntervalBoundaries(r);
		
		<return first hit>
				
		return null;
	}
where
	<return first hit>=
	for (IntervalBoundary ib : intervalBoundaries) {
		HitRecord firstHit = ib.hitRecord;
		
		if (firstHit != null && firstHit.t > 0.f) {		
			firstHit.intersectable = this;
			return firstHit;			
		}
	}    
<h4>Combinators, Intermediate Nodes</h4>
<h5>CSGInstance</h5>
A CSGInstance node modulates the incoming ray and outgoing intervals to simulate a
linear transformation of the CSG object.
It does pretty much the same as Instance does for any Intersectables in general.

	[rt/intersectables/CSGInstance.java]= 
	package rt.intersectables;

	<common imports>
	public class CSGInstance extends CSGSolid {
		CSGSolid o;
		Matrix4f t, ti, tit;
		
		public CSGInstance(CSGSolid o, Matrix4f t) {
			<establish instance parameters>
		}
		
		ArrayList<IntervalBoundary> getIntervalBoundaries(Ray r_) {
			Ray r = Instance.transformRay(r_, ti);
			
			// Intersect
			ArrayList<IntervalBoundary> bs = o.getIntervalBoundaries(r);
			
			// Transform result
			for (IntervalBoundary b : bs) {
				if (b.hitRecord == null) continue;
				Instance.transformHitRecord(b.hitRecord, r_, t, tit);
			}
			return bs;
		}
	}
	
<img src="output/rt.testscenes.CSGInstanceTest 1SPP.png"></img>
	[rt/testscenes/CSGInstanceTest.java]= 
	package rt.testscenes;
	<common imports>
	public class CSGInstanceTest extends ObjectTest {
		public CSGInstanceTest()
		{
			super(new Vector3f(0.f, 0.f, 3.f));
			
			Matrix4f m = new Matrix4f(); m.setIdentity(); 
			m.setTranslation(new Vector3f(0.5f,0.2f,0.3f));
			CSGSolid a = new CSGInstance(new CSGSphere(), m);
			
			CSGSolid b = new CSGSphere();
			
			root = CSGNode.subtract(b,a);
		}
	}
	<test scenes>+=
	new CSGInstanceTest(),

<h5>CSGNode</h5>
A CSG node combines two CSG solids using a set operation, such as
intersection, addition, or subtraction.
It uses the Roth algorithm to combine the sets of intervals from the
left (A) and right (B) child. 
	<csg node>=
	protected CSGSolid left, right;

	public enum OperationType {
		INTERSECT, ADD, SUBTRACT
	};
	protected OperationType operation;

	public CSGNode(CSGSolid left, CSGSolid right, OperationType operation) {
		this.left = left;
		this.right = right;
		this.operation = operation;
	}
	
For convenience, we provide the following methods to construct such nodes
	<static csg node constructors>=
	public static CSGSolid intersect(CSGSolid... s) {
		return operate(OperationType.INTERSECT, s);
	}
	public static CSGSolid add(CSGSolid... s) {
		return operate(OperationType.ADD, s);
	}
	public static CSGSolid subtract(CSGSolid... s) {
		return operate(OperationType.SUBTRACT, s);
	}
which are implemented by repeating the binary operation, associating to the left:
	<static csg node constructors>+=
    public static CSGSolid operate(OperationType operation, CSGSolid... s) {
        assert s.length >= 1;
        if (s.length == 1) return s[0];
        CSGNode r = operate(operation, s[0], s[1]);
        for (int i = 2; i < s.length; i++)
            r = operate(operation, r, s[i]);
        return r;
    }
    
    public static CSGNode operate(OperationType operation, CSGSolid left, CSGSolid right) {
        return new CSGNode(left, right, operation);
    }
    
<h5>The Roth Algorithm</h5>
<img src=roth.png></img>
The getIntervalBoundaries(r) method of the CSGNode computes the combined intervals.
The main idea is to first get
the boundaries of the two CSG solids to be combined. Then, the boundaries
are merged according to the set operation specified by the node with the Roth algorithm.
	<csg node get interval boundaries>=
	public ArrayList<IntervalBoundary> getIntervalBoundaries(Ray r) {
		ArrayList<IntervalBoundary> leftIntervals = left.getIntervalBoundaries(r);
		ArrayList<IntervalBoundary> rightIntervals = right.getIntervalBoundaries(r);

		<interleave intervals>
		<roth combine intervals>
		<clean up intervals>

		return combined;
	}

During interleaving, we make use of the BelongsTo property of IntervalBoundary.
	<interleave intervals>=
	ArrayList<IntervalBoundary> combined =
					new ArrayList<IntervalBoundary>(leftIntervals.size() + rightIntervals.size());
	
	// Tag interval boundaries with left or right node and combine into one list
	tagAndCombine(combined, leftIntervals, 	BelongsTo.LEFT);
	tagAndCombine(combined, rightIntervals, BelongsTo.RIGHT);

	// sort by t
	Collections.sort(combined);
where
    <csg node get interval boundaries>+=
		private void tagAndCombine(
                Collection<IntervalBoundary> combined,
				Collection<IntervalBoundary> intervals, 
                BelongsTo tag) {
			for (IntervalBoundary b: intervals) {
				b.belongsTo = tag;
				combined.add(b);
			}
		}
        
The Roth algorithm merges the intervals according to the set operation of the node.
To do this, we traverse interval boundaries 'b' from low to high t and 
re-set the boundaries' BoundaryType property (START, END)
according to Boolean set operation used to combine the two child solids.
The traversal state includes whether we are currently within any interval of
the left child and whether we are currently within any interval of the right child.
	<roth combine intervals>=
		boolean inLeft = false, inRight = false;
		
		for (IntervalBoundary b : combined) {
			<determine whether we enter or leave some interval of left or right>
			
			// apply operation
			switch (operation) {
				case INTERSECT: 
					<apply intersect>
					break;
					
				case SUBTRACT: 
					<apply subtract>
					break;
					
				case ADD: 
					<apply add>
					break;
			}
		}
		
	<determine whether we enter or leave some interval of left or right>=
	switch (b.belongsTo) {
		case LEFT:
			inLeft = b.type == BoundaryType.START;
			break;
		case RIGHT:
			inRight = b.type == BoundaryType.START;
			break; 
	}
    
The "apply operation" phase reclassifies intersection- (or interval boundary-) points.
<ul>
<li>
If we are computing the intersection, an interval boundary is an entering boundary if we are in an interval of both left and right.	
	<apply intersect>=
	if (inLeft && inRight)
		b.type = BoundaryType.START;
	else
		b.type = BoundaryType.END;
<li>		
If we are computing the subtraction, an interval boundary is an entering boundary if we are in an interval of left and not of right.			
	<apply subtract>=
	if (inLeft && !inRight)
		b.type = BoundaryType.START;
	else
		b.type = BoundaryType.END;

In a subtract operation, the subtracted solid is turned inside out,
or it "switches sign", so we need to flip its normal direction		
	<apply subtract>+=
	if (b.belongsTo == BelongsTo.RIGHT && b.hitRecord != null) {
		b.hitRecord.normal.negate();
	}
<li>
If we are computing the union (add operation), any interval boundary is an entering boundary if we are in an interval of either left or right.
	<apply add>=
	if (inLeft || inRight)
		b.type = BoundaryType.START;
	else
		b.type = BoundaryType.END;
</ul>
In the clean-up phase we remove unnecessary interval boundaries:
We remove those where we have two boundaries of the same type (START or END) following each other.
	<clean up intervals>=
	Iterator<IntervalBoundary> it = combined.iterator();
	IntervalBoundary prev = new IntervalBoundary();
	prev.type = BoundaryType.END;
	while (it.hasNext()) {
		IntervalBoundary b = it.next();
		if (b.type == prev.type)
			it.remove();
		prev.type = b.type;
	}
	
	[rt/intersectables/CSGNode.java]= 
	package rt.intersectables;
	<common imports>
	public class CSGNode extends CSGSolid {
		<csg node>
        
		<static csg node constructors>
		
		<csg node get interval boundaries>
	}
		
<h4>Basic Objects, Leaf Nodes</h4>
<h5>Abstract Leaf</h5>
CSG leaf nodes are volumes, here defined as the set of all points p with f(p) <= 0 for some 'density' 
function f.
	<csg leaf volume definition>=
	public abstract float f(Vector3f p);
    
    public boolean isWithinVolume(Vector3f p) {return f(ray.origin) <= 0;}
    
The surface of a CSG volume is defined as the set of all points q with f(q) = 0.
The normal at a point on the surface is defined as normalize(∇f(q)).
	<csg leaf get normal>=
	public abstract Vector3f getUnnormalizedNormal(Vector3f q);
	
Each CSG volume must provide a method that computes all finite intersection times t_i such
that
    f(o + t_i * d) = 0
for a ray defined by origin o and d.
	<csg leaf compute finite intersection times>=
	public abstract ArrayList<Float> getFiniteIntersectionTimes(Ray r);

<h6>CSGLeaf intersection intervalcomputation</h6>
	<csg leaf get interval boundaries>=
	public ArrayList<IntervalBoundary> getIntervalBoundaries(Ray ray) {
		<convert finite intersection times to boundaries>
		<classify intersections>
		<add start end if needed>
		return boundaries;
	}
    
We construct interval boundaries corresponding by converting the
all finite intersection times 't' to
HitRecords and sorting them.
	<convert finite intersection times to boundaries>=
        ArrayList<Float> intersectionTimes = getFiniteIntersectionTimes(ray);
        <intersection times empty test>
        ArrayList<IntervalBoundary> boundaries = new ArrayList<IntervalBoundary>(intersectionTimes.size());
        for (Float t : intersectionTimes) {
            boundaries.add(new IntervalBoundary(
                t,
                new HitRecord(
                    ray,
                    t, 
                    this,
                    M.normalize(getUnnormalizedNormal(q))
                )
            ));
        }
        Collections.sort(boundaries);
The list of intersection times t may be null, i.e. empty. In that case, we return an empty list of
boundaries if the origin of the ray is not within the volume, otherwise we go on
with an empty list of finite intersection times.
	<intersection times empty test>=
	if (intersectionTimes == null) 
		if (!isWithinVolume(ray.origin))
			return new ArrayList<IntervalBoundary>();
		else
			intersectionTimes = new ArrayList<Float>();
            
We then classify the intersections as entering or leaving the volume.
	<classify intersections>=
	for (IntervalBoundary b : boundaries) {
		if (<ray leaves volume>)
			b.type = BoundaryType.END;
		else 
			b.type = BoundaryType.START;
	}
<img src=entercsg.jpg></img>
The ray leaves the volume when the surface normal (red in the above picture) 
and ray direction point into the same halfspace, otherwise it enters.
	<ray leaves volume>=
	M.sameHalfspace(b.hitRecord.normal, ray.direction)
	
Finally, we prepend an "enter" boundary at t = -∞ if there is none at the beginning,
and a "leave" boundary at t = +∞ if there is none at the end of the list.
	<add start end if needed>=
	if (boundaries.isEmpty() || boundaries.get(0).type == BoundaryType.END)
		boundaries.add(0, new IntervalBoundary(Float.NEGATIVE_INFINITY));
		
	if (boundaries.isEmpty() || boundaries.get(boundaries.size()-1).type == BoundaryType.START)
		boundaries.add(new IntervalBoundary(Float.POSITIVE_INFINITY));
	
	[rt/intersectables/CSGLeaf.java]= 
	package rt.intersectables;
	<common imports>
	public abstract class CSGLeaf extends CSGSolid {
		<csg leaf volume definition>
		<csg leaf get normal>
		<csg leaf compute finite intersection times>
		<csg leaf get interval boundaries>
	}
    
<h5>Concrete primitives</h5>
The solutions for the intersection times and the 
gradients for the functions implemented below 
were found with Mathematica using:
	r[t_] := {ox, oy, oz} + t {dx, dy, dz};
    
	f[{x_, y_, z_}] := (* insert definition of f here *);
    
	Solve[f[r[t]] == 0, t] // FullSimplify // InputForm
	{D[f[{x, y, z}], x], D[f[{x, y, z}], y], D[f[{x, y, z}], z]} // 
	  FullSimplify // InputForm
      
Where we abbreviated the ray attributes as
	<rename ray variables>=
	float ox, oy, oz, dx, dy, dz;
	ox = r.origin.x;
	oy = r.origin.y;
	oz = r.origin.z;
	dx = r.direction.x;
	dy = r.direction.y;
	dz = r.direction.z;
    
In the case of the two sided infinite cone, this gives something like
    {{t -> -((dx*ox + dy*oy - dz*oz + 
		  Sqrt[4*(dx*ox + dy*oy - dz*oz)^2 - 
			 4*(dx^2 + dy^2 - dz^2)*(ox^2 + oy^2 - oz^2)]/2)/
		 (dx^2 + dy^2 - dz^2))}, 
	 {t -> (-(dx*ox) - dy*oy + dz*oz + 
		 Sqrt[4*(dx*ox + dy*oy - dz*oz)^2 - 
			4*(dx^2 + dy^2 - dz^2)*(ox^2 + oy^2 - oz^2)]/2)/
		(dx^2 + dy^2 - dz^2)}}
	{2*x, 2*y, -2*z}

The last line of this result tells us to implement the gradient as
    public Vector3f getUnnormalizedNormal(Vector3f q) {
        return new Vector3f(q.x, q.y, -q.z);
    }
(the scaling with 2 does not matter).
The result also tells us that in getFiniteIntersectionTimes
we first need to compute the expression within the
square root (which is the same for both expressions). 
If it is negative, there are no hits.
Otherwise they are as stated.
The method thus boils down to
    public ArrayList<Float> getFiniteIntersectionTimes(Ray r) {
        <rename ray variables>
        float D = 4*(dx*ox + dy*oy - dz*oz)*(dx*ox + dy*oy - dz*oz) - 
     4*(dx*dx + dy*dy - dz*dz)*(ox*ox + oy*oy - oz*oz);
        if (D < 0) return null;
        
        ArrayList<Float> l = new ArrayList<Float>(2);
        
        l.add(
            -((dx*ox + dy*oy - dz*oz + M.sqrtf(D)/2)/(dx*dx + dy*dy - dz*dz))
        );
        
        l.add(
            (-(dx*ox) - dy*oy + dz*oz + M.sqrtf(D)/2)/(dx*dx + dy*dy - dz*dz)
        );
        return l;
    }
            
<h5>XY CSGPlane</h5>	
	<plane definition>=
	p.z

	[rt/intersectables/CSGXYPlane.java]= 
	package rt.intersectables;
	<common imports>
	public class CSGXYPlane extends CSGLeaf {
		public Vector3f getUnnormalizedNormal(Vector3f q) {
			return new Vector3f(1,0,0);
		}
		
		public float f(Vector3f p) {
			return <plane definition>;
		}
		
		public ArrayList<Float> getFiniteIntersectionTimes(Ray ray) {
			if (ray.direction.z == 0) return null;
            ArrayList<Float> l = new ArrayList<Float>(1);
			l.add(-(ray.origin.z/ray.direction.z));
			return l;
		}
	}
	
		
<img src="output/rt.testscenes.CSGXYPlaneTest 1SPP.png"></img>	
	[rt/testscenes/CSGXYPlaneTest.java]= 
	package rt.testscenes;
	<common imports>

	public class CSGXYPlaneTest extends PinholeCameraScene {
		public CSGXYPlaneTest()
		{
			Vector3f eye = new Vector3f(0.f, 0.f, 3.f);
			Vector3f lookAt = new Vector3f(0.f, 0.f, 0.f);
			setCamera(eye, lookAt, <up vector>);
			
			integratorFactory = new DebugIntegratorFactory();
			
			root = new CSGXYPlane();
		}
	}
	<test scenes>+=
	new CSGXYPlaneTest(),

<h5>UnitSphere</h5>
    <sphere definition>=
	p.x*p.x + p.y*p.y + p.z*p.z

    [rt/intersectables/CSGUnitSphere.java]= 
	package rt.intersectables;
	<common imports>
	public class CSGUnitSphere extends CSGLeaf {
		public Vector3f getUnnormalizedNormal(Vector3f q) {
			return q;
		}
		
		public float f(Vector3f p) {
			return <sphere definition>;
		}
		
		public ArrayList<Float> getFiniteIntersectionTimes(Ray ray) {
			<rename ray variables>
			float D = 4*M.sqr(dx*ox + dy*oy + dz*oz) - 4*(dx*dx + dy*dy + dz*dz)*(ox*ox + oy*oy + oz*oz);
			if (D < 0) return null;
			
			ArrayList<Float> l = new ArrayList<Float>(2);
			
			l.add(
				-((dx*ox + dy*oy + dz*oz + M.sqrtf(D)/2)/(dx*dx + dy*dy + dz*dz))
			);
			
			l.add(
				(-2*dx*ox - 2*dy*oy - 2*dz*oz + M.sqrtf(D))/(2*(dx*dx + dy*dy + dz*dz))
			);
			return l;
		}
	}
    
<h5>Cone</h5>
A cone for CSG operations. 
The cone represents a solid cone shaped volume, defined by
	<cone definition>=
	p.x*p.x + p.y*p.y - p.z*p.z
	
	[rt/intersectables/CSGTwoSidedInfiniteCone.java]= 
	package rt.intersectables;
	<common imports>
	public class CSGTwoSidedInfiniteCone extends CSGLeaf {
		public Vector3f getUnnormalizedNormal(Vector3f q) {
			return new Vector3f(q.x, q.y, -q.z);
		}
		
		public float f(Vector3f p) {return <cone definition>;}
		
		public ArrayList<Float> getFiniteIntersectionTimes(Ray r) {
			<rename ray variables>
			float D = 4*(dx*ox + dy*oy - dz*oz)*(dx*ox + dy*oy - dz*oz) - 
         4*(dx*dx + dy*dy - dz*dz)*(ox*ox + oy*oy - oz*oz);
			if (D < 0) return null;
			
			ArrayList<Float> l = new ArrayList<Float>(2);
			
			l.add(
				-((dx*ox + dy*oy - dz*oz + M.sqrtf(D)/2)/(dx*dx + dy*dy - dz*dz))
			);
			
			l.add(
				(-(dx*ox) - dy*oy + dz*oz + M.sqrtf(D)/2)/(dx*dx + dy*dy - dz*dz)
			);
			return l;
		}
	}	
<img src="output/rt.testscenes.ConeTest 1SPP.png"></img>
	[rt/testscenes/ConeTest.java]= 
	package rt.testscenes;
	<common imports>
	public class ConeTest extends ObjectTest {
		public ConeTest() {
			super(new Vector3f(3.f, 0.f, 0.f));
			root = new CSGTwoSidedInfiniteCone();
		}
	}
	<test scenes>+=
	new ConeTest(),
	
<img src="output/rt.testscenes.ConeNormalTest 1SPP.png"></img>
	[rt/testscenes/ConeNormalTest.java]= 
	package rt.testscenes;
	<common imports>
	public class ConeNormalTest extends ObjectNormalTest {
		public ConeNormalTest() {
			super(new Vector3f(3.f, 0.f, 0.f));
			root = new CSGTwoSidedInfiniteCone();
		}
	}	
	<test scenes>+=
	new ConeNormalTest(),
		
<h5>Cylinder</h5>
	<cylinder definition>=
	p.x*p.x + p.y*p.y - 1
The solutions for the intersection times and the gradient were found with Mathematica:
	r[t_] := {ox, oy, oz} + t {dx, dy, dz};
	f[{x_, y_, z_}] := x^2 + y^2 - 1;
	Solve[f[r[t]] == 0, t] // FullSimplify // InputForm
	{D[f[{x, y, z}], x], D[f[{x, y, z}], y], D[f[{x, y, z}], z]} // 
	  FullSimplify // InputForm
giving
	{{t -> -((dx*ox + dy*oy + Sqrt[-(dy^2*(-1 + ox^2)) + 
        dx*(dx + 2*dy*ox*oy - dx*oy^2)])/(dx^2 + dy^2))}, 
	 {t -> (-(dx*ox) - dy*oy + Sqrt[-(dy^2*(-1 + ox^2)) + 
       dx*(dx + 2*dy*ox*oy - dx*oy^2)])/(dx^2 + dy^2)}}
	{2*x, 2*y, 0}
	   
	[rt/intersectables/CSGInfiniteCylinder.java]= 
	package rt.intersectables;
	<common imports>
	
	public class CSGInfiniteCylinder extends CSGLeaf {
		public Vector3f getUnnormalizedNormal(Vector3f q) {
			return new Vector3f(q.x, q.y, 0);
		}
		
		public float f(Vector3f p) {return <cylinder definition>;}
		
		public ArrayList<Float> getFiniteIntersectionTimes(Ray r) {
			<rename ray variables>
			float D = -(dy*dy*(-1 + ox*ox)) +  dx*(dx + 2*dy*ox*oy - dx*oy*oy);
			if (D < 0) return null;
			
			ArrayList<Float> l = new ArrayList<Float>(2);
			l.add(
				-((dx*ox + dy*oy + M.sqrtf(D))/(dx*dx + dy*dy))
			);
			
			l.add(
				(-(dx*ox) - dy*oy + M.sqrtf(D))/(dx*dx + dy*dy)
			);
			return l;
		}
	}	
					
<img src="output/rt.testscenes.CylinderTest 1SPP.png"></img>	
	[rt/testscenes/CylinderTest.java]= 
	package rt.testscenes;
	<common imports>
	public class CylinderTest extends ObjectNormalTest {
		public CylinderTest() {
			super(new Vector3f(3.f, 0.f, 0.f));
			root = new CSGInfiniteCylinder();
		}
	}
	<test scenes>+=
	new CylinderTest(),

<h4>Compound CSG Objects</h4>
The following objects are pre combined CSG objects.
	
	[rt/intersectables/CSGCompound.java]= 
	package rt.intersectables;
	<common imports>
	public class CSGCompound extends CSGSolid {
		public CSGSolid root;
		ArrayList<IntervalBoundary> getIntervalBoundaries(Ray r)
		{
			return root.getIntervalBoundaries(r);
		}
	}

<h5>Sphere</h5>
A sphere for CSG operations. 
The sphere represents a solid spherical shaped volume, so it is
Mathematically speaking a ball.

	[rt/intersectables/CSGSphere.java]= 
	package rt.intersectables;
	<common imports>

	public class CSGSphere extends CSGSolid {
		public CSGSphere(Vector3f center, float radius) {		
			Matrix4f m = new Matrix4f(); m.setIdentity();
            m.m00 = radius;                                 m.m03 = center.x;
                            m.m11 = radius;                 m.m13 = center.y;
                                            m.m22 = radius; m.m23 = center.z;
            
			CSGPlane p1 = new CSGInstance(new CSGXYPlane(), m);
			root = p1;
		}
	}
	
<img src="output/rt.testscenes.SphereTest 1SPP.png"></img>	
	[rt/testscenes/SphereTest.java]= 
	package rt.testscenes;
	<common imports>
	public class SphereTest extends PinholeCameraScene {

		public SphereTest()
		{
			super(new Vector3f(0.f, 0.f, 3.f));
			
			CSGSphere a = new CSGSphere(new Vector3f(0.5f,0.2f,0.3f), 1);
			CSGSphere b = new CSGSphere(new Vector3f(0.0f,0,0), 1);
			
			root = CSGNode.subtract(b,a);
		}
	}
	<test scenes>+=
	new SphereTest(),
            
<h5>CSGPlane</h5>	
A plane for CSG operations. 
The plane represents a solid that fills a whole half-space.
The plane normal is assumed to point into the empty half-space, 
and the plane occupies the half-space opposite to the normal.
The plane is defined by its (normalized) normal and the signed
distance of the plane to the origin, along the opposite normal direction.
Thus, the plane with normal 0,0,1 and d = -2 is the plane z = 2.

	[rt/intersectables/CSGPlane.java]= 
	package rt.intersectables;
	<common imports>
	public class CSGPlane extends CSGCompound {
		public CSGPlane(Vector3f n, float d)
		{
            Vector3f t1 = M.tangentTo(n);
            Vector3f t2 = M.cross(n, t1);
            
            Matrix4f m = new Matrix4f(); m.setIdentity();
            m.m00 = t1.x; m.m01 = t2.x; m.m02 = n.x; m.m03 = -d*n.x;
            m.m10 = t1.y; m.m11 = t2.y; m.m12 = n.y; m.m13 = -d*n.y;
            m.m20 = t1.z; m.m21 = t2.z; m.m22 = n.z; m.m23 = -d*n.z;
            
			CSGPlane p1 = new CSGInstance(new CSGXYPlane(), m);
			root = p1;
		}
	}
    
The following tests demonstrate how the plane parametrization works.
You should see nothing on this image, because the plane is exactly at the camera position
<img src="output/rt.testscenes.CSGPlaneTest 1SPP.png"></img>	
	[rt/testscenes/CSGPlaneTest.java]= 
	package rt.testscenes;
	<common imports>
	public class CSGPlaneTest extends ObjectTest {
		public CSGPlaneTest()
		{
			super(new Vector3f(0.f, 0.f, 3.f));
			root = new CSGPlane(new Vector3f(0,0,1), -3);
		}
	}
	<test scenes>+=
	new CSGPlaneTest(),
You should see an infinite plane (in debug output) facing you in this test.
<img src="output/rt.testscenes.CSGPlaneTest2 1SPP.png"></img>	
	[rt/testscenes/CSGPlaneTest2.java]= 
	package rt.testscenes;
	<common imports>
	public class CSGPlaneTest2 extends ObjectTest {
		public CSGPlaneTest2()
		{
			super(new Vector3f(0.f, 0.f, 3.f));
			root = new CSGPlane(new Vector3f(0,0,1), 3);
		}
	}
	<test scenes>+=
	new CSGPlaneTest2(),
    
<h5>CSGCube</h5>
A cube implemented using planes and CSG. The cube occupies the volume [-1,1] x [-1,1] x [-1,1]. 
	[rt/intersectables/CSGCube.java]= 
	package rt.intersectables;
	<common imports>
	public class CSGCube extends CSGCompound {
		
		public CSGCube()
		{
			CSGPlane p1 = new CSGPlane(new Vector3f(1.f,0.f,0.f),-1.f);
			CSGPlane p2 = new CSGPlane(new Vector3f(-1.f,0.f,0.f),-1.f);
			CSGPlane p3 = new CSGPlane(new Vector3f(0.f,1.f,0.f),-1.f);
			CSGPlane p4 = new CSGPlane(new Vector3f(0.f,-1.f,0.f),-1.f);
			CSGPlane p5 = new CSGPlane(new Vector3f(0.f,0.f,1.f),-1.f);
			CSGPlane p6 = new CSGPlane(new Vector3f(0.f,0.f,-1.f),-1.f);
			root = CSGNode.intersect(p1, p2, p3, p4,p5, p6);
		}
	}
<h5>CSGCappedZTunnel</h5>
A square tunnel from -1 to 1 with an opening at the side +z. The face -z is closed.
	[rt/intersectables/CSGCappedZTunnel.java]= 
	package rt.intersectables;
	<common imports>
	public class CSGCappedZTunnel extends CSGCompound {
		public CSGCappedZTunnel()
		{
			CSGPlane p1 = new CSGPlane(new Vector3f(1.f, 0.f, 0.f), 1.f);
			CSGPlane p2 = new CSGPlane(new Vector3f(-1.f, 0.f, 0.f), 1.f);
			CSGPlane p3 = new CSGPlane(new Vector3f(0.f, 1.f, 0.f), 1.f);
			CSGPlane p4 = new CSGPlane(new Vector3f(0.f, -1.f, 0.f), 1.f);
			CSGPlane p5 = new CSGPlane(new Vector3f(0.f, 0.f, 1.f), 1.f);
			root = CSGNode.add(p1, p2, p3, p4, p5);
		}
	}
	
<h5>CSGUnitCylinder</h5>
A cylinder along the z axis from -0.5 to 0.5 of radius 1.	
	[rt/intersectables/CSGUnitCylinder.java]= 
	package rt.intersectables;
	<common imports>

	public class CSGUnitCylinder extends CSGCompound {
		public CSGUnitCylinder()
		{
			root = CSGNode.intersect(
				new CSGPlane(new Vector3f(0.f,0.f,1.f),-1.f, m),
				new CSGPlane(new Vector3f(0.f,0.f,-1.f),-1.f, m),
				new CSGInfiniteCylinder()
			);
		}
	}
	
In the test scene, we look at it from the side, i.e. from the +x axis, from
	<unit cylinder origin>=
	3.f, 0.f, 0.f
to be precise.
<img src="output/rt.testscenes.UnitCylinderTest 1SPP.png"></img>	
	[rt/testscenes/UnitCylinderTest.java]= 
	package rt.testscenes;
	<common imports>
	public class UnitCylinderTest extends ObjectTest {

		public UnitCylinderTest()
		{
			super(new Vector3f(<unit cylinder origin>));
			root = new CSGUnitCylinder();
		}
	}
	<test scenes>+=
	new UnitCylinderTest(),
<h5>CSGDodecahedron</h5>
A dodecahedron implemented using planes and CSG. The dodecahedron has its center at [0,0,0]. 
All planes are at unit distance from the origin.
It makes a dodecahedron by specifying planes that contain faces, and using CSG
intersection. Face normals are computed using the facts that in a dodecahedron
(1) the top and bottom faces are uniform pentagons, (2) dihedral angles
(a dihedral or torsion angle is the angle between two planes) between 
all faces are 
    pi - arctan(2).
	[rt/intersectables/CSGDodecahedron.java]= 
	package rt.intersectables;
	<common imports>
	public class CSGDodecahedron extends CSGCompound {

		public CSGDodecahedron()
		{
			Vector3f normal;
			
			// Make CSG planes
			CSGPlane planes[] = new CSGPlane[12];
			
			// Bottom half
			normal  = new Vector3f(0.f, -1.f, 0.f);
			planes[0] = new CSGPlane(normal, -1.f);	

			for(int i=0; i<5; i++)
			{
				float x, y, z;
				float theta;
			
				// Make face normals, using facts that in a dodecahedron
				// - top and bottom faces are uniform pentagons
				// - dihedral angles between all faces are pi - arctan(2)
				theta = (float)i * 2.f*(float)Math.PI / 5.f;
				x = (float)(Math.sin(theta) * Math.sin(Math.atan(2.f)));
				z = (float)(Math.cos(theta) * Math.sin(Math.atan(2.f)));
				y = -(float)(Math.cos(Math.atan(2.f)));
				
				normal = new Vector3f(x, y, z);
				planes[i+1] = new CSGPlane(normal, -1.f);	
			}
			
			// Top half
			normal = new Vector3f(0.f, 1.f, 0.f);
			planes[6] = new CSGPlane(normal, -1.f);		

			for(int i=0; i<5; i++)
			{
				float x, y, z;
				float theta;
				
				// Make face normals
				theta = ((float)i+0.5f) * 2.f*(float)Math.PI / 5.f;
				x = (float)(Math.sin(theta) * Math.sin(Math.atan(2.f)));
				z = (float)(Math.cos(theta) * Math.sin(Math.atan(2.f)));
				y = (float)(Math.cos(Math.atan(2.f)));
				
				normal = new Vector3f(x, y, z);
				planes[i+7] = new CSGPlane(normal, -1.f);	
			}
					
			// Build CSG tree (just intersect all of it - this is a convex volume after all).
			root = new CSGNode.intersect(planes);
		}
	}

<h3>Distance Fields</h3>
A (signed) distance field is similar to a CSG solid in that it is defined by a function f
taking three coordinates as arguments and returning a real number that is 0 at the surface (and negative within the volume).
Indeed, every distance field is a CSG solid, however the converse does not hold.
For f(x, y, z) to define a distance field, the value f(x, y, z) must be exactly or less than
the distance to the nearest contact point with the surface of the volume we are defining.
Remember that for a CSG solid, f(x, y, z) is allowed to be anything, as long as it is
(hopefully continuous) and negative within the volume, 0 on its surface and positive outside.
<p>
However for a distance field, this number must give the radius of a sphere that could be constructed
around the point x, y, z so that it at most touches, but does not intersect, the volume that is being defined.

The distance information is used to march through the distance field efficiently.
<img src=raymarch.png></img>
See <a href=http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm>here</a> for some examples of distance functions.
Some slides about the technique can be found
<a href=http://www.iquilezles.org/www/material/nvscene2008/nvscene2008.htm>here</a>.
We require all basic objects to give a maximum radius r of a sphere centered in the origin which fully contains 
them for optimization purposes.
	<maximum radius>=
	public float maximumRadius = 100.f;
Furthermore, every object can have a minimum ray-march-step size, 
which is also used to compute an approximate normal of the distance field
using symmetric differences.
	<minimal step size>=
	public float minimumStepSize = 0.001f;
<h4>Intersection Algorithm - Distance Marching</h4>
We step through the fields in steps of size given by the f function
at the current origin of a unit marching ray that starts at the input ray position.
    <march step size>=
    Math.abs(f(mr.origin))
we take the absolute value since we want to find intersections when we start on the inside of 
surfaces as well.
    
	<df intersect>=
	public HitRecord intersect(Ray r) {
		<construct marching ray mr of normalized length>
		float totalS = 0.f;
		while (canHitContainingSphere(mr)) {
			float s = <march step size>;     totalS += s;
			mr.origin = mr.t(s);
            
			<no hit>
			<process hit>
		}
		return null;
	}

	<construct marching ray mr of normalized length>=
	Vector3f d = new Vector3f(r.direction);
	float originalLength = M.normalizeAndGetLength(d);
	Ray mr = new Ray(r.origin, d);

Once the step size falls below or threshold, we assume a hit.
Otherwise, we do another step of size s.
	<no hit>=
        if (s > minimumStepSize) continue;
        
	<process hit>=
        return new HitRecord(
            mr,
            <compute t>, 
            this, 
            normal(mr.origin)
        );
    
The computation
	<compute t>=
	totalS/originalLength
converts totalS back to „t“ units of the original direction vector and
	<math utilities>+=
	public static float normalizeAndGetLength(Vector3f v) {
		float l = v.length();
		v.scale(1/l);
		return l;
	}
is a fused operation to speed things up a little.
The helper method
	<df intersect>+=
	private boolean canHitContainingSphere(Ray r) {
		float t = Math.max(
			M.intersectSphere(new Vector3f(), maximumRadius, r, -1),
			M.intersectSphere(new Vector3f(), maximumRadius, r, 1)
		);
		return t >= 0;
	}
determines whether the given ray can still hit the containing
sphere from the outside or inside with a positive t (that is, whether r is still 'in front of'
or 'inside' the given sphere).

<h4>Distance Field Normal</h4>
The normal is approximated by taking the central differences along each axis.
In that sense, distance fields, and csg’s can be regarded as density fields,
where this is a common approach to determine the normal.
	<df normal>=
	private float fa(Vector3f p, float x, float y, float z) {
		return f(M.add(p, new Vector3f(x* minimumStepSize, y* minimumStepSize, z* minimumStepSize)));
	}
	private float cd(Vector3f p, float x, float y, float z) {
		return fa(p, x, y, z) - fa(p, -x, -y, -z);
	}	
	public Vector3f normal(Vector3f p) {
		float xd = cd(p, 1.f, 0, 0),
		      yd = cd(p, 0, 1.f, 0),
		      zd = cd(p, 0, 0, 1.f);
		Vector3f n = new Vector3f(xd, yd, zd); n.normalize();
		return n;
	}
<h4>Distance Field</h4>
The only function implementations of the DistanceField base class need to implement is the
f function.
	[rt/intersectables/DistanceField.java]= 
	package rt.intersectables;
	<common imports>
	public abstract class DistanceField extends Intersectable {
		<minimal step size>
		<maximum radius>
        
		public abstract float f(Vector3f p);

		<df normal>
		<df intersect>
	}
    
<h4>Difference between signed and unsigned fields</h4>
The operations below assume a signed distance field, that is, one where the f function 
is negative inside the volume.
Notice that the intersection algorithm per se would also work with an unsigned field 
i.e. one which is positive on both sides of the surface.
However, the normal computation would not work.

<h4>Distance Field Connectives</h4>
Distance fields can be combined with operations similar to csg operations, and more.
<h5>DFNode</h5>
Issue: We still need to compute combined maximum radius.
Also, I do not know why (or whether always) it works with the
provided smin/smax functions, given they might modify the distances to some value that
is too big (too small does not matter).
So probably smax does not (always) work (?).

	[rt/intersectables/DFNode.java]= 
	package rt.intersectables;
	<common imports>
	public class DFNode extends DistanceField {
		public enum DFOperationType {
			INTERSECT, ADD, SUBTRACT,
			SMOOTH_INTERSECT, SMOOTH_ADD, SMOOTH_SUBTRACT,
		};

		DFOperationType o;
		DistanceField a, b;
		
		public float f(Vector3f p) {
			switch(o) {
				case ADD:
					return Math.min(a.f(p), b.f(p));
				case INTERSECT:
					return Math.max(a.f(p), b.f(p));
				case SUBTRACT:			
					return Math.max(a.f(p), -b.f(p));

				case SMOOTH_ADD:
					return M.smin(a.f(p), b.f(p));
				case SMOOTH_INTERSECT:
					return M.smax(a.f(p), b.f(p));
				case SMOOTH_SUBTRACT:			
					return M.smax(a.f(p), -b.f(p));
			}
			return 0.f;
		}

		public DFNode(DistanceField a, DistanceField b, DFOperationType o) {
			this.a = a; this.b = b; this.o = o;
		}
	}
Where
	<math utilities>+=
	// Like GLSL mix, = a if h = 1, blends to b
	public static float mix(float a, float b, float h) {
    		return (1-h)*a + h*b;
	}
	static final float smink = 0.1f;
	public static float smin(float a, float b) {
		float h = clamp( 0.5f+0.5f*(b-a)/smink, 0.0f, 1.0f );
    	return mix( b, a, h ) - smink*h*(1.0f-h);
	}
	/*Other smooth minimum functions:
	float res = exp( -k*a ) + exp( -k*b ); // k = 32
    return -log( res )/k;
	
	float a = pow( a, k ), b = pow( b, k ); // k = 8
  	return pow( (a*b)/(a+b), 1.0f/k );
	*/

	public static float smax(float a, float b) {
		return -smin(-a, -b);
	}
	
are <a href=http://www.iquilezles.org/www/articles/smin/smin.htm>smooth minimum/maximum functions</a>.
<h6>Demo</h6>
Here is the difference between standard minimum/csg subtraction:

<img src="output/rt.testscenes.DFTestCSG 1SPP.png"></img>	
	[rt/testscenes/DFTestCSG.java]= 
	package rt.testscenes;
	<common imports>
	public class DFTestCSG extends ObjectNormalTest {
		public DFTestCSG()
		{
			super(new Vector3f(3.f, 0.f, 0.f));
			
			integratorFactory = new NormalDebugIntegratorFactory();
			CSGSolid a = new CSGSphere(new Vector3f(), 1);
			<make matrix>
			CSGSolid b = new CSGInstance(new CSGSphere(<sphere two>), m); 
			root = new CSGNode(a, b, OperationType.SUBTRACT);
		}
	}
	<test scenes>+=
	new DFTestCSG(),
and SMOOTH_SUBTRACT of two spheres:
<img src="output/rt.testscenes.DFTest 1SPP.png"></img>	
	[rt/testscenes/DFTest.java]= 
	package rt.testscenes;
	<common imports>
	public class DFTest extends ObjectNormalTest {
		public DFTest()
		{
			super(new Vector3f(3.f, 0.f, 0.f));
			
			DistanceField a = new DFSphere(new Vector3f(), 1);
			<make matrix>
			DistanceField b = new DFInstance(new DFSphere(<sphere two>), m); 
			root = new DFNode(a, b, DFOperationType.SMOOTH_SUBTRACT);
		}
	}
	<test scenes>+=
	new DFTest(),
	
In this scene the second sphere is squashed along the z axis, which points to the left
since we are watching from 3,0,0.
	<make matrix>=
	Matrix4f m = new Matrix4f(); m.setIdentity();
	m.m22 = 0.5f;
	<sphere two>=
	new Vector3f(0.3f,0.2f,0.27f), 0.75f

<h5>DFInstance</h5>
Looking up the distance function in a uniformly linearly transformed distance field is trivial.

Issue: What does this do to the containing sphere’s radius, maximumRadius? 
We might need to extract the scaling component of the transformation, maybe also the shear, and the translation. A rotation (around the origin) has no influence.
Certainly, nothing needs to change when you don’t move the object too much, e.g. when just rotating.
Can I just use Matri4f.getScale?

	[rt/intersectables/DFInstance.java]= 
	package rt.intersectables;
	<common imports>
	public class DFInstance extends DistanceField {
		DistanceField o;
		Matrix4f t;
		
		public float f(Vector3f p) {
			p = M.transformVectorAsPoint(t, p);
			return o.f(p);
		}

		public DFInstance(DistanceField o, Matrix4f t) {
			t = new Matrix4f(t); t.invert();
			this.t = t; this.o = o;
		}
	}
Note: When the deformations are not too big, we can even use non-uniform transformations with distance fields.
See  <a href=http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm>here under 'domain deformations'</a>.

<h4>Distance Field Primitives</h4>
See <a href=http://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm>here</a> 
for some examples of distance functions.
	[rt/intersectables/DFSphere.java]= 
	package rt.intersectables;
	<common imports>
	public class DFSphere extends DistanceField {
		Vector3f c; float r; 
		public float f(Vector3f p) {
			return M.sub(p, c).length() - r;
		}

		public DFSphere(Vector3f c, float r) {
			this.c = c;
			this.r = r;			
			maximumRadius = c.equals(new Vector3f()) ? r : <determine radius of containing sphere at origin>;
			maximumRadius *= 1.1f; // just for the fun
		}
	}
    
To determine the radius, notice that we must also consider the case where c = 0.
In the other case, we can do:
	<determine radius of containing sphere at origin>=
	M.t(c, M.normalize(c), r).length()

Note: We might be able to optimize things further by allowing the 'containing sphere' to be
centered anywhere.

<h3>Instance</h3>
An instance of an intersectable is defined by an object o of which is represents
an instance, and a transformation matrix t specifying where to place this „copy“.
	<establish instance parameters>=
	this.t = new Matrix4f(t);
	ti = M.invert(t);
	tit = new Matrix4f(ti);
	tit.transpose(); 
	this.o = o;
tit is t inverse transposed. It is the special transformation matrix needed for normals.
<img src=titnormals.png></img>
Because other instancing classes share lots of code with this, we define the transformation of ray and result as static functions:
	<transform ray>=
	public static Ray transformRay(Ray r_, Matrix4f ti) {
		Ray r = new Ray(r_.origin, r_.direction);
		ti.transform(r.direction);
		r.origin = M.transformVectorAsPoint(ti, r.origin);
		return r;
	}
		
	<transform hit record>=
	public static HitRecord transformHitRecord(HitRecord h, Ray r_, Matrix4f t, Matrix4f tit) {
		M.transformVectorAsPoint(t, h.position);
		tit.transform(h.normal);	
		// Set the untransformed incoming direction
		h.w = M.negate(r_.direction);
		return h;
	}

	[rt/intersectables/Instance.java]= 
	package rt.intersectables;
	<common imports>

	public class Instance extends Intersectable {
		private Intersectable o;
		private Matrix4f t, ti, tit; 
		public Instance(Intersectable o, Matrix4f t) {
			<establish instance parameters>
		}

		public HitRecord intersect(Ray r_) {
			Ray r = transformRay(r_, ti);
			HitRecord h = o.intersect(r);
			if (h == null) return null;
			return transformHitRecord(h, r_, t, tit);
		}

		<transform ray>
		<transform hit record>		
	}
	
Test for instancing functionality. Note: the spheres look strange (elliptical) and
it looks like they intersect a bit because of perspective projection!
<img src="output/rt.testscenes.InstancingTest 1SPP.png"></img>	
	[rt/testscenes/InstancingTest.java]= 
	package rt.testscenes;
	<common imports>
	public class InstancingTest extends ObjectTest {
		public InstancingTest()
		{
			super(new Vector3f(0.f, 0.f, 3.f));
			setDimensions(1280, 720);

			CSGSphere sphere = new CSGSphere();
			
			Matrix4f translation = new Matrix4f();
			translation.setIdentity();
			translation.setTranslation(new Vector3f(2.0f, 0.f, 0.f));
			Instance sphere2 = new Instance(sphere, translation);
			
			translation.setTranslation(new Vector3f(-2.0f, 0.f, 0.f));
			Instance sphere3 = new Instance(sphere, translation);
			
			root = new IntersectableList(sphere, sphere2, sphere3);
		}
	}
	<test scenes>+=
	new InstancingTest(),

<h3>Mesh</h3>
A triangle mesh is a list of triangles.
The mesh internally stores the triangles using vertex and index arrays
instead of copying these properties to every triangle it is made of. 

	<mesh vertices>=
	public float[] vertices;
Stores x,y,z coordinates for each vertex consecutively.
	<mesh normals>=
	public float[] normals;
Stores x,y,z component for each vertex-normal consecutively.
<p>
Each triangle is defined by three consecutive indices in the indices array.
	<mesh indices>=
	public int[] indices;
The indices i refer to the vertices and normals arrays that store vertex and normal coordinates: 
the i-th vertex occupies locations {3*i+0, 3*i+1, 3*i+2} in the vertices array.
The mesh instantiates a MeshTriangle for each triangle,
	<mesh triangles>=
	private MeshTriangle[] triangles;
and the mesh provides an iterator to iterate through the triangles.
	<triangle iterator>=
	public Iterator<Intersectable> iterator() {
		return new MeshIterator(triangles);
	}
		
	private class MeshIterator implements Iterator<Intersectable> {
		private int i = 0;
		private MeshTriangle[] triangles;
			
		public MeshIterator(MeshTriangle[] triangles) {
			this.triangles = triangles;
		}
			
		public boolean hasNext() {
			return i < triangles.length;
		}
			
		public MeshTriangle next() {
			int j = i; i++;
			return triangles[j];
		}

		public void remove() {}
	}
	[rt/intersectables/Mesh.java]= 
	package rt.intersectables;
	<common imports>
	public class Mesh extends Aggregate {
		<mesh vertices>
		<mesh normals>
		<mesh indices>
		<mesh triangles>
        
        <additional mesh data>
        
		<triangle iterator>
		
		public Mesh(float[] vertices, float[] normals, int[] indices)
		{
			this.vertices = vertices;
			this.normals = normals;
			this.indices = indices;

			triangles = new MeshTriangle[indices.length/3];		
			for(int i=0; i<indices.length/3; i++)
				triangles[i] = new MeshTriangle(this, i);
		}	
	}
	
    <additional mesh data>=
    
Test scene for rendering triangle meshes.	
<img src="output/rt.testscenes.TeapotTest 1SPP.png"></img>	
	[rt/testscenes/TeapotTest.java]= 
	package rt.testscenes;
	<common imports>
	public class TeapotTest extends ObjectTest {
		public TeapotTest()
		{	
			super(new Vector3f(0.f,0.f,2.f));
			root = <load teapot>;
		}
	}
	<load teapot>=
	ObjReader.read("obj/teapot.obj", 0.95f)
	<test scenes>+=
	new TeapotTest(),
	
<h4>MeshTriangle</h4>	
MeshTriangle defines a triangle by referring back to a Mesh
and its vertex and index arrays to look up the vertex data. 	
<p>
Convention is that vertex order is counter
clockwise when the triangle is seen from outside (outside is by convention
the direction the normal points into).
The normal here thus refers is the cross product of the vector
AB with AC for the three triangle vertices A, B, C.
	[rt/intersectables/MeshTriangle.java]= 
	package rt.intersectables;
	<common imports>

	public class MeshTriangle extends Intersectable {

		private Mesh mesh;
		private int index;
       
		public MeshTriangle(Mesh mesh, int index)
		{
			this.mesh = mesh;
			this.index = index;	
            
            <additional mesh triangle construction tasks>
		}
		
		public HitRecord intersect(Ray ray)
		{
			<ray triangle intersection>
		}
        
        <additional mesh triangle methods>
	}
<h5>Ray-Triangle Intersection</h5>	
The ray-triangle intersection algorithm has the following steps
	<ray triangle intersection>=
		<extract triangle points>
		<compute two triangle sides and normal>
		<ray plane intersection for triangle>
		<compute triangle st>
		<is triangle st within triangle>
		<interpolate normals>
		<return triangle hitpoint>
		
	<extract triangle points>=
	<extract indices>
	<extract vertices>

	<extract indices>=
	int v0 = mesh.indices[index*3], v1 = mesh.indices[index*3+1], v2 = mesh.indices[index*3+2];
	
	<extract vertices>=
	float x0 = mesh.vertices[v0*3],   x1 = mesh.vertices[v1*3],   x2 = mesh.vertices[v2*3];
	float y0 = mesh.vertices[v0*3+1], y1 = mesh.vertices[v1*3+1], y2 = mesh.vertices[v2*3+1];
	float z0 = mesh.vertices[v0*3+2], z1 = mesh.vertices[v1*3+2], z2 = mesh.vertices[v2*3+2];
	
	Vector3f tv0 = new Vector3f(x0,y0,z0), 
		  tv1 = new Vector3f(x1,y1,z1), 
		  tv2 = new Vector3f(x2,y2,z2);
	
	<compute two triangle sides and normal>=
	Vector3f u, v, n;             
	u = M.sub(tv1, tv0);
	v = M.sub(tv2, tv0);
	n = M.cross(u, v);  
	n.normalize();	
		
For the following phases, we operate in a shifted coordinate system where tv0, the first triangle point, becomes the origin.
	<ray plane intersection for triangle>=
	Vector3f w0 = M.sub(ray.origin, tv0);

	float tmp = n.dot(ray.direction);
	if (tmp == 0) return null;
	float tt = -n.dot(w0) / tmp;

	Vector3f I = ray.t(tt);
The obtained intersection point is in world space again, so it must be shifted to obtain the intersection point w that is on the triangle plane through the origin.

	<compute triangle st>=
	Vector3f w = M.sub(I, tv0); 

We want to find the factors s, t such that s*u + t*v = w.
It turns out that the following computation yields the desired factors 
(see bottom of <a href=http://geomalgorithms.com/a06-_intersect-2.html>this page</a>, 
I did not check or convince myself of the math).
	<compute triangle st>+=
	float uu, vv, uv, wu, wv, D;
	uu = u.dot(u);
	uv = u.dot(v);
	vv = v.dot(v);
	wu = w.dot(u);
	wv = w.dot(v);
	D = uv * uv - uu * vv;

	float s, t;
	s = (uv * wv - vv * wu) / D;
	t = (uv * wu - uu * wv) / D;
A point is within the triangle if s, t and s+t are in the interval [0..1].
	<is triangle st within triangle>=
	if (s < 0.0 || s > 1.0) return null;
	if (t < 0.0 || (s + t) > 1.0) return null;

If so, we can extract the mesh vertice's normals and interpolate them, which 
gives us smoother shading than just using the triangle plane's normal n directly.
	<interpolate normals>=
        <extract normals>
        n0.scale(1-s-t); 
        n1.scale(s);
        n2.scale(t);
        n = n0; n.add(n1); n.add(n2); n.normalize();
       
where       
	<extract normals>=
        float nx0 = mesh.normals[v0*3],   nx1 = mesh.normals[v1*3],   nx2 = mesh.normals[v2*3];
        float ny0 = mesh.normals[v0*3+1], ny1 = mesh.normals[v1*3+1], ny2 = mesh.normals[v2*3+1];
        float nz0 = mesh.normals[v0*3+2], nz1 = mesh.normals[v1*3+2], nz2 = mesh.normals[v2*3+2];
        
        Vector3f n0 = new Vector3f(nx0,ny0,nz0), 
                 n1 = new Vector3f(nx1,ny1,nz1), 
                 n2 = new Vector3f(nx2,ny2,nz2);
		  
Then we can output the hit-record.
	<return triangle hitpoint>=
        HitRecord h = new HitRecord(
                ray,
                tt, // not t!
                this, 
                n
                ); 
        <triangle hit record post processing>
        return h;
        
	<triangle hit record post processing>=
    
<h5>Tests</h5>
<img src="output/rt.testscenes.TriangleTest 1SPP.png"></img>	
<img src=tritest.JPG></img>
	[rt/testscenes/TriangleTest.java]= 
	package rt.testscenes;
	<common imports>
	public class TriangleTest extends ObjectUVTest {

		public TriangleTest()
		{
			super(new Vector3f(0.f, 0.f, 3.f));

			float[] vertices = {
				0.f, 0.f, 0.f, 
				1.f, 0.f, 0.f, 
				0.f, 1.f, 0.f};
			float[] normals = {
				0.f, 0.f, 1.f,
				0.f, 0.f, 1.f,
				0.f, 0.f, 1.f};
			int[] indices = {0, 1, 2};
			
			root = new Mesh(vertices, normals, indices);
		}
	}
	<test scenes>+=
	new TriangleTest(),
<img src="output/rt.testscenes.TriangleTest2 1SPP.png"></img>	
	[rt/testscenes/TriangleTest2.java]= 
	package rt.testscenes;
	<common imports>
	public class TriangleTest2 extends ObjectUVTest {

		public TriangleTest2()
		{
			super(new Vector3f(0.f, 0.f, 9.f));
			
			float[] vertices = {
				0.f, 0.f, 0.f, 
				1.f, 0.f, 0.f, 
				0.f, 1.f, 0.f,
				
				3.f, 1.f, 2.f,
				2.f, 4.f, 5.f,
				1.f, 2.f, 3.f,
				
				1.f, 0.f, 3.f, 
				2.f, 0.f, 3.f, 
				1.f, 2.f, 3.f,
			};
			float[] normals = {
				0.f, 0.f, 1.f,
				0.f, 0.f, 1.f, 
				0.f, 0.f, 1.f,
				
				0.f, 0.f, 1.f,
				0.f, 0.f, 1.f,
				0.f, 0.f, 1.f,
				
				0.f, 0.f, 1.f,
				0.f, 0.f, 1.f,
				0.f, 0.f, 1.f,
				};
			int[] indices = {
				0, 1, 2,
				3, 4, 5,
				6, 7, 8
			};
			
			root = new Mesh(vertices, normals, indices);
		}

	}	
	<test scenes>+=
	new TriangleTest2(),

<h4>Mesh Primitives</h4>
We provide some meshes that are constructed computationally (procedurally) 
just because we can.
<h5>MeshUnitCylinder</h5>
The parameter n is the amount of sides.
Issue: Uncapped as of now - this was only added to investigate a
problem with the triangle intersection test. Also, there is no computation of normals.
Creates every triangle separately (not making use of index buffer).

	[rt/intersectables/MeshUnitCylinder.java]=
	package rt.intersectables;
	<common imports>
	public class MeshUnitCylinder extends IntersectableList {
		public MeshUnitCylinder(int n) {
			int m = <compute amount of indices>;
			float z = 1;
			float[] vertices = new float[3*m];  int cv = 0;
			float[] normals  = new float[3*m];  int cn = 0;
			int  [] indices	 = new int[m]; 		int ci = 0;
			
			<compute angle step>
			for (int i = 0; i < n; i++) {
				float x = <compute x>, y = <compute y>;
				float nx = <compute nx>, ny = <compute ny>;
				<construct vertices>
				<advance indices>
			}
			
			add(new Mesh(vertices, normals, indices));
		}
	}
	
We have n sides, each with two triangles.
	<compute amount of indices>=
	3*(n*2)
We step an angle of 1/n-th of the whole circle in each step.
	<compute angle step>=
	float a = (float)Math.PI*2.f/n;
	
	<compute x>=
	(float)Math.cos((i+0)*a)
	<compute y>=
	(float)Math.sin((i+0)*a)
	
	<compute nx>=
	(float)Math.cos((i+1)*a)
	<compute ny>=
	(float)Math.sin((i+1)*a)
	
We must construct triangles such that their vertices are in counter-clockwise order when seen from the outside.
<img src=cyltri.jpg></img>
	<construct vertices>=
	<vertex a>
	<vertex b>
	<vertex c>
	
	<vertex b>
	<vertex d>
	<vertex c>
	
Where the vertices are
	<vertex a>=
	vertices[cv++] = x; vertices[cv++] = y; vertices[cv++] = z; 
	<vertex b>=
	vertices[cv++] = x; vertices[cv++] = y; vertices[cv++] = -z;
	<vertex c>=
	vertices[cv++] = nx; vertices[cv++] = ny; vertices[cv++] = z;
	<vertex d>=
	vertices[cv++] = nx; vertices[cv++] = ny; vertices[cv++] = -z;
	
Just advance by the six vertices we created.
	<advance indices>=
	for (int k = 0; k < 6; k++, ci++) 
		indices[ci] = ci;
	
In the test scene, we look at it from the side, i.e. from the +x axis, from
	<muc origin>=
	3.f, 0.f, 0.f
to be precise.

<img src="output/rt.testscenes.MUC 1SPP.png"></img>
	[rt/testscenes/MUC.java]= 
	package rt.testscenes;
	<common imports>
	public class MUC extends ObjectTest {
		public MUC()
		{
			super(new Vector3f(<muc origin>));
			root = new MeshUnitCylinder(8);
		}
	}
	<test scenes>+=
	new MUC(),
    
<h5>Rectangle</h5>
A rectangle given by origin and two delta vectors.
It points into the direction of the cross product of da with db.
    <rectangle normal>=
    Vector3f n = M.cross(da, db); 
<img src=rect.jpg></img>
        
    <rvertex a>=
	vertices[cv++] = a.x; vertices[cv++] = a.y; vertices[cv++] = a.z;     
    <rvertex b>=
	vertices[cv++] = b.x; vertices[cv++] = b.y; vertices[cv++] = b.z;     
    <rvertex c>=
	vertices[cv++] = c.x; vertices[cv++] = c.y; vertices[cv++] = c.z;     
    <rvertex d>=
	vertices[cv++] = d.x; vertices[cv++] = d.y; vertices[cv++] = d.z; 
    
    [rt/intersectables/Rectangle.java]=
	package rt.intersectables;
	<common imports>
	public class Rectangle extends IntersectableList {
        Vector3f a, da, db;
		public Rectangle(Vector3f a, Vector3f da, Vector3f db) {
            this.a = a; this.da = da; this.db = db;
            
			int m = 2 * 3;
			float z = 1;
			float[] vertices = new float[3*m]; int cv = 0;
			float[] normals  = new float[3*m];  
			int  [] indices	 = {0,1,2,3,4,5}; 	
			
            Vector3f b = M.add(a,da);
            Vector3f c = M.add(a,db);
            Vector3f d = M.add(c,da);
            
            <rvertex a>
            <rvertex b>
            <rvertex c>
            
            <rvertex b>
            <rvertex d>
            <rvertex c>
            
            <rectangle normal>
            for (int i = 0; i < m; i++) {
                normals[3*i+0] = n.x; normals[3*i+1] = n.y; normals[3*i+2] = n.z;
            }
			
			add(new Mesh(vertices, normals, indices));
		}
        
        <additional rectangle methods>
	}
    
<h2>Acceleration Structures</h2>
The naive approach to determining
    hit = first intersection with scene
used in for example the Aggregate, 
has a complexity of O(n), where n is the amount of objects in the scene.
We can improve this to circa O(log n).
For this we partition the scene's space or object groups recursively in say halfs,
such that we can ignore groups of objects at once when their bounding box is not even hit.
We could also use bounding spheres, or arbitrarily oriented shapes as bounding volumes, but
axis alighned bounding boxes are particularly easy to work with.

<h3>AABB</h3>
Every accelerateable intersectable returns its axis aligned bounding box via the aabb method.
    <additional intersectable methods and data>+=
    public AABB aabb() {
        throw new RuntimeException(this.getClass()+" does not implement aabb()");
    } 
        
An axis aligned bounding box is uniquely defined by its lower left and 
upper right corner coordinates a and b.
    <aabb attributes>=
    Vector3f a, b;
  
An aabb can be constructed such that it encloses a set of points
    <construct aabb>=
        public AABB(Vector3f... ps) {
            float xmin = Float.POSITIVE_INFINITY, ymin = xmin, zmin = xmin, 
                  xmax = Float.NEGATIVE_INFINITY, ymax = xmax, zmax = xmax;
            for (Vector3f p : ps) {
                xmin = Math.min(xmin, p.x); ymin = Math.min(ymin, p.y); zmin = Math.min(zmin, p.z);
                xmax = Math.max(xmax, p.x); ymax = Math.max(ymax, p.y); zmax = Math.max(zmax, p.z);
            }
            a = new Vector3f(xmin, ymin, zmin);
            b = new Vector3f(xmax, ymax, zmax);
        }
        
Or by copying an existing
    <construct aabb>+=
        public AABB(AABB o) {
            a = new Vector3f(o.a); b = new Vector3f(o.b);
        }
The first way of construction can be used to create an aabb that encloses two given ones
    <aabb union>=
    public AABB union(AABB o) {
        return new AABB(a, b, o.a, o.b);
    }
        
We can intersect an aabb with a ray quite easily:
        <ray aabb intersection>=
        public float[] getIntersections(Ray ray) {
            float e_x = ray.origin.x;
            float e_y = ray.origin.y;
            float e_z = ray.origin.z;
            float d_x = ray.direction.x;
            float d_y = ray.direction.y;
            float d_z = ray.direction.z;
            float 
                x_min = a.x, x_max = b.x,
                y_min = a.y, y_max = b.y,
                z_min = a.z, z_max = b.z;
            float t_xmin, t_xmax,
                  t_ymin, t_ymax,
                  t_zmin, t_zmax;
            
            if( d_x >= 0 ) {
                t_xmin = ( x_min - e_x ) / d_x;
                t_xmax = ( x_max - e_x ) / d_x;
            } else {
                t_xmin = ( x_max - e_x ) / d_x;
                t_xmax = ( x_min - e_x ) / d_x;
            }
            
            if( d_y >= 0 ) {
                t_ymin = ( y_min - e_y ) / d_y;
                t_ymax = ( y_max - e_y ) / d_y;
            } else {
                t_ymin = ( y_max - e_y ) / d_y;
                t_ymax = ( y_min - e_y ) / d_y;
            }
            
            if( d_z >= 0 ) {
                t_zmin = ( z_min - e_z ) / d_z;
                t_zmax = ( z_max - e_z ) / d_z;
            } else {
                t_zmin = ( z_max - e_z ) / d_z;
                t_zmax = ( z_min - e_z ) / d_z;
            }

			if (t_xmin>t_ymax || t_ymin>t_xmax) return null;
			if (t_xmin>t_zmax || t_zmin>t_xmax) return null;
			if (t_ymin>t_zmax || t_zmin>t_ymax) return null;
            return new float[] {
                Math.max(Math.max(t_xmin, t_ymin), t_zmin),
                Math.min(Math.min(t_xmax, t_ymax), t_zmax)
            };
		}
The intersection times returned by this are ordered by t. 
We return null if there are none.

<p>
For convenience, we also create a method that, assuming two Intersectables whose
AABBs don't overlap, intersects a ray with both of them and returns them
in the order they are hit. If either is not hit, set it to null.
    <ray aabb intersect and order>=
       public static <T extends Intersectable> T[] intersectAndSort(Ray r, T[] o) {
            assert o != null;
            assert o[0] != null;
            assert o[1] != null;
            assert o[0].aabb() != null;
            assert o[1].aabb() != null;
            float i1[] = o[0].aabb().getIntersections(r);
            float i2[] = o[1].aabb().getIntersections(r);
            
            if (i1 == null) {o[0] = null; return o;}
            if (i2 == null) {o[1] = null; return o;}
            if (i2[0] < i1[0]) {T x = o[0]; o[0] = o[1]; o[1] = x;}
            return o;
        }
    
A method to test whether two axis aligned bounding boxes overlap is straightforward to
implement: two axis aligned boxes are guaranteed to overlap if all of their extents in
x, y, or z coordinates overlap.
<img src=ioverlap.jpg></img>
    <overlaps with other aabb>=
    private static boolean intervalsOverlap(float min, float max, float omin, float omax) {
        return min <= omax && max >= omin;
    }
    public boolean overlapsWith(AABB o) {
        return intervalsOverlap(a.x, b.x,   o.a.x, o.b.x)
            && intervalsOverlap(a.y, b.y,   o.a.y, o.b.y)
            && intervalsOverlap(a.z, b.z,   o.a.z, o.b.z);
    }
    
    
    [rt/AABB.java]= 
    package rt;
    <common imports>
    public class AABB {
        <aabb attributes>
        <construct aabb>
        <aabb union>
        <ray aabb intersection>
        <ray aabb intersect and order>
        <overlaps with other aabb>
    }
    
    <unit tests>+=
    @Test
    public void testAABB() {
        AABB aabb = new AABB(new Vector3f(0,0,0),new Vector3f(2.f,0.5f,0),new Vector3f(1.f,1.f,1.f));
        assertTrue(aabb.a.x == 0 && aabb.b.x == 2.f);
        assertTrue(aabb.a.y == 0 && aabb.b.y == 1.f);
        assertTrue(aabb.a.z == 0 && aabb.b.z == 1.f);
        
        AABB aabb3 = new AABB(new Vector3f(0,0,0),new Vector3f(1.f,1.f,1.f));
        
        AABB aabb2 = aabb.union(aabb3);
        assertTrue(aabb2.overlapsWith(aabb));
        
        float[] ts = aabb3.getIntersections(new Ray(
            new Vector3f(-1,0.5f,0.5f),
            new Vector3f(1,0,0)));
        assertEquals(1.f,ts[0],0.0001f);
        assertEquals(2.f,ts[1],0.0001f);
    }
    
<h4>Triangle AABB</h4>
For the moment, we confine ourselves to computing the AABB for triangle primitives,
which is straightforward:
    <additional mesh triangle construction tasks>=
        <extract indices>
        <extract vertices>
        aabb = new AABB(tv0, tv1, tv2);
                
    <additional mesh triangle methods>=
        private AABB aabb;
        public AABB aabb() {
            return aabb;
        }
Notice that for efficiency reasons, we only construct this once, assuming that 
the mesh will not change.

<h4>Aggregate AABB</h4>
The aabb of an aggregate is simply the union of all child aabbs.
    <additional aggregate methods>=
    public AABB aabb() {
        AABB aabb = null;
        for (Intersectable o : this)
            aabb = (aabb == null) ? o.aabb() : aabb.union(o.aabb());
        return aabb;
    }
    
<h3>BSP, Binary Space partitioning</h3>
Main idea: Recursively divide bounding box into two disjoint parts using
dividing planes (with arbitrary position, orientation).
We fix our orientation to the three axis in space 
(axis aligned splitting planes and bounding boxes).
    <axis enum>=
    public static enum Axis {
        X,Y,Z;
        Axis next() { return this == X ? Y : this == Y ? Z : X; }
    }
        
We implement the BSPAccelerator root node as an IntersectableList containing just one 
BSPNode.
    [rt/BSPAccelerator.java]= 
    package rt;
    <common imports>
    public class BSPAccelerator extends IntersectableList {
        public BSPAccelerator(Aggregate primitives) {
            BSPNode root = new BSPNode();
            
            root.aabb = primitives.aabb();
            root.primitives = primitives;
            
            int n = primitives.size();
            
            root.construct(Axis.X, 0, <maximum depth>);
            
            add(root);
        }
    }
<h4>BSPNode</h4>
By convention the children in the binary tree that a BSP is are called 
'below' and 'above'. 'below' represents that 
part of space with coordinate values lower than that of the split plane along
the axis of it.
A node then either stores two child nodes or a list of primitives when it is a leaf:
    <bsp node attributes>=
        BSPNode below, above;
        Aggregate primitives;
        boolean isLeaf() {
            return primitives != null && below == null && above == null;
        }
        
It stores the axis aligned bounding box that intersects all the objects it contains
    <bsp node attributes>+=
    AABB aabb;
    public AABB aabb() {return aabb;}
    
<h4>Construction</h4>
The construct method of a bsp node assumes 'primitives' and 'aabb' were already set.
'axis' represents the split plane normal's direction (we don't care about orientation).

    <construct bsp>=
    void construct(Axis axis, int depth, int maxdepth) {
        <no further children>
        <prepare above and below child>
        <compute child aabb>
        
        <assign primitives to children>
        <construct children>
    }
    
Basic BSP tree construction splits BSP nodes
in their geometric middle
    <compute child aabb>=
    float p;
    switch (axis) {
        case X: p = (aabb.a.x + aabb.b.x)/2; below.aabb.b.x = p; above.aabb.a.x = p; break;
        case Y: p = (aabb.a.y + aabb.b.y)/2; below.aabb.b.y = p; above.aabb.a.y = p; break;
        case Z: p = (aabb.a.z + aabb.b.z)/2; below.aabb.b.z = p; above.aabb.a.z = p; break;
    }

Splitting continues until each node includes fewer objects (e.g., triangles) 
than 
    <max objects per leaf>=
    5
or the tree reaches a maximum depth, which might be computed from the amount n 
of primitives in the tree
    <maximum depth>=
    8 + (int)(1.3 * Math.log(n))
    
    <no further children>=
    if (primitives.size() <= <max objects per leaf> ||
        depth > maxdepth) return;
        
    <prepare above and below child>=
        below = new BSPNode();
        above = new BSPNode();
        
        IntersectableList 
            obelow = new IntersectableList(),
            oabove = new IntersectableList();
        below.primitives = obelow;
        above.primitives = oabove;
        
        below.aabb = new AABB(aabb); // lower values
        above.aabb = new AABB(aabb); // higher values
    
    <assign primitives to children>=
        for (Intersectable o : primitives) {
            if (o.aabb().overlapsWith(below.aabb)) obelow.add(o);
            if (o.aabb().overlapsWith(above.aabb)) oabove.add(o);
        }
        primitives = null;
        
The children will use the cyclically next splitting axis.
    <construct children>=
        depth++;
        axis = axis.next();
        below.construct(axis, depth, maxdepth);
        above.construct(axis, depth, maxdepth);
        
<h4>Intersection</h4>
For intersection, we simply traverse the children that are hit in order.
    <child is hit>=
        float[] ts = aabb.getIntersections(ray); 
        if (ts == null) return null;
        float tmin = ts[0], tmax = ts[1];
    
<ul>
<li>    
When we arrive at a leaf, we intersect with all primitives and keep the hit record
if the intersection happens within the volume.
    <leaf intersection>=
        if (isLeaf()) {
            HitRecord a = primitives.intersect(ray);
            if (a != null && a.t >= tmin && a.t <= tmax) return a;
            return null;
        }
We cannot use other hits, because they might not be globally closest as illustrated below.
<img src=bspisec.png></img>
<li>Otherwise we 
traverse the children:
    <intersect bsp children>=
        BSPNode[] xs = AABB.intersectAndSort(ray, new BSPNode[]{below, above});
        for (BSPNode x : xs) { 
            if (x == null) continue;
            
            HitRecord a = x.intersect(ray);
            if (a != null) return a;
        }
</ul>
Overall:
    <intersect bsp>=
        public HitRecord intersect(Ray ray) {
            <child is hit>
            <leaf intersection>
            <intersect bsp children>
            return null;
        }
        
    [rt/BSPNode.java]= 
    package rt;
    <common imports>
    public class BSPNode extends Intersectable {
        <bsp node attributes>
        <axis enum>
        
        <intersect bsp>
        
        <construct bsp>
    }

<h4>Test: BSPScene</h4>
<img src="output/rt.testscenes.BSPScene 1SPP.png"></img>
	[rt/testscenes/BSPScene.java]= 
	package rt.testscenes;
	<common imports>
	public class BSPScene extends ObjectNormalTest {
		public BSPScene()
		{
			super(new Vector3f(0.f,0.f,2.f));
			root = new BSPAccelerator(ObjReader.read("obj/Specter_GT3.obj", 0.95f));
		}
	}
	<test scenes>+=
	new BSPScene(),
    
